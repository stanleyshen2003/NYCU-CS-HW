diff --git a/.gitignore b/.gitignore
index f5381c6..f02f4a8 100644
--- a/.gitignore
+++ b/.gitignore
@@ -36,9 +36,6 @@ perlin_image
 perlin_for_test
 simple_poly
 
-vgg
-discriminator/datasets
-
 *.zip
 
 *.png
diff --git a/DDPG.py b/DDPG.py
deleted file mode 100644
index c69f550..0000000
--- a/DDPG.py
+++ /dev/null
@@ -1,359 +0,0 @@
-import sys
-import gym
-import numpy as np
-import os
-import time
-import random
-from collections import namedtuple
-import torch
-import torch.nn as nn
-from torch.optim import Adam
-from torch.autograd import Variable
-import torch.optim.lr_scheduler as Scheduler
-import torch.nn.functional as F
-from torch.utils.tensorboard import SummaryWriter
-from buildEnv import createEnv, MyStocksEnv
-from torch.distributions import Categorical
-import logging
-#from skopt.space import Real, Integer
-#from skopt import gp_minimize
-logging.basicConfig(filename='train.log', level=logging.DEBUG)
-
-os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-def soft_update(target, source, tau):
-    for target_param, param in zip(target.parameters(), source.parameters()):
-        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
-
-def hard_update(target, source):
-    for target_param, param in zip(target.parameters(), source.parameters()):
-        target_param.data.copy_(param.data)
-
-Transition = namedtuple(
-    'Transition', ('state', 'action', 'mask', 'next_state', 'reward'))
-
-class ReplayMemory(object):
-
-    def __init__(self, capacity):
-        self.capacity = capacity
-        self.memory = []
-        self.position = 0
-
-    def push(self, *args):
-        if len(self.memory) < self.capacity:
-            self.memory.append(None)
-        self.memory[self.position] = Transition(*args)
-        self.position = (self.position + 1) % self.capacity
-
-    def sample(self, batch_size):
-        return random.sample(self.memory, batch_size)
-
-    def __len__(self):
-        return len(self.memory)
-
-class OUNoise:
-
-    def __init__(self, action_dimension, scale=0.1, mu=0, theta=0.15, sigma=0.2):
-        self.action_dimension = action_dimension
-        self.scale = scale
-        self.mu = mu
-        self.theta = theta
-        self.sigma = sigma
-        self.state = np.ones(self.action_dimension) * self.mu
-        self.reset()
-
-    def reset(self):
-        self.state = np.ones(self.action_dimension) * self.mu
-
-    def noise(self):
-        x = self.state
-        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))
-        self.state = x + dx
-        return self.state * self.scale    
-
-class Actor(nn.Module):
-    def __init__(self, hidden_size, num_inputs, action_space):
-        super(Actor, self).__init__()
-        self.action_space = action_space
-        num_outputs = action_space
-
-        ########## YOUR CODE HERE (5~10 lines) ##########
-        # Construct your own actor network
-        self.linearlayer1 = nn.Linear(num_inputs, hidden_size)
-        self.linearlayer2 = nn.Linear(hidden_size, hidden_size)
-        self.linearlayer3 = nn.Linear(hidden_size, hidden_size)
-        self.outputlayer = nn.Linear(hidden_size, num_outputs)
-        ########## END OF YOUR CODE ##########
-        
-    def forward(self, inputs):
-        
-        ########## YOUR CODE HERE (5~10 lines) ##########
-        # Define the forward pass your actor network
-        x = self.linearlayer1(inputs)
-        x = F.relu(x)
-        x = self.linearlayer2(x)
-        x = F.relu(x)
-        x = self.linearlayer3(x)
-        x = F.relu(x)
-        action = self.outputlayer(x)
-        return action
-        ########## END OF YOUR CODE ##########
-
-class Critic(nn.Module):
-    def __init__(self, hidden_size, num_inputs, action_space):
-        super(Critic, self).__init__()
-        self.action_space = action_space
-        num_outputs = action_space
-
-        ########## YOUR CODE HERE (5~10 lines) ##########
-        # Construct your own critic network
-        self.linearlayer1 = nn.Linear(num_inputs+num_outputs, hidden_size)
-        self.linearlayer2 = nn.Linear(hidden_size, hidden_size)
-        self.linearlayer3 = nn.Linear(hidden_size, hidden_size)
-        self.outputlayer = nn.Linear(hidden_size, 1)
-        ########## END OF YOUR CODE ##########
-
-    def forward(self, inputs, actions):
-        
-        ########## YOUR CODE HERE (5~10 lines) ##########
-        # Define the forward pass your critic network
-        x = self.linearlayer1(torch.cat([inputs, actions], dim=-1))
-        x = F.relu(x)
-        x = self.linearlayer2(x)
-        x = F.relu(x)
-        x = self.linearlayer3(x)
-        x = F.relu(x)
-        v = self.outputlayer(x)
-        return v
-        ########## END OF YOUR CODE ##########        
-        
-
-class DDPG(object):
-    def __init__(self, num_inputs, action_space, env, epsilon, gamma=0.995, tau=0.0005, hidden_size=128, lr_a=1e-4, lr_c=1e-3, lr_a_decay=0.995, lr_c_decay=0.995, step_size=100):
-
-        self.num_inputs = num_inputs
-        self.action_space = action_space
-
-        self.actor = Actor(hidden_size, self.num_inputs, self.action_space)
-        self.actor_target = Actor(hidden_size, self.num_inputs, self.action_space)
-        self.actor_perturbed = Actor(hidden_size, self.num_inputs, self.action_space)
-        self.actor_optim = Adam(self.actor.parameters(), lr=lr_a)
-        self.actor_scedule = Scheduler.StepLR(self.actor_optim, step_size=step_size, gamma=lr_a_decay)
-
-        self.critic = Critic(hidden_size, self.num_inputs, self.action_space)
-        self.critic_target = Critic(hidden_size, self.num_inputs, self.action_space)
-        self.critic_optim = Adam(self.critic.parameters(), lr=lr_c)
-        self.critic_scedule = Scheduler.StepLR(self.critic_optim, step_size=step_size, gamma=lr_c_decay)
-
-        self.gamma = gamma
-        self.tau = tau
-        self.epsilon = epsilon
-        self.env = env
-
-        hard_update(self.actor_target, self.actor) 
-        hard_update(self.critic_target, self.critic)
-
-
-    def select_action(self, state, epsilon=0.0):
-        self.actor.eval()
-        probs = self.actor((Variable(state)))
-        probs = probs.detach()
-        m = Categorical(logits= probs)
-        action = m.sample().item()
-        if random.random() > epsilon:
-            return self.env.action_space.sample()
-        return action
-
-    def update_parameters(self, batch):
-        state_batch = Variable(torch.cat([b.state for b in batch]))
-        action_batch = Variable(torch.cat([b.action for b in batch]))
-        reward_batch = Variable(torch.cat([b.reward for b in batch]))
-        mask_batch = Variable(torch.cat([b.mask for b in batch]))
-        next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
-        
-        # Calculate policy loss and value loss
-        # Update the actor and the critic
-        q_v = self.critic(state_batch, action_batch)
-        next_action = self.actor_target(next_state_batch)
-        next_q = self.critic_target(next_state_batch, next_action)
-        q_target = reward_batch.view(-1,1) + self.gamma * next_q * (1-mask_batch.view(-1,1))
-        value_loss = F.mse_loss(q_v, q_target)
-        #update critic
-        self.critic_optim.zero_grad()
-        value_loss.backward()
-        self.critic_optim.step()
-        #update actor
-        ploss = self.critic(state_batch, self.actor(state_batch))
-        policy_loss = -ploss.mean()
-        self.actor_optim.zero_grad()
-        policy_loss.backward()
-        self.actor_optim.step()
-
-        soft_update(self.actor_target, self.actor, self.tau)
-        soft_update(self.critic_target, self.critic, self.tau)
-
-        return value_loss.item(), policy_loss.item()
-
-
-    def save_model(self, env_name, suffix="", actor_path=None, critic_path=None):
-        local_time = time.localtime()
-        timestamp = time.strftime("%m%d%Y_%H%M%S", local_time)
-        if not os.path.exists('preTrained/lunarlander/'):
-            os.makedirs('preTrained/lunarlander/')
-
-        if actor_path is None:
-            actor_path = "preTrained/lunarlander/ddpg_actor_{}_{}_{}".format(env_name, timestamp, suffix) 
-        if critic_path is None:
-            critic_path = "preTrained/lunarlander/ddpg_critic_{}_{}_{}".format(env_name, timestamp, suffix) 
-        print('Saving models to {} and {}'.format(actor_path, critic_path))
-        torch.save(self.actor.state_dict(), actor_path)
-        torch.save(self.critic.state_dict(), critic_path)
-
-    def load_model(self, actor_path, critic_path):
-        print('Loading models from {} and {}'.format(actor_path, critic_path))
-        if actor_path is not None:
-            self.actor.load_state_dict(torch.load(actor_path))
-        if critic_path is not None: 
-            self.critic.load_state_dict(torch.load(critic_path))
-
-def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-    # Define a tensorboard writer
-    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-
-    logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
-        lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
-    torch.manual_seed(10)
-
-    num_episodes = 1000
-    gamma = 0.995
-    tau = 0.002
-    lr_a = lr_a_ #1e-4
-    lr_c = lr_c_ #1e-3
-    lr_a_decay=lr_a_decay_ #0.995
-    lr_c_decay=lr_c_decay_ #0.995
-    hidden_size = 128
-    noise_scale = noise_scale_ #0.3
-    replay_size = 100000
-    batch_size = batch_size_ #128
-    epsilon = 0.03
-    updates_per_step = 1
-    print_freq = 20
-    ewma_reward = 0
-    rewards = []
-    ewma_reward_history = []
-    total_numsteps = 0
-    updates = 0
-
-    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
-                 action_space = env.action_space.n, 
-                 env = env, 
-                 epsilon= epsilon,
-                 gamma = gamma, 
-                 tau = tau, 
-                 hidden_size = hidden_size,
-                lr_a= lr_a, 
-                lr_c= lr_c, 
-                lr_a_decay= lr_a_decay, 
-                lr_c_decay = lr_c_decay)
-    #ounoise = OUNoise(env.action_space)
-    memory = ReplayMemory(replay_size)
-    
-    for i_episode in range(num_episodes):
-        
-        #ounoise.scale = noise_scale
-        #ounoise.reset()
-        
-        state = torch.Tensor([env.reset().reshape(-1)])
-
-        episode_reward = 0
-        val_loss = []
-        act_loss = []
-        while True:
-            
-            ########## YOUR CODE HERE (15~25 lines) ##########
-            # 1. Interact with the env to get new (s,a,r,s') samples 
-            # 2. Push the sample to the replay buffer
-            # 3. Update the actor and the critic
-            total_numsteps+=1
-            action = agent.select_action(state, epsilon)
-            next_state, reward, done, info = env.step(action)
-            next_state = torch.Tensor([next_state.reshape(-1)])
-            memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
-            if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
-                batch = memory.sample(batch_size)
-                v_loss, a_loss = agent.update_parameters(batch)
-                val_loss.append(v_loss)
-                act_loss.append(a_loss)
-            episode_reward += reward
-            state = next_state
-            if done:
-                break
-            ########## END OF YOUR CODE ########## 
-        
-
-        rewards.append(episode_reward)
-        actor_loss = np.mean(act_loss)
-        critic_loss = np.mean(val_loss)
-        t = 0
-        
-        state = torch.Tensor([env.reset().reshape(-1)])
-        episode_reward = 0
-        while True:
-            action = agent.select_action(state)
-
-            next_state, reward, done, info = env.step(action)
-            
-            #env.render()
-            
-            episode_reward += reward
-
-            next_state = torch.Tensor([next_state.reshape(-1)])
-
-            state = next_state
-            
-            t += 1
-            if done:
-                print(info)
-                break
-
-        rewards.append(episode_reward)
-        # update EWMA reward and log the results
-        ewma_reward = 0.05 * episode_reward + (1 - 0.05) * ewma_reward
-        ewma_reward_history.append(ewma_reward)
-        if i_episode % print_freq == 0:
-            print("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))    
-            logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
-
-        #Logging
-        #writer.add_scalar('Reward', episode_reward, i_episode)
-        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
-        #writer.add_scalar('Critic loss', critic_loss, i_episode)
-        #writer.add_scalar('Actor loss', actor_loss, i_episode)
-
-        #if ewma_reward >= 120:
-        #    agent.save_model(env_name, '.pth')
-        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-        #    #break
-        #    return (ewma_reward+500)/(i_episode+1) #For tuning
-    
-    agent.save_model(env_name, '.pth')  
-    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-    return (ewma_reward+500)/(i_episode+1) #For tuning
-
-def main():
-    """
-    Training args
-    """
-    lr_a = 0.001
-    lr_c = 0.001
-    lr_a_decay_ = 1.0
-    lr_c_decay_ = 1.0
-    noise_scale_ = 0.3
-    batch_size_ = 64
-
-
-    env = createEnv(2330)
-
-    train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
-if __name__ == '__main__':
-    main()
\ No newline at end of file
diff --git a/DQN.py b/DQN.py
deleted file mode 100644
index 468e698..0000000
--- a/DQN.py
+++ /dev/null
@@ -1,281 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import numpy as np
-import gym
-import random
-from collections import deque
-from torch import Tensor
-import os
-from tqdm import tqdm
-import buildEnv
-import math
-total_rewards = []
-
-
-class replay_buffer:
-    """
-    A deque storing trajectories
-    """
-
-    def __init__(self, capacity):
-        self.capacity = capacity  # the size of the replay buffer
-        self.memory = deque(maxlen=capacity)  # replay buffer itself
-
-    def insert(self, state, action, reward, next_state, done):
-        """
-        Insert a sequence of data gotten by the agent into the replay buffer.
-        Parameter:
-            state: the current state
-            action: the action done by the agent
-            reward: the reward agent got
-            next_state: the next state
-            done: the status showing whether the episode finish
-        Return:
-            None
-        """
-        self.memory.append([state, action, reward, next_state.reshape(48), done])
-
-    def sample(self, batch_size):
-        """
-        Sample a batch size of data from the replay buffer.
-        Parameter:
-            batch_size: the number of samples which will be propagated through the neural network
-        Returns:
-            observations: a batch size of states stored in the replay buffer
-            actions: a batch size of actions stored in the replay buffer
-            rewards: a batch size of rewards stored in the replay buffer
-            next_observations: a batch size of "next_state"s stored in the replay buffer
-            done: a batch size of done stored in the replay buffer
-        """
-        batch = random.sample(self.memory, batch_size)
-        observations, actions, rewards, next_observations, done = zip(*batch)
-        return observations, actions, rewards, next_observations, done
-
-    def __len__(self):
-        return len(self.memory)
-
-
-class Net(nn.Module):
-    """
-    The structure of the Neural Network calculating Q values of each state.
-    """
-
-    def __init__(self,  num_actions, hidden_layer_size=256):
-        super(Net, self).__init__()
-        self.input_state = 48  # the dimension of state space
-        self.num_actions = num_actions  # the dimension of action space
-        self.fc1 = nn.Linear(self.input_state, hidden_layer_size)  # input layer
-        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)  # hidden layer
-        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)
-        self.fc4 = nn.Linear(hidden_layer_size, num_actions)  # output layer
-
-    def forward(self, states):
-        """
-        Forward the state to the neural network.
-        Parameter:
-            states: a batch size of states
-        Return:
-            q_values: a batch size of q_values
-        """
-        x = F.relu(self.fc1(states))
-        x = F.relu(self.fc2(x))
-        x = F.relu(self.fc3(x))
-        q_values = self.fc4(x)
-        return q_values
-
-
-class Agent:
-    def __init__(
-        self, env, epsilon=10, learning_rate=0.0002, GAMMA=0.97, batch_size=32, capacity=10000
-    ):
-        """
-        The agent learning how to control the action of the cart pole.
-        Hyperparameters:
-            epsilon: Determines the explore/expliot rate of the agent
-            learning_rate: Determines the step size while moving toward a minimum of a loss function
-            GAMMA: the discount factor (tradeoff between immediate rewards and future rewards)
-            batch_size: the number of samples which will be propagated through the neural network
-            capacity: the size of the replay buffer/memory
-        """
-        self.env = env
-        self.n_actions = 2  # the number of actions
-        self.count = 0
-
-        self.epsilon = epsilon
-        self.learning_rate = learning_rate
-        self.gamma = GAMMA
-        self.batch_size = batch_size
-        self.capacity = capacity
-
-        self.buffer = replay_buffer(self.capacity)
-        self.evaluate_net = Net(self.n_actions)  # the evaluate network
-        self.target_net = Net(self.n_actions)  # the target network
-
-        self.optimizer = torch.optim.Adam(
-            self.evaluate_net.parameters(), lr=self.learning_rate
-        )  # Adam is a method using to optimize the neural network
-
-    def learn(self):
-        """
-        - Implement the learning function.
-        - Here are the hints to implement.
-        Steps:
-        -----
-        1. Update target net by current net every 100 times. (we have done this for you)
-        2. Sample trajectories of batch size from the replay buffer.
-        3. Forward the data to the evaluate net and the target net.
-        4. Compute the loss with MSE.
-        5. Zero-out the gradients.
-        6. Backpropagation.
-        7. Optimize the loss function.
-        -----
-        Parameters:
-            self: the agent itself.
-            (Don't pass additional parameters to the function.)
-            (All you need have been initialized in the constructor.)
-        Returns:
-            None (Don't need to return anything)
-        """
-        if self.count % 10 == 0:
-            self.target_net.load_state_dict(self.evaluate_net.state_dict())
-
-        # Begin your code
-        """
-        Sample trajectories of batch size from the replay buffer.
-        Convert these sampled data into tensor.
-        """
-        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)
-        states = torch.tensor(np.array(states), dtype=torch.float)
-        actions = torch.tensor(np.array(actions), dtype=torch.int64).unsqueeze(-1)
-        rewards = torch.tensor(np.array(rewards), dtype=torch.float)
-        next_states = torch.tensor(np.array(next_states), dtype=torch.float)
-        dones = torch.tensor(np.array(dones), dtype=torch.float)
-        
-        q_values = torch.gather(self.evaluate_net(states), 1, actions)
-        
-        next_actions = self.evaluate_net(next_states).argmax(dim=1, keepdim=True)
-        next_q_values = self.target_net(next_states).gather(1, next_actions).reshape(32)
-        target_q_values = (rewards + self.gamma * (1 - dones) * next_q_values).unsqueeze(1)
-
-        loss = F.mse_loss(q_values, target_q_values)
-        self.optimizer.zero_grad()
-        loss.backward()
-        self.optimizer.step()
-        # End your code
-        torch.save(self.target_net.state_dict(), "./Tables/DQN.pt")
-
-    def choose_action(self, state):
-        """
-        - Implement the action-choosing function.
-        - Choose the best action with given state and epsilon
-        Parameters:
-            self: the agent itself.
-            state: the current state of the enviornment.
-            (Don't pass additional parameters to the function.)
-            (All you need have been initialized in the constructor.)
-        Returns:
-            action: the chosen action.
-        """
-        with torch.no_grad():
-            # Begin your code
-            """
-            Generate a random number. If the number is bigger than epsilonreturn the index of the maximum Q of the given state in Q-table.
-        Or return random action.
-            """
-            temp = np.random.random()
-            if temp < math.exp(-1*self.epsilon) or temp < 0.005:
-                return np.random.randint(self.n_actions)
-            # forward the state to nn and find the argmax of the actions
-            
-            action = torch.argmax(self.evaluate_net(Tensor(state).reshape(48))).item()
-            # End your code
-        return action
-
-def train(env):
-    """
-    Train the agent on the given environment.
-    Paramenters:
-        env: the given environment.
-    Returns:
-        None (Don't need to return anything)
-    """
-    agent = Agent(env)
-    episode = 500
-    rewards = []
-    for i_episode in range(episode):
-        state = env.reset()
-        count = 0
-        while True:
-            count += 1
-            agent.count += 1
-            # env.render()
-            tempstate1 = state.reshape(48)
-            state = state.reshape(48)
-            for i in range(12):
-                for j in range(4):
-                    tempstate1[i*4+j] = (state[44+j] - state[4*i+j])/state[44+j]
-            action = agent.choose_action(tempstate1)
-            next_state, reward, done, info = env.step(action)
-            tempstate2 = next_state.reshape(48)
-            next_state = next_state.reshape(48)
-            for i in range(12):
-                for j in range(4):
-                    tempstate2[i*4+j] = (next_state[44+j] - next_state[4*i+j])/next_state[44+j]
-            agent.buffer.insert(tempstate1, int(action), reward, tempstate2, int(done))
-
-            if len(agent.buffer) >= 100:
-                agent.learn()
-            if done:
-                rewards.append(count)
-                break
-            state = next_state
-        print(i_episode, info)
-    total_rewards.append(rewards)
-
-
-def test(env):
-    """
-    Test the agent on the given environment.
-    Paramenters:
-        env: the given environment.
-    Returns:
-        None (Don't need to return anything)
-    """
-    rewards = []
-    testing_agent = Agent(env)
-    #testing_agent.target_net.load_state_dict(torch.load("Tables/DQN2850.pt"))
-    for _ in range(1):
-        state = env.reset().reshape(48)
-        while True:
-            tempstate = state
-            for i in range(12):
-                for j in range(4):
-                    tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-            Q = testing_agent.target_net(
-                torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
-            action = int(torch.argmax(Q).numpy())
-            next_state, _, done, _ = env.step(action)
-            if done:
-                break
-            state = next_state.reshape(48)
-
-    print(f"reward: {np.mean(rewards)}")
-    print(f"max Q:{testing_agent.check_max_Q()}")
-
-
-if __name__ == "__main__":
-    env = buildEnv.createEnv(2330) 
-    os.makedirs("./Tables", exist_ok=True)
-
-    # training section:
-    for i in range(2):
-        print(f"#{i + 1} training progress")
-        train(env)
-
-    # testing section:
-    test(env)
-    env.close()
-
-    os.makedirs("./Rewards", exist_ok=True)
-    np.save("./Rewards/DQN_rewards.npy", np.array(total_rewards))
\ No newline at end of file
diff --git a/Tables/DQN.pt b/Tables/DQN.pt
deleted file mode 100644
index 2aa0210..0000000
Binary files a/Tables/DQN.pt and /dev/null differ
diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
index 46c76ed..5646f0f 100644
--- a/Trajectory_Transformer/config/offline.py
+++ b/Trajectory_Transformer/config/offline.py
@@ -2,7 +2,7 @@ from trajectory.utils import watch
 
 #------------------------ base ------------------------#
 
-logbase = 'logs/'
+logbase = 'Trajectory_Transformer/scripts/logs'
 gpt_expname = 'gpt/azure'
 
 ## automatically make experiment names for planning
diff --git a/Trajectory_Transformer/environment.yml b/Trajectory_Transformer/environment.yml
deleted file mode 100644
index 19b5c9d..0000000
--- a/Trajectory_Transformer/environment.yml
+++ /dev/null
@@ -1,20 +0,0 @@
-name: trajectory
-channels:
-- defaults
-- conda-forge
-dependencies:
-- python=3.8
-- pip
-- patchelf
-- pip:
-    - -f https://download.pytorch.org/whl/torch_stable.html
-    - numpy
-    - gym==0.18.0
-    - mujoco-py==2.0.2.13
-    - matplotlib==3.3.4
-    - torch==1.9.1+cu111
-    - typed-argument-parser
-    - git+https://github.com/Farama-Foundation/d4rl@f2a05c0d66722499bf8031b094d9af3aea7c372b#egg=d4rl
-    - scikit-image==0.17.2
-    - scikit-video==1.1.11
-    - gitpython
diff --git a/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json b/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json
deleted file mode 100644
index df33154..0000000
--- a/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoIYaUUpQu"
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-    "config": "config.offline",
-    "dataset": "stock_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H4_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoEIaUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoFYaUUpQu"
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 4,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoGYaUUpQu"
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoJ4aUUpQu"
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
-        "time": "Tue May 16 17:20:15 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoOYaUUpQu"
-    },
-    "savepath": "logs/stock_2330/plans/defaults/freq1_H4_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCHZpc19mcmVxlEsyjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAhzZXRfc2VlZJRoAmgGaA2GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBCGlFKUjAZkZXZpY2WUjARjdWRhlIwKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAlwbGFuX2ZyZXGUSwGMBW1rZGlylGgCaAZoGYaUUpSMCHNhdmVwYXRolIwxbG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjgvMJSMB3ZlcmJvc2WUiIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwKYWRkX2V4dHJhc5RoAmgGaCGGlFKUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAdjZGZfb2JzlE6MC3JlYWRfY29uZmlnlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwFa19vYnOUSwGMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2xvZ2Jhc2WUjAVsb2dzL5SMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAdob3Jpem9ulEsEjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmg5hpRSlIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUjAVrX2FjdJROjAhuX2V4cGFuZJRLAowGc3VmZml4lIwBMJSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFdWJoDYaUUpQu"
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt b/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt
deleted file mode 100644
index 96b9122..0000000
--- a/Trajectory_Transformer/scripts/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt
+++ /dev/null
@@ -1,955 +0,0 @@
-diff --git a/DDPG.py b/DDPG.py
-index d682b97..c69f550 100644
---- a/DDPG.py
-+++ b/DDPG.py
-@@ -1,6 +1,3 @@
--from env.market import Market
--from helper.args_parser import model_launcher_parser
--from helper.data_logger import generate_algorithm_logger, generate_market_logger
- import sys
- import gym
- import numpy as np
-@@ -15,12 +12,15 @@ from torch.autograd import Variable
- import torch.optim.lr_scheduler as Scheduler
- import torch.nn.functional as F
- from torch.utils.tensorboard import SummaryWriter
-+from buildEnv import createEnv, MyStocksEnv
-+from torch.distributions import Categorical
- import logging
- #from skopt.space import Real, Integer
- #from skopt import gp_minimize
- logging.basicConfig(filename='train.log', level=logging.DEBUG)
- 
--
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- def soft_update(target, source, tau):
-     for target_param, param in zip(target.parameters(), source.parameters()):
-         target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
-@@ -153,46 +153,16 @@ class DDPG(object):
-         hard_update(self.actor_target, self.actor) 
-         hard_update(self.critic_target, self.critic)
- 
--    def get_stock_code_and_action(self, a, use_greedy=False, use_prob=False):
--        # Reshape a.
--        if not use_greedy:
--            a = a.reshape((-1,))
--            # Calculate action index depends on prob.
--            if use_prob:
--                # Generate indices.
--                a_indices = np.arange(a.shape[0])
--                # Get action index.
--                action_index = np.random.choice(a_indices, p=a)
--            else:
--                # Get action index.
--                action_index = np.argmax(a)
--        else:
--            if use_prob:
--                # Calculate action index
--                if np.random.uniform() < self.epsilon:
--                    action_index = np.floor(a).astype(int)
--                else:
--                    action_index = np.random.randint(0, self.action_space)
--            else:
--                # Calculate action index
--                action_index = np.floor(a).astype(int)
--
--        # Get action
--        action = action_index % 3
--        # Get stock index
--        stock_index = np.floor(action_index / 3).astype(np.int)
--        # Get stock code.
--        stock_code = self.env.codes[stock_index]
--
--        return stock_code, action, action_index
--
--    def select_action(self, state, action_noise=None):
-+
-+    def select_action(self, state, epsilon=0.0):
-         self.actor.eval()
--        mu = self.actor((Variable(state)))
--        mu = mu.data
--        noise = [0.0] if action_noise is None else action_noise.noise()
--        noise = torch.FloatTensor(noise)
--        return torch.clamp(mu + noise, min=0, max=1.0)
-+        probs = self.actor((Variable(state)))
-+        probs = probs.detach()
-+        m = Categorical(logits= probs)
-+        action = m.sample().item()
-+        if random.random() > epsilon:
-+            return self.env.action_space.sample()
-+        return action
- 
-     def update_parameters(self, batch):
-         state_batch = Variable(torch.cat([b.state for b in batch]))
-@@ -201,7 +171,6 @@ class DDPG(object):
-         mask_batch = Variable(torch.cat([b.mask for b in batch]))
-         next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
-         
--        ########## YOUR CODE HERE (10~20 lines) ##########
-         # Calculate policy loss and value loss
-         # Update the actor and the critic
-         q_v = self.critic(state_batch, action_batch)
-@@ -219,7 +188,6 @@ class DDPG(object):
-         self.actor_optim.zero_grad()
-         policy_loss.backward()
-         self.actor_optim.step()
--        ########## END OF YOUR CODE ########## 
- 
-         soft_update(self.actor_target, self.actor, self.tau)
-         soft_update(self.critic_target, self.critic, self.tau)
-@@ -248,9 +216,9 @@ class DDPG(object):
-         if critic_path is not None: 
-             self.critic.load_state_dict(torch.load(critic_path))
- 
--def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-+def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-     # Define a tensorboard writer
--    writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-+    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
- 
-     logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
-         lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
-@@ -276,9 +244,8 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-     total_numsteps = 0
-     updates = 0
- 
--    
--    agent = DDPG(num_inputs = env.data_dim,
--                 action_space = env.trader.action_space, 
-+    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
-+                 action_space = env.action_space.n, 
-                  env = env, 
-                  epsilon= epsilon,
-                  gamma = gamma, 
-@@ -288,15 +255,15 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 lr_c= lr_c, 
-                 lr_a_decay= lr_a_decay, 
-                 lr_c_decay = lr_c_decay)
--    ounoise = OUNoise(env.trader.action_space)
-+    #ounoise = OUNoise(env.action_space)
-     memory = ReplayMemory(replay_size)
-     
-     for i_episode in range(num_episodes):
-         
--        ounoise.scale = noise_scale
--        ounoise.reset()
-+        #ounoise.scale = noise_scale
-+        #ounoise.reset()
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
- 
-         episode_reward = 0
-         val_loss = []
-@@ -308,10 +275,9 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             # 2. Push the sample to the replay buffer
-             # 3. Update the actor and the critic
-             total_numsteps+=1
--            action = agent.select_action(state, ounoise)
--            code, action, a_index= agent.get_stock_code_and_action(action, use_greedy=False, use_prob=True)
--            next_state, reward, done, _ = env.forward(code, action)
--            next_state = torch.Tensor([next_state])
-+            action = agent.select_action(state, epsilon)
-+            next_state, reward, done, info = env.step(action)
-+            next_state = torch.Tensor([next_state.reshape(-1)])
-             memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
-             if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
-                 batch = memory.sample(batch_size)
-@@ -320,7 +286,7 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 act_loss.append(a_loss)
-             episode_reward += reward
-             state = next_state
--            if done == env.Done:
-+            if done:
-                 break
-             ########## END OF YOUR CODE ########## 
-         
-@@ -330,23 +296,24 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-         critic_loss = np.mean(val_loss)
-         t = 0
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
-         episode_reward = 0
-         while True:
-             action = agent.select_action(state)
- 
--            next_state, reward, done, _ = env.step(action.numpy()[0])
-+            next_state, reward, done, info = env.step(action)
-             
-             #env.render()
-             
-             episode_reward += reward
- 
--            next_state = torch.Tensor([next_state])
-+            next_state = torch.Tensor([next_state.reshape(-1)])
- 
-             state = next_state
-             
-             t += 1
-             if done:
-+                print(info)
-                 break
- 
-         rewards.append(episode_reward)
-@@ -358,36 +325,22 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
- 
-         #Logging
--        writer.add_scalar('Reward', episode_reward, i_episode)
--        writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
--        writer.add_scalar('Critic loss', critic_loss, i_episode)
--        writer.add_scalar('Actor loss', actor_loss, i_episode)
--
--        if ewma_reward >= 120:
--            agent.save_model(env_name, '.pth')
--            logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--            #break
--            return (ewma_reward+500)/(i_episode+1) #For tuning
-+        #writer.add_scalar('Reward', episode_reward, i_episode)
-+        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
-+        #writer.add_scalar('Critic loss', critic_loss, i_episode)
-+        #writer.add_scalar('Actor loss', actor_loss, i_episode)
-+
-+        #if ewma_reward >= 120:
-+        #    agent.save_model(env_name, '.pth')
-+        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-+        #    #break
-+        #    return (ewma_reward+500)/(i_episode+1) #For tuning
-     
-     agent.save_model(env_name, '.pth')  
-     logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-     return (ewma_reward+500)/(i_episode+1) #For tuning
- 
- def main():
--    """
--    Market environment args 
--    """
--    #mode = args.mode
--    mode = 'test'
--    # codes = args.codes
--    codes = ["2303"]
--    # market = args.market
--    market = 'stock'
--    # episode = args.episode
--    episode = 1000
--    training_data_ratio = 0.95
--    # training_data_ratio = args.training_data_ratio
--
-     """
-     Training args
-     """
-@@ -398,14 +351,8 @@ def main():
-     noise_scale_ = 0.3
-     batch_size_ = 64
- 
--    model_name = os.path.basename(__file__).split('.')[0]
- 
--    env = Market(codes, start_date="2012-01-01", end_date="2018-01-01", **{
--        "market": market,
--        "mix_index_state": False,
--        "logger": generate_market_logger(model_name),
--        "training_data_ratio": training_data_ratio,
--    })
-+    env = createEnv(2330)
- 
-     train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
- if __name__ == '__main__':
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 9a7a974..f6720ba 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -57,7 +57,7 @@ base = {
-         'renderer': 'Renderer',
- 
-         'plan_freq': 1,
--        'horizon': 15,
-+        'horizon': 4,
-         'beam_width': 128,
-         'n_expand': 2,
- 
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index f06654a..235e6e8 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -12,15 +12,19 @@ parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
- sys.path.insert(0, parent_dir)
- import trajectory.utils as utils
- import trajectory.datasets as datasets
-+from trajectory.datasets.Random.buildEnv import createEnv
- from trajectory.search import (
-     beam_plan,
-     make_prefix,
-     extract_actions,
-     update_context,
- )
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '3'
- 
-+code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stock_'+code
-     config: str = 'config.offline'
- 
- #######################
-@@ -43,7 +47,8 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
- ####### dataset #######
- #######################
- 
--env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
-+
-+env = createEnv(code)
- #renderer = utils.make_renderer(args)
- timer = utils.timer.Timer()
- 
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index 6ef5569..bb35461 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stocks-v0_r'
-+    dataset: str = 'stock_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 5000
-+n_epochs = 10000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index 659bd84..28c9f58 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -5,9 +5,12 @@ from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
- import matplotlib.pyplot as plt
- import numpy as np
- import pickle
-+import os
-+import sys
-+from buildEnv import createEnv
- 
--quat_type = "stocks-v0"
--env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-+quat_type = 2330
-+env = createEnv(2330)
- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- 
- action_dim = env.action_space.n
-@@ -20,11 +23,11 @@ for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals'
- for _ in range(episode):
-     observation = env.reset()
-     while True:
--        action = np.random.rand(action_dim)
--        next_observation, reward, done, _ = env.step(np.argmax(action))
-+        action = env.action_space.sample()
-+        next_observation, reward, done, _ = env.step(action)
-         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
-         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--        episode_data['actions'].append(action)
-+        episode_data['actions'].append(np.array([action]))
-         episode_data['rewards'].append(np.array([reward]).astype('float32'))
-         episode_data['terminals'].append(done)
-         if done:
-@@ -32,5 +35,5 @@ for _ in range(episode):
- 
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
-+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
-     pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 4525194..bd75e78 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -44,7 +44,7 @@ def segment(observations, terminals, max_path_length):
- 
- class SequenceDataset(torch.utils.data.Dataset):
- 
--    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=1000, penalty=None, device='cuda:0'):
-+    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=2000, penalty=None, device='cuda:0'):
-         print(f'[ datasets/sequence ] Sequence length: {sequence_length} | Step: {step} | Max path length: {max_path_length}')
-         #self.env = env = load_environment(env) if type(env) is str else env
-         self.sequence_length = sequence_length
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-index 6c69f6b..c30ee70 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-@@ -1,244 +1,71 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 1dd7eb6..98c4875 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -17,7 +17,7 @@ args_to_watch = [
-- base = {
-- 
--     'train': {
---        'N': 100,
--+        'N': 20,
--         'discount': 0.99,
--         'n_layer': 4,
--         'n_head': 4,
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index 881688c..f06654a 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -1,10 +1,15 @@
-- import json
-- import pdb
--+import os
--+import sys
-- from os.path import join
-- import gym
-- import gym_anytrading
--+import numpy as np
-- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
-- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.search import (
--@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- #######################
-- 
-- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
---renderer = utils.make_renderer(args)
--+#renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
-- discretizer = dataset.discretizer
--@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
-- action_dim = dataset.action_dim
-- 
-- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
---preprocess_fn = datasets.get_preprocess_fn(env.name)
--+#preprocess_fn = datasets.get_preprocess_fn(env.name)
-- 
-- #######################
-- ###### main loop ######
--@@ -63,10 +68,11 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = env.max_episode_steps
--+T = 1000000
-- for t in range(T):
-- 
---    observation = preprocess_fn(observation)
--+    #observation = preprocess_fn(observation)
--+    observation = observation.reshape(-1)
-- 
--     if t % args.plan_freq == 0:
--         ## concatenate previous transitions and current observations to input to model
--@@ -90,18 +96,18 @@ for t in range(T):
--     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
-- 
--     ## execute action in environment
---    next_observation, reward, terminal, _ = env.step(action)
--+    next_observation, reward, terminal, info = env.step(np.argmax(action))
-- 
--     ## update return
--     total_reward += reward
---    score = env.get_normalized_score(total_reward)
--+    #score = env.get_normalized_score(total_reward)
-- 
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-- 
--     print(
---        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
--+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
-- 
--@@ -114,11 +120,13 @@ for t in range(T):
--     #    ## save rollout thus far
--     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
-- 
---    if terminal: break
--+    if terminal: 
--+        print(info)
--+        break
-- 
--     observation = next_observation
-- 
-- ## save result as a json file
-- json_path = join(args.savepath, 'rollout.json')
---json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
-- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index ddcda7a..9a2273b 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -2,11 +2,17 @@ import os
-- import numpy as np
-- import torch
-- import pdb
--+import sys
--+
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- 
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.models.transformers import GPT
-- 
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
--     dataset: str = 'forex-v0'
--@@ -31,7 +37,7 @@ dataset_config = utils.Config(
--     savepath=(args.savepath, 'data_config.pkl'),
--     env=args.dataset,
--     N=args.N,
---    penalty=args.termination_penalty,
--+    penalty=None,
--     sequence_length=sequence_length,
--     step=args.step,
--     discount=args.discount,
--@@ -104,7 +110,8 @@ trainer = trainer_config()
-- #######################
-- 
-- ## scale number of epochs to keep number of updates constant
---n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+n_epochs = 3000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
--deleted file mode 100644
--index fa97c75..0000000
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 71bfb7e..bbd08e4 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-- action_dim = env.action_space.n
-- 
-- episode = 10
---
--+T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = []
--@@ -25,13 +25,12 @@ for _ in range(episode):
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--         episode_data['actions'].append(action)
---        episode_data['rewards'].append(np.array(reward).astype('float32'))
--+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--             break
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---
---with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
--diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
--index 69ee58d..d1062c5 100644
----- a/Trajectory_Transformer/trajectory/datasets/__init__.py
--+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
--@@ -1,3 +1,3 @@
---from .d4rl import load_environment
--+#from .d4rl import load_environment
-- from .sequence import *
-- from .preprocessing import get_preprocess_fn
--diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index c23b4f3..4525194 100644
----- a/Trajectory_Transformer/trajectory/datasets/sequence.py
--+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
--         self.device = device
--         
--         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
---        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
--+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
--             dataset = pickle.load(f)
--         print('✓')
-- 
--@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
--         terminals = dataset['terminals']
--         realterminals = [False]*len(dataset['terminals'])
-- 
---        #observations = np.reshape(observations, (100, 7000))
--         self.observations_raw = observations
--         self.actions_raw = actions
--         self.next_observations_raw = next_observations
--diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
--index 7c596c3..7529384 100644
----- a/Trajectory_Transformer/trajectory/utils/__init__.py
--+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
--@@ -2,7 +2,7 @@ from .setup import Parser, watch
-- from .arrays import *
-- from .serialization import *
-- from .progress import Progress, Silent
---from .rendering import make_renderer
--+#from .rendering import make_renderer
-- # from .video import *
-- from .config import Config
-- from .training import Trainer
--diff --git a/requirements.txt b/requirements.txt
--index ece16ed..a579177 100644
----- a/requirements.txt
--+++ b/requirements.txt
--@@ -1,14 +1,16 @@
-- numpy
-- gym
-- numpy
---torch
--+pytorch==1.12.1
--+torchvision==0.13.1 
--+torchaudio==0.12.1
-- transformers==4.5.1
-- wandb==0.9.1
-- tensorboard
-- pyprind
-- tensorflow
-- gin-config
---gym
--+gym==0.21.0
-- tqdm
-- blosc
-- git+https://github.com/google/dopamine.git
-\ No newline at end of file
-+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+index f42cef8..0e84897 100644
-+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+@@ -1,23 +1,23 @@
-+ {
-+     "add_extras": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+     },
-+     "beam_width": 128,
-+     "cdf_act": 0.6,
-+     "cdf_obs": null,
-+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "config": "config.offline",
-+     "dataset": "forex-v0",
-+     "device": "cuda",
-+     "exp_name": "plans/defaults/freq1_H15_beam128",
-+     "generate_exp_name": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+     },
-+     "get_commit": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+     },
-+     "gpt_epoch": "latest",
-+     "gpt_loadpath": "gpt/azure",
-+@@ -28,7 +28,7 @@
-+     "max_context_transitions": 5,
-+     "mkdir": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+     },
-+     "n_expand": 2,
-+     "percentile": "mean",
-+@@ -37,24 +37,24 @@
-+     "prefix_context": true,
-+     "read_config": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+     },
-+     "renderer": "Renderer",
-+     "reproducibility": {
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "git_has_uncommitted_changes": true,
-+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-+-        "time": "Sun May 14 00:30:59 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-++        "time": "Tue May 16 00:22:08 2023"
-+     },
-+     "save_diff": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+     },
-+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "set_seed": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+     },
-+     "suffix": "0",
-+     "verbose": true,
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
-deleted file mode 100644
-index 59fc81f..0000000
---- a/logs/stocks-v0_r/gpt/azure/args.json
-+++ /dev/null
-@@ -1,65 +0,0 @@
--{
--    "N": 20,
--    "action_weight": 5,
--    "add_extras": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
--    },
--    "attn_pdrop": 0.1,
--    "batch_size": 64,
--    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
--    "config": "config.offline",
--    "dataset": "stocks-v0_r",
--    "device": "cuda",
--    "discount": 0.99,
--    "discretizer": "QuantileDiscretizer",
--    "embd_pdrop": 0.1,
--    "exp_name": "gpt/azure",
--    "generate_exp_name": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
--    },
--    "get_commit": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
--    },
--    "learning_rate": 0.0006,
--    "logbase": "logs/",
--    "lr_decay": true,
--    "mkdir": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
--    },
--    "n_embd": 32,
--    "n_epochs_ref": 50,
--    "n_head": 4,
--    "n_layer": 4,
--    "n_saves": 3,
--    "read_config": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
--    },
--    "reproducibility": {
--        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
--        "git_has_uncommitted_changes": true,
--        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
--        "time": "Mon May 15 17:39:32 2023"
--    },
--    "resid_pdrop": 0.1,
--    "reward_weight": 1,
--    "save_diff": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
--    },
--    "savepath": "logs/stocks-v0_r/gpt/azure",
--    "seed": 42,
--    "set_seed": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
--    },
--    "step": 1,
--    "subsampled_sequence_length": 10,
--    "termination_penalty": -100,
--    "value_weight": 1
--}
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
-deleted file mode 100644
-index f2b7eea..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
-deleted file mode 100644
-index 7d861b1..0000000
---- a/logs/stocks-v0_r/gpt/azure/diff.txt
-+++ /dev/null
-@@ -1,59 +0,0 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 98c4875..9a7a974 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -29,7 +29,7 @@ base = {
--         'device': 'cuda',
-- 
--         'n_embd': 32,
---        'batch_size': 256,
--+        'batch_size': 64,
--         'learning_rate': 6e-4,
--         'lr_decay': True,
--         'seed': 42,
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 9a2273b..6ef5569 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stocks-v0_r'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 3000
--+n_epochs = 5000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
--index 506330f..e08063c 100644
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index bbd08e4..659bd84 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
-- 
---quat_type = "forex-v0"
---env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = "stocks-v0"
--+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
-- 
---episode = 10
--+episode = 100
-- T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
-deleted file mode 100644
-index db868c9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
-deleted file mode 100644
-index aaacded..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
-deleted file mode 100644
-index c3fe2b4..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
-deleted file mode 100644
-index f13edba..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
-deleted file mode 100644
-index 5531c7d..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
-deleted file mode 100644
-index 090ede9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
-diff --git a/old_env/trader.py b/old_env/trader.py
-index 7937f12..6b2f29c 100644
---- a/old_env/trader.py
-+++ b/old_env/trader.py
-@@ -4,7 +4,7 @@ import math
- 
- from time import time
- from enum import Enum
--from env.position import Position
-+from position import Position
- 
- 
- class ActionCode(Enum):
\ No newline at end of file
diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
index b2cfabd..565f323 100644
--- a/Trajectory_Transformer/scripts/train.py
+++ b/Trajectory_Transformer/scripts/train.py
@@ -12,10 +12,10 @@ import trajectory.datasets as datasets
 from trajectory.models.transformers import GPT
 
 os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-os.environ["CUDA_VISIBLE_DEVICES"] = '0'
+os.environ["CUDA_VISIBLE_DEVICES"] = '3'
 
 class Parser(utils.Parser):
-    dataset: str = 'DDQN_1_2330'
+    dataset: str = 'stock_2330'
     config: str = 'config.offline'
 
 #######################
@@ -111,19 +111,19 @@ trainer = trainer_config()
 
 ## scale number of epochs to keep number of updates constant
 #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
-n_epochs = 3000
-save_freq = int(n_epochs // args.n_saves)
+n_epochs = 1000
+save_freq = 10
 
-for epoch in range(n_epochs):
+for epoch in range(1, n_epochs+1):
     print(f'\nEpoch: {epoch} / {n_epochs} | {args.dataset} | {args.exp_name}')
 
     trainer.train(model, dataset)
 
     ## get greatest multiple of `save_freq` less than or equal to `save_epoch`
-    save_epoch = (epoch + 1) // save_freq * save_freq
-    statepath = os.path.join(args.savepath, f'state_{save_epoch}.pt')
-    print(f'Saving model to {statepath}')
+    if epoch % save_freq == 0:
+        statepath = os.path.join(args.savepath, f'state_{epoch}.pt')
+        print(f'Saving model to {statepath}')
 
-    ## save state to disk
-    state = model.state_dict()
-    torch.save(state, statepath)
+        ## save state to disk
+        state = model.state_dict()
+        torch.save(state, statepath)
diff --git a/Trajectory_Transformer/trajectory/datasets/Random/buildEnv.py b/Trajectory_Transformer/trajectory/datasets/Random/buildEnv.py
index d788c38..b5f6362 100644
--- a/Trajectory_Transformer/trajectory/datasets/Random/buildEnv.py
+++ b/Trajectory_Transformer/trajectory/datasets/Random/buildEnv.py
@@ -75,6 +75,14 @@ class MyStocksEnv(StocksEnv):
         return ismax, ismin
 
 
+def state_preprocess(state):
+    state = state.reshape(-1)
+    tempstate = state
+    for i in range(12):
+        for j in range(4):
+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
+    return tempstate
+
 def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
     csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
     data = pd.read_csv(csv_name)
diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
index 122adaf..50ae3d7 100644
--- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
@@ -7,7 +7,7 @@ import numpy as np
 import pickle
 import os
 import sys
-from buildEnv import createEnv
+from buildEnv import createEnv, state_preprocess
 
 quat_type = 2330
 env = createEnv(2330)
@@ -15,17 +15,20 @@ env = createEnv(2330)
 
 action_dim = env.action_space.n
 
-episode = 100
+episode = 10
 T = 0
 episode_data = {}
 for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
     episode_data[k] = []
-for _ in range(episode):
+for e in range(episode):
+    env.seed(e)
     observation = env.reset()
+    observation = state_preprocess(observation)
     while True:
         probs = np.random.rand(action_dim)
         action = np.random.choice(2, p=probs/np.sum(probs))
         next_observation, reward, done, _ = env.step(action)
+        next_observation = state_preprocess(next_observation)
         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
         episode_data['actions'].append(probs)
diff --git a/Trajectory_Transformer/trajectory/datasets/Random/stock_2330.pkl b/Trajectory_Transformer/trajectory/datasets/Random/stock_2330.pkl
index 165dedd..a25c541 100644
Binary files a/Trajectory_Transformer/trajectory/datasets/Random/stock_2330.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/stock_2330.pkl differ
diff --git a/buildEnv.py b/buildEnv.py
index d788c38..2065a16 100644
--- a/buildEnv.py
+++ b/buildEnv.py
@@ -74,6 +74,12 @@ class MyStocksEnv(StocksEnv):
                     ismin = False
         return ismax, ismin
 
+def state_preprocess(state):
+    tempstate = state
+    for i in range(12):
+        for j in range(4):
+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
+    return tempstate
 
 def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
     csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
diff --git a/gen_DQN_data.py b/gen_DQN_data.py
index 6e1288a..6901db6 100644
--- a/gen_DQN_data.py
+++ b/gen_DQN_data.py
@@ -8,5 +8,20 @@ stock = 2330
 env = createEnv(2330)
 
 data = gen_offline_data(episodes, env)
+
+for _ in range(episodes):
+    observation = env.reset()
+    while True:
+        probs = np.random.rand(2)
+        action = np.random.choice(2, p=probs/np.sum(probs))
+        next_observation, reward, done, _ = env.step(action)
+        data['observations'].append(observation.reshape(-1).astype('float32'))
+        data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
+        data['actions'].append(probs)
+        data['rewards'].append(np.array([reward]).astype('float32'))
+        data['terminals'].append(done)
+        if done:
+            break
+
 with open('Trajectory_Transformer/trajectory/datasets/Medium/DDQN_{}_{}'.format(episodes, stock) + '.pkl', 'wb') as f:
     pickle.dump(data, f)
diff --git a/logs/DDPG-20230509145837-stock_market.log b/logs/DDPG-20230509145837-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509145915-stock_market.log b/logs/DDPG-20230509145915-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150100-stock_market.log b/logs/DDPG-20230509150100-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150257-stock_market.log b/logs/DDPG-20230509150257-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150435-stock_market.log b/logs/DDPG-20230509150435-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150605-stock_market.log b/logs/DDPG-20230509150605-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150751-stock_market.log b/logs/DDPG-20230509150751-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDPG-20230509150840-stock_market.log b/logs/DDPG-20230509150840-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/DDQN_1_2330/gpt/azure/args.json b/logs/DDQN_1_2330/gpt/azure/args.json
deleted file mode 100644
index 92a2476..0000000
--- a/logs/DDQN_1_2330/gpt/azure/args.json
+++ /dev/null
@@ -1,65 +0,0 @@
-{
-    "N": 20,
-    "action_weight": 5,
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmgwhpRSlC4="
-    },
-    "attn_pdrop": 0.1,
-    "batch_size": 64,
-    "commit": "c38fed077310b11b3ed50a9137bef173cac138df main",
-    "config": "config.offline",
-    "dataset": "DDQN_1_2330",
-    "device": "cuda",
-    "discount": 0.99,
-    "discretizer": "QuantileDiscretizer",
-    "embd_pdrop": 0.1,
-    "exp_name": "gpt/azure",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmgzhpRSlC4="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmgqhpRSlC4="
-    },
-    "learning_rate": 0.0006,
-    "logbase": "logs/",
-    "lr_decay": true,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmgnhpRSlC4="
-    },
-    "n_embd": 32,
-    "n_epochs_ref": 50,
-    "n_head": 4,
-    "n_layer": 4,
-    "n_saves": 3,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1Ymg+hpRSlC4="
-    },
-    "reproducibility": {
-        "command_line": "python Trajectory_Transformer/scripts/train.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/c38fed077310b11b3ed50a9137bef173cac138df",
-        "time": "Sun May 28 21:00:00 2023"
-    },
-    "resid_pdrop": 0.1,
-    "reward_weight": 1,
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmgPhpRSlC4="
-    },
-    "savepath": "logs/DDQN_1_2330/gpt/azure",
-    "seed": 42,
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMAU6USxSMCGxyX2RlY2F5lIiMCHNhdmVwYXRolIwabG9ncy9ERFFOXzFfMjMzMC9ncHQvYXp1cmWUjAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMCXNhdmVfZGlmZpRoAmgGaA+GlFKUjApiYXRjaF9zaXpllEtAjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDG5fZXBvY2hzX3JlZpRLMowGbl9oZWFklEsEjA1hY3Rpb25fd2VpZ2h0lEsFjAx2YWx1ZV93ZWlnaHSUSwGMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowHbl9sYXllcpRLBIwEc3RlcJRLAYwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmF0dG5fcGRyb3CURz+5mZmZmZmajAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCHNldF9zZWVklGgCaAZoIYaUUpSMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MBW1rZGlylGgCaAZoJ4aUUpSMCmdldF9jb21taXSUaAJoBmgqhpRSlIwEc2VlZJRLKowGbl9lbWJklEsgjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwKYWRkX2V4dHJhc5RoAmgGaDCGlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDOGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhkaXNjb3VudJRHP++uFHrhR66MB2RhdGFzZXSUjAtERFFOXzFfMjMzMJSMDXJld2FyZF93ZWlnaHSUSwGMB2xvZ2Jhc2WUjAVsb2dzL5SMC3JlYWRfY29uZmlnlGgCaAZoPoaUUpR1YmghhpRSlC4="
-    },
-    "step": 1,
-    "subsampled_sequence_length": 10,
-    "termination_penalty": -100,
-    "value_weight": 1
-}
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/gpt/azure/data_config.pkl b/logs/DDQN_1_2330/gpt/azure/data_config.pkl
deleted file mode 100644
index 57efab1..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/data_config.pkl and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/diff.txt b/logs/DDQN_1_2330/gpt/azure/diff.txt
deleted file mode 100644
index 681ef99..0000000
--- a/logs/DDQN_1_2330/gpt/azure/diff.txt
+++ /dev/null
@@ -1,622 +0,0 @@
-diff --git a/DDQN.py b/DDQN.py
-index 2e34be3..6b01dd9 100644
---- a/DDQN.py
-+++ b/DDQN.py
-@@ -277,6 +277,37 @@ def test(env):
-     print(env._total_profit)
-     print(env._total_reward)
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
-+
-+def gen_offline_data(episodes, env):
-+    agent = Agent(env)
-+    agent.target_net.load_state_dict(torch.load("./Tables/DDQN.pt"))
-+    episode_data = {}
-+    for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-+        episode_data[k] = []
-+    for _ in range(episodes):
-+        observation = env.reset()
-+        observation = state_preprocess(observation.reshape(-1))
-+        while True:
-+            Q = agent.target_net.forward(torch.FloatTensor(observation)).squeeze(0).detach()
-+            action = int(torch.argmax(Q).numpy())
-+            next_observation, reward, done, info = env.step(action)
-+            episode_data['observations'].append(np.array(observation))
-+            next_observation = state_preprocess(next_observation.reshape(-1))
-+            episode_data['next_observations'].append(np.array(next_observation))
-+            episode_data['actions'].append(np.array(Q))
-+            episode_data['rewards'].append(np.array([reward]).astype('float32'))
-+            episode_data['terminals'].append(np.array([done]))
-+            observation = next_observation
-+            if done:
-+                print(info)
-+                break
-+    return episode_data
- 
- if __name__ == "__main__":
-     env = buildEnv.createEnv(2330)        
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 73c5b28..70300f8 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -57,8 +57,8 @@ base = {
-         'renderer': 'Renderer',
- 
-         'plan_freq': 1,
--        'horizon': 10,
--        'beam_width': 128,
-+        'horizon': 2,
-+        'beam_width': 32,
-         'n_expand': 2,
- 
-         'k_obs': 1,
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index 8979c32..0b5cd38 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -20,11 +20,11 @@ from trajectory.search import (
-     update_context,
- )
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '3'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'stock_'+code
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -67,17 +67,28 @@ value_fn = lambda x: discretizer.value_fn(x, args.percentile)
- observation = env.reset()
- total_reward = 0
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
- ## observations for rendering
-+observation = observation.reshape(-1)
-+observation = state_preprocess(observation)
- rollout = [observation.copy()]
- 
- ## previous (tokenized) transitions for conditioning transformer
- context = []
- 
-+
-+
- T = 1187
- for t in range(T):
- 
-     #observation = preprocess_fn(observation)
--    observation = observation.reshape(-1)
-+    #observation = observation.reshape(-1)
-+    #observation = state_preprocess(observation)
- 
-     if t % args.plan_freq == 0:
-         ## concatenate previous transitions and current observations to input to model
-@@ -108,6 +119,7 @@ for t in range(T):
-     #score = env.get_normalized_score(total_reward)
- 
-     ## update rollout observations and context transitions
-+    next_observation = state_preprocess(next_observation.reshape(-1))
-     rollout.append(next_observation.copy())
-     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-     print(
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index bb35461..b2cfabd 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -12,10 +12,10 @@ import trajectory.datasets as datasets
- from trajectory.models.transformers import GPT
- 
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stock_2330'
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 10000
-+n_epochs = 3000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py b/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-deleted file mode 100644
-index 2e34be3..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-+++ /dev/null
-@@ -1,294 +0,0 @@
--import torch
--import torch.nn as nn
--import torch.nn.functional as F
--import numpy as np
--import gym
--import random
--from collections import deque
--from torch import Tensor
--import os
--from tqdm import tqdm
--import buildEnv
--import math
--import math
--total_rewards = []
--
--
--class replay_buffer():
--    '''
--    A deque storing trajectories
--    '''
--    def __init__(self, capacity):
--        self.capacity = capacity  # the size of the replay buffer
--        self.memory = deque(maxlen=capacity)  # replay buffer itself
--
--    def insert(self, state, action, reward, next_state, done):
--        '''
--        Insert a sequence of data gotten by the agent into the replay buffer.
--        Parameter:
--            state: the current state
--            action: the action done by the agent
--            reward: the reward agent got
--            next_state: the next state
--            done: the status showing whether the episode finish        
--        Return:
--            None
--        '''
--        
--        self.memory.append([state, action, reward, next_state.reshape(48), done])
--
--    def sample(self, batch_size):
--        '''
--        Sample a batch size of data from the replay buffer.
--        Parameter:
--            batch_size: the number of samples which will be propagated through the neural network
--        Returns:
--            observations: a batch size of states stored in the replay buffer
--            actions: a batch size of actions stored in the replay buffer
--            rewards: a batch size of rewards stored in the replay buffer
--            next_observations: a batch size of "next_state"s stored in the replay buffer
--            done: a batch size of done stored in the replay buffer
--        '''
--        batch = random.sample(self.memory, batch_size)
--        observations, actions, rewards, next_observations, done = zip(*batch)
--        return observations, actions, rewards, next_observations, done
--
--    def __len__(self):
--        return len(self.memory)
--
--
--class Net(nn.Module):
--    '''
--    The structure of the Neural Network calculating Q values of each state.
--    '''
--    def __init__(self,  num_actions, hidden_layer_size=600):
--        super(Net, self).__init__()
--        self.input_state = 48  # the dimension of state space
--        self.num_actions = num_actions  # the dimension of action space
--        self.fc1 = nn.Linear(self.input_state, 32*12)  # input layer
--        self.fc2 = nn.Linear(32*12, hidden_layer_size)  # hidden layer
--        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)
--        self.fc4 = nn.Linear(hidden_layer_size, num_actions)  # output layer
--
--    def forward(self, states):
--        '''
--        Forward the state to the neural network.        
--        Parameter:
--            states: a batch size of states
--        Return:
--            q_values: a batch size of q_values
--        '''
--        x = F.relu(self.fc1(states))
--        x = F.relu(self.fc2(x))
--        x = F.relu(self.fc3(x))
--        q_values = self.fc4(x)
--        return q_values
--
--
--class Agent():
--    def __init__(self, env, epsilon=10, learning_rate=0.0002, GAMMA=0.97, batch_size=32, capacity=10000):
--        """
--        The agent learning how to control the action of the cart pole.
--        Hyperparameters:
--            epsilon: Determines the explore/expliot rate of the agent
--            learning_rate: Determines the step size while moving toward a minimum of a loss function
--            GAMMA: the discount factor (tradeoff between immediate rewards and future rewards)
--            batch_size: the number of samples which will be propagated through the neural network
--            capacity: the size of the replay buffer/memory
--        """
--        self.env = env
--        self.n_actions = 2  # the number of actions
--        self.count = 0
--
--        self.epsilon = epsilon
--        self.learning_rate = learning_rate
--        self.gamma = GAMMA
--        self.batch_size = batch_size
--        self.capacity = capacity
--
--        self.buffer = replay_buffer(self.capacity)
--        self.evaluate_net = Net(self.n_actions)  # the evaluate network
--        self.target_net = Net(self.n_actions)  # the target network
--        self.optimizer = torch.optim.Adam(
--            self.evaluate_net.parameters(), lr=self.learning_rate)  # Adam is a method using to optimize the neural network
--
--    def learn(self):
--        '''
--        - Implement the learning function.
--        - Here are the hints to implement.
--        Steps:
--        -----
--        1. Update target net by current net every 100 times. (we have done this for you)
--        2. Sample trajectories of batch size from the replay buffer.
--        3. Forward the data to the evaluate net and the target net.
--        4. Compute the loss with MSE.
--        5. Zero-out the gradients.
--        6. Backpropagation.
--        7. Optimize the loss function.
--        -----
--        Parameters:
--            self: the agent itself.
--            (Don't pass additional parameters to the function.)
--            (All you need have been initialized in the constructor.)
--        Returns:
--            None (Don't need to return anything)
--        '''
--        if self.count % 10 == 0:
--            self.target_net.load_state_dict(self.evaluate_net.state_dict())
--
--        # Begin your code
--        # TODO
--        # Step2: Sample the data stored in the buffer and store them into data type Tensor 
--        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)
--        states = torch.tensor(np.array(states), dtype=torch.float)
--        actions = torch.tensor(np.array(actions), dtype=torch.int64).unsqueeze(-1)
--        rewards = torch.tensor(np.array(rewards), dtype=torch.float)
--        next_states = torch.tensor(np.array(next_states), dtype=torch.float)
--        dones = torch.tensor(np.array(dones), dtype=torch.float)
--
--        # Step3: Forward the data to the evaluate net and the target net with a few adjustment of the size
--        
--        q_values = torch.gather(self.evaluate_net(states), 1, actions)
--        
--        next_actions = self.evaluate_net(next_states).argmax(dim=1, keepdim=True)
--        next_q_values = self.target_net(next_states).gather(1, next_actions).reshape(32)
--        target_q_values = (rewards + self.gamma * (1 - dones) * next_q_values).unsqueeze(1)
--        # Step4: Compute the loss with MSE.
--        loss = F.mse_loss(q_values, target_q_values)
--        
--        # Step5: Zero-out the gradients.
--        self.optimizer.zero_grad()
--
--        # Step6: Backpropagation.
--        loss.backward()
--        # Step7: Optimize the loss function.
--        self.optimizer.step()
--        
--            
--        # End your code
--        
--
--
--    def choose_action(self, state):
--
--        with torch.no_grad():
--            # Begin your code
--            # TODO
--            temp = np.random.random()
--            if temp < math.exp(-1*self.epsilon) or temp<0.005:
--                return np.random.randint(self.n_actions)
--            # forward the state to nn and find the argmax of the actions
--            
--            action = torch.argmax(self.evaluate_net(Tensor(state).reshape(48))).item()
--            # End your code
--        return action
--
--
--def train(env):
--    """
--    Train the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    agent = Agent(env)
--    #agent.target_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    #agent.evaluate_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    episode = 150
--    rewards = []
--    cnt = 0
--    for _ in tqdm(range(episode)):
--        cnt += 1
--        state = env.reset()
--        #print(state)
--        count0 = 0
--        count1 = 0
--        while True:
--            agent.count += 1
--            #env.render()
--            tempstate1 = state.reshape(48)
--            state = state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate1[i*4+j] = (state[44+j] - state[4*i+j])/state[44+j]
--            action = agent.choose_action(tempstate1)
--            next_state, reward, done, _ = env.step(action)
--            tempstate2 = next_state.reshape(48)
--            next_state = next_state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate2[i*4+j] = (next_state[44+j] - next_state[4*i+j])/next_state[44+j]
--            agent.buffer.insert(tempstate1, int(action), reward, tempstate2, int(done))
--            if(action==1):
--                count1 += 1
--            else:
--                count0 += 1
--            if len(agent.buffer) >= 100:
--                agent.learn()
--            if done:
--                rewards.append(env._total_reward)
--                #print("!")
--                #print(count0)
--                #print(count1)
--                #print(agent.env._total_reward)
--                #print(agent.env._total_profit)
--                break
--            state = next_state
--        agent.epsilon += 0.1
--        
--        if(cnt % 50 ==0):
--            url = "Tables/DDQN"+str(cnt+3850)+".pt"
--            url2 = "Rewards/DDQN_rewards_iter2_new"+str(cnt+3850)+".npy"
--            try:
--                np.save(url2, np.array(rewards))
--                print(".np saved at "+url2)
--            except RuntimeError:
--                print("!!")  
--            try:
--                torch.save(agent.target_net.state_dict(), url)
--            except RuntimeError:
--                print("!!!")
--
--def test(env):
--    """
--    Test the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    testing_agent = Agent(env)
--    testing_agent.target_net.load_state_dict(torch.load("Tables/DDQN2850.pt"))
--    for _ in range(1):
--        state = env.reset().reshape(48)
--        while True:
--            tempstate = state
--            for i in range(12):
--                for j in range(4):
--                    tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
--            Q = testing_agent.target_net(
--                torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--            action = int(torch.argmax(Q).numpy())
--            next_state, _, done, _ = env.step(action)
--            if done:
--                break
--            state = next_state.reshape(48)
--    print(env._total_profit)
--    print(env._total_reward)
--
--
--if __name__ == "__main__":
--    env = buildEnv.createEnv(2330)        
--    os.makedirs("./Tables", exist_ok=True)
--    os.makedirs("./Rewards", exist_ok=True)
--    # training section:
--    for i in range(1):
--        print(f"#{i + 1} training progress")
--        #with tf.device('/device:GPU:0'):
--        #train(env)
--        
--    # testing section:
--    test(env)
--    env.close()
--    #np.save("./Rewards/DDQN_rewards.npy", np.array(total_rewards))
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py b/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-deleted file mode 100644
-index d788c38..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-+++ /dev/null
-@@ -1,86 +0,0 @@
--import numpy as np
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions
--import pandas as pd
--
--def my_process_data(env):
--    start = env.frame_bound[0] - env.window_size
--    end = env.frame_bound[1]
--
--    prices = env.df['Close'].to_numpy()
--    prices = prices[start:end]
--    signal_features = env.df.loc[:, ['Open', 'Close', 'High', 'Low']].to_numpy()[start:end]
--    return prices, signal_features
--
--def my_calculate_reward(self, action):
--    
--    '''
--    # this is the original one
--    step_reward = 0
--    trade = False
--    if ((action == Actions.Buy.value and self._position == Positions.Short) or
--        (action == Actions.Sell.value and self._position == Positions.Long)):
--        trade = True
--    '''
--    '''
--    for i in range(13,3,-2):
--        ismin, ismax = self.knowIs(i)
--        if(ismax and action == Actions.Buy.value):
--            return (i*-5 + 15)/10
--        if(ismin and action == Actions.Sell.value):
--            return (-5 * i + 15)/10
--    '''
--    '''  
--    if trade:
--        current_price = self.prices[self._current_tick]
--        last_trade_price = self.prices[self._last_trade_tick]
--        price_diff = current_price - last_trade_price
--        #step_reward = 0.5
--        #if action == Actions.Sell.value:
--        #    step_reward += price_diff
--        #if action == Actions.Sell.value and ismax:
--        #    step_reward += 3
--        #if action == Actions.Buy.value and ismin:
--        #    step_reward += 3
--        #else:
--        #    step_reward -= price_diff
--    
--    
--    
--    return step_reward
--    '''
--
--    if action == Actions.Sell.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick] - self.prices[self._current_tick+1]
--    if action == Actions.Buy.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick+1] - self.prices[self._current_tick]
--    return 0
--
--
--class MyStocksEnv(StocksEnv):
--    _process_data = my_process_data
--    _calculate_reward = my_calculate_reward
--    def knowIs(self, window):
--        ismax = False
--        ismin = False 
--        if self._current_tick < self._end_tick-window/2:
--            ismax = True
--            ismin = True
--            for i in range(int(-window/2),int(window/2+1)):
--                if(self.prices[self._current_tick + i] > self.prices[self._current_tick]):
--                    ismax = False
--                if(self.prices[self._current_tick + i] < self.prices[self._current_tick]):
--                    ismin = False
--        return ismax, ismin
--
--
--def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
--    csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
--    data = pd.read_csv(csv_name)
--    read_df = pd.DataFrame(data)
--    read_df = read_df.loc[::-1].reset_index(drop=True)
--    env = MyStocksEnv(df = read_df, window_size = window_size, frame_bound = frame_bounds)
--    return env
--if __name__ == "__main__":
--    createEnv(2330)
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-deleted file mode 100644
-index 67bdff1..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-+++ /dev/null
-@@ -1,57 +0,0 @@
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
--from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--import matplotlib.pyplot as plt
--import numpy as np
--import pickle
--import os
--import sys
--from buildEnv import createEnv
--from DDQN import Agent
--import torch
--from tqdm import tqdm
--
--quat_type = 2330
--env = createEnv(2330)
--# env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--
--testing_agent = Agent(env)
--testing_agent.target_net.load_state_dict(torch.load("/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Tables/DDQN.pt"))
--
--action_dim = env.action_space.n
--
--episode = 100
--T = 0
--episode_data = {}
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = []
--for _ in tqdm(range(episode)):
--    observation = env.reset().reshape(-1)
--    while True:
--        tempstate = observation.reshape(-1)
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (observation[44+j] - observation[i*4+j])/observation[44+j]
--        Q = testing_agent.target_net(torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--        action = int(torch.argmax(Q).numpy())
--        next_observation, reward, done, _ = env.step(action)
--        observation = next_observation.reshape(48)
--        episode_data['observations'].append(tempstate.astype('float32'))
--        next_observation = next_observation.reshape(-1)
--        tempstate = next_observation
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (next_observation[44+j] - next_observation[i*4+j])/next_observation[44+j]
--        episode_data['next_observations'].append(tempstate.astype('float32'))
--        episode_data['actions'].append(np.array(Q))
--        #print(Q)
--        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--        episode_data['terminals'].append(done)
--        if done:
--            break
--
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Medium/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
--    pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 3c3bb2b..49041a2 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -62,12 +62,12 @@ class SequenceDataset(torch.utils.data.Dataset):
-         #     print(f'[ datasets/sequence ] Modifying environment')
-         #     dataset = preprocess_fn(dataset)
-         ##
--        observations = dataset['observations']
--        actions = dataset['actions']
--        next_observations = dataset['next_observations']
--        rewards = dataset['rewards']
--        terminals = dataset['terminals']
--        realterminals = [False]*len(dataset['terminals'])
-+        observations = np.array(dataset['observations'])
-+        actions = np.array(dataset['actions'])
-+        next_observations = np.array(dataset['next_observations'])
-+        rewards = np.array(dataset['rewards'])
-+        terminals = np.array(dataset['terminals'])
-+        realterminals = np.array(dataset['terminals'])
- 
-         self.observations_raw = observations
-         self.actions_raw = actions
-diff --git a/logs/stock_2330/gpt/azure/state_0.pt b/logs/stock_2330/gpt/azure/state_0.pt
-index 215a98c..2008ae4 100644
-Binary files a/logs/stock_2330/gpt/azure/state_0.pt and b/logs/stock_2330/gpt/azure/state_0.pt differ
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/gpt/azure/model_config.pkl b/logs/DDQN_1_2330/gpt/azure/model_config.pkl
deleted file mode 100644
index 033b29b..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/model_config.pkl and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/state_0.pt b/logs/DDQN_1_2330/gpt/azure/state_0.pt
deleted file mode 100644
index e15915f..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/state_0.pt and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/state_1000.pt b/logs/DDQN_1_2330/gpt/azure/state_1000.pt
deleted file mode 100644
index ce9f90f..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/state_1000.pt and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/state_333.pt b/logs/DDQN_1_2330/gpt/azure/state_333.pt
deleted file mode 100644
index 6558008..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/state_333.pt and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/state_666.pt b/logs/DDQN_1_2330/gpt/azure/state_666.pt
deleted file mode 100644
index 580bf7b..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/state_666.pt and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/state_999.pt b/logs/DDQN_1_2330/gpt/azure/state_999.pt
deleted file mode 100644
index 4fc3c38..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/state_999.pt and /dev/null differ
diff --git a/logs/DDQN_1_2330/gpt/azure/trainer_config.pkl b/logs/DDQN_1_2330/gpt/azure/trainer_config.pkl
deleted file mode 100644
index d3afe86..0000000
Binary files a/logs/DDQN_1_2330/gpt/azure/trainer_config.pkl and /dev/null differ
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/args.json b/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/args.json
deleted file mode 100644
index 30683bd..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaDmGlFKULg=="
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "c38fed077310b11b3ed50a9137bef173cac138df main",
-    "config": "config.offline",
-    "dataset": "DDQN_1_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H10_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaDGGlFKULg=="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaBiGlFKULg=="
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 10,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaB6GlFKULg=="
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaBuGlFKULg=="
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/c38fed077310b11b3ed50a9137bef173cac138df",
-        "time": "Sun May 28 21:50:17 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaCGGlFKULg=="
-    },
-    "savepath": "logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVCAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHJlbmRlcmVylIwIUmVuZGVyZXKUjAVrX2FjdJROjAdjZGZfYWN0lEc/4zMzMzMzM4wIc2F2ZXBhdGiUjDNsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4LzCUjA5wcmVmaXhfY29udGV4dJSIjAh2aXNfZnJlcZRLMowIbl9leHBhbmSUSwKMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjiUjAZjb21taXSUjC1jMzhmZWQwNzczMTBiMTFiM2VkNTBhOTEzN2JlZjE3M2NhYzEzOGRmIG1haW6UjAVrX29ic5RLAYwKYmVhbV93aWR0aJRLgIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCmdldF9jb21taXSUaAJoBmgYhpRSlIwLcmVhZF9jb25maWeUaAJoBmgbhpRSlIwFbWtkaXKUaAJoBmgehpRSlIwJc2F2ZV9kaWZmlGgCaAZoIYaUUpSMCHNldF9zZWVklGgCaAZoJIaUUpSMB2xvZ2Jhc2WUjAVsb2dzL5SMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwHdmVyYm9zZZSIjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAdob3Jpem9ulEsKjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAphZGRfZXh0cmFzlGgCaAZoOYaUUpSMB2NkZl9vYnOUTowGZGV2aWNllIwEY3VkYZSMCnBlcmNlbnRpbGWUjARtZWFulIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lHViaCSGlFKULg=="
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/diff.txt b/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/diff.txt
deleted file mode 100644
index 4a3943a..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam128/0/diff.txt
+++ /dev/null
@@ -1,620 +0,0 @@
-diff --git a/DDQN.py b/DDQN.py
-index 2e34be3..6b01dd9 100644
---- a/DDQN.py
-+++ b/DDQN.py
-@@ -277,6 +277,37 @@ def test(env):
-     print(env._total_profit)
-     print(env._total_reward)
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
-+
-+def gen_offline_data(episodes, env):
-+    agent = Agent(env)
-+    agent.target_net.load_state_dict(torch.load("./Tables/DDQN.pt"))
-+    episode_data = {}
-+    for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-+        episode_data[k] = []
-+    for _ in range(episodes):
-+        observation = env.reset()
-+        observation = state_preprocess(observation.reshape(-1))
-+        while True:
-+            Q = agent.target_net.forward(torch.FloatTensor(observation)).squeeze(0).detach()
-+            action = int(torch.argmax(Q).numpy())
-+            next_observation, reward, done, info = env.step(action)
-+            episode_data['observations'].append(np.array(observation))
-+            next_observation = state_preprocess(next_observation.reshape(-1))
-+            episode_data['next_observations'].append(np.array(next_observation))
-+            episode_data['actions'].append(np.array(Q))
-+            episode_data['rewards'].append(np.array([reward]).astype('float32'))
-+            episode_data['terminals'].append(np.array([done]))
-+            observation = next_observation
-+            if done:
-+                print(info)
-+                break
-+    return episode_data
- 
- if __name__ == "__main__":
-     env = buildEnv.createEnv(2330)        
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 73c5b28..46c76ed 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -17,7 +17,7 @@ args_to_watch = [
- base = {
- 
-     'train': {
--        'N': 20,
-+        'N': 100,
-         'discount': 0.99,
-         'n_layer': 4,
-         'n_head': 4,
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index 8979c32..0b5cd38 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -20,11 +20,11 @@ from trajectory.search import (
-     update_context,
- )
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '3'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'stock_'+code
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -67,17 +67,28 @@ value_fn = lambda x: discretizer.value_fn(x, args.percentile)
- observation = env.reset()
- total_reward = 0
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
- ## observations for rendering
-+observation = observation.reshape(-1)
-+observation = state_preprocess(observation)
- rollout = [observation.copy()]
- 
- ## previous (tokenized) transitions for conditioning transformer
- context = []
- 
-+
-+
- T = 1187
- for t in range(T):
- 
-     #observation = preprocess_fn(observation)
--    observation = observation.reshape(-1)
-+    #observation = observation.reshape(-1)
-+    #observation = state_preprocess(observation)
- 
-     if t % args.plan_freq == 0:
-         ## concatenate previous transitions and current observations to input to model
-@@ -108,6 +119,7 @@ for t in range(T):
-     #score = env.get_normalized_score(total_reward)
- 
-     ## update rollout observations and context transitions
-+    next_observation = state_preprocess(next_observation.reshape(-1))
-     rollout.append(next_observation.copy())
-     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-     print(
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index bb35461..b2cfabd 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -12,10 +12,10 @@ import trajectory.datasets as datasets
- from trajectory.models.transformers import GPT
- 
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stock_2330'
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 10000
-+n_epochs = 3000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py b/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-deleted file mode 100644
-index 2e34be3..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-+++ /dev/null
-@@ -1,294 +0,0 @@
--import torch
--import torch.nn as nn
--import torch.nn.functional as F
--import numpy as np
--import gym
--import random
--from collections import deque
--from torch import Tensor
--import os
--from tqdm import tqdm
--import buildEnv
--import math
--import math
--total_rewards = []
--
--
--class replay_buffer():
--    '''
--    A deque storing trajectories
--    '''
--    def __init__(self, capacity):
--        self.capacity = capacity  # the size of the replay buffer
--        self.memory = deque(maxlen=capacity)  # replay buffer itself
--
--    def insert(self, state, action, reward, next_state, done):
--        '''
--        Insert a sequence of data gotten by the agent into the replay buffer.
--        Parameter:
--            state: the current state
--            action: the action done by the agent
--            reward: the reward agent got
--            next_state: the next state
--            done: the status showing whether the episode finish        
--        Return:
--            None
--        '''
--        
--        self.memory.append([state, action, reward, next_state.reshape(48), done])
--
--    def sample(self, batch_size):
--        '''
--        Sample a batch size of data from the replay buffer.
--        Parameter:
--            batch_size: the number of samples which will be propagated through the neural network
--        Returns:
--            observations: a batch size of states stored in the replay buffer
--            actions: a batch size of actions stored in the replay buffer
--            rewards: a batch size of rewards stored in the replay buffer
--            next_observations: a batch size of "next_state"s stored in the replay buffer
--            done: a batch size of done stored in the replay buffer
--        '''
--        batch = random.sample(self.memory, batch_size)
--        observations, actions, rewards, next_observations, done = zip(*batch)
--        return observations, actions, rewards, next_observations, done
--
--    def __len__(self):
--        return len(self.memory)
--
--
--class Net(nn.Module):
--    '''
--    The structure of the Neural Network calculating Q values of each state.
--    '''
--    def __init__(self,  num_actions, hidden_layer_size=600):
--        super(Net, self).__init__()
--        self.input_state = 48  # the dimension of state space
--        self.num_actions = num_actions  # the dimension of action space
--        self.fc1 = nn.Linear(self.input_state, 32*12)  # input layer
--        self.fc2 = nn.Linear(32*12, hidden_layer_size)  # hidden layer
--        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)
--        self.fc4 = nn.Linear(hidden_layer_size, num_actions)  # output layer
--
--    def forward(self, states):
--        '''
--        Forward the state to the neural network.        
--        Parameter:
--            states: a batch size of states
--        Return:
--            q_values: a batch size of q_values
--        '''
--        x = F.relu(self.fc1(states))
--        x = F.relu(self.fc2(x))
--        x = F.relu(self.fc3(x))
--        q_values = self.fc4(x)
--        return q_values
--
--
--class Agent():
--    def __init__(self, env, epsilon=10, learning_rate=0.0002, GAMMA=0.97, batch_size=32, capacity=10000):
--        """
--        The agent learning how to control the action of the cart pole.
--        Hyperparameters:
--            epsilon: Determines the explore/expliot rate of the agent
--            learning_rate: Determines the step size while moving toward a minimum of a loss function
--            GAMMA: the discount factor (tradeoff between immediate rewards and future rewards)
--            batch_size: the number of samples which will be propagated through the neural network
--            capacity: the size of the replay buffer/memory
--        """
--        self.env = env
--        self.n_actions = 2  # the number of actions
--        self.count = 0
--
--        self.epsilon = epsilon
--        self.learning_rate = learning_rate
--        self.gamma = GAMMA
--        self.batch_size = batch_size
--        self.capacity = capacity
--
--        self.buffer = replay_buffer(self.capacity)
--        self.evaluate_net = Net(self.n_actions)  # the evaluate network
--        self.target_net = Net(self.n_actions)  # the target network
--        self.optimizer = torch.optim.Adam(
--            self.evaluate_net.parameters(), lr=self.learning_rate)  # Adam is a method using to optimize the neural network
--
--    def learn(self):
--        '''
--        - Implement the learning function.
--        - Here are the hints to implement.
--        Steps:
--        -----
--        1. Update target net by current net every 100 times. (we have done this for you)
--        2. Sample trajectories of batch size from the replay buffer.
--        3. Forward the data to the evaluate net and the target net.
--        4. Compute the loss with MSE.
--        5. Zero-out the gradients.
--        6. Backpropagation.
--        7. Optimize the loss function.
--        -----
--        Parameters:
--            self: the agent itself.
--            (Don't pass additional parameters to the function.)
--            (All you need have been initialized in the constructor.)
--        Returns:
--            None (Don't need to return anything)
--        '''
--        if self.count % 10 == 0:
--            self.target_net.load_state_dict(self.evaluate_net.state_dict())
--
--        # Begin your code
--        # TODO
--        # Step2: Sample the data stored in the buffer and store them into data type Tensor 
--        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)
--        states = torch.tensor(np.array(states), dtype=torch.float)
--        actions = torch.tensor(np.array(actions), dtype=torch.int64).unsqueeze(-1)
--        rewards = torch.tensor(np.array(rewards), dtype=torch.float)
--        next_states = torch.tensor(np.array(next_states), dtype=torch.float)
--        dones = torch.tensor(np.array(dones), dtype=torch.float)
--
--        # Step3: Forward the data to the evaluate net and the target net with a few adjustment of the size
--        
--        q_values = torch.gather(self.evaluate_net(states), 1, actions)
--        
--        next_actions = self.evaluate_net(next_states).argmax(dim=1, keepdim=True)
--        next_q_values = self.target_net(next_states).gather(1, next_actions).reshape(32)
--        target_q_values = (rewards + self.gamma * (1 - dones) * next_q_values).unsqueeze(1)
--        # Step4: Compute the loss with MSE.
--        loss = F.mse_loss(q_values, target_q_values)
--        
--        # Step5: Zero-out the gradients.
--        self.optimizer.zero_grad()
--
--        # Step6: Backpropagation.
--        loss.backward()
--        # Step7: Optimize the loss function.
--        self.optimizer.step()
--        
--            
--        # End your code
--        
--
--
--    def choose_action(self, state):
--
--        with torch.no_grad():
--            # Begin your code
--            # TODO
--            temp = np.random.random()
--            if temp < math.exp(-1*self.epsilon) or temp<0.005:
--                return np.random.randint(self.n_actions)
--            # forward the state to nn and find the argmax of the actions
--            
--            action = torch.argmax(self.evaluate_net(Tensor(state).reshape(48))).item()
--            # End your code
--        return action
--
--
--def train(env):
--    """
--    Train the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    agent = Agent(env)
--    #agent.target_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    #agent.evaluate_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    episode = 150
--    rewards = []
--    cnt = 0
--    for _ in tqdm(range(episode)):
--        cnt += 1
--        state = env.reset()
--        #print(state)
--        count0 = 0
--        count1 = 0
--        while True:
--            agent.count += 1
--            #env.render()
--            tempstate1 = state.reshape(48)
--            state = state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate1[i*4+j] = (state[44+j] - state[4*i+j])/state[44+j]
--            action = agent.choose_action(tempstate1)
--            next_state, reward, done, _ = env.step(action)
--            tempstate2 = next_state.reshape(48)
--            next_state = next_state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate2[i*4+j] = (next_state[44+j] - next_state[4*i+j])/next_state[44+j]
--            agent.buffer.insert(tempstate1, int(action), reward, tempstate2, int(done))
--            if(action==1):
--                count1 += 1
--            else:
--                count0 += 1
--            if len(agent.buffer) >= 100:
--                agent.learn()
--            if done:
--                rewards.append(env._total_reward)
--                #print("!")
--                #print(count0)
--                #print(count1)
--                #print(agent.env._total_reward)
--                #print(agent.env._total_profit)
--                break
--            state = next_state
--        agent.epsilon += 0.1
--        
--        if(cnt % 50 ==0):
--            url = "Tables/DDQN"+str(cnt+3850)+".pt"
--            url2 = "Rewards/DDQN_rewards_iter2_new"+str(cnt+3850)+".npy"
--            try:
--                np.save(url2, np.array(rewards))
--                print(".np saved at "+url2)
--            except RuntimeError:
--                print("!!")  
--            try:
--                torch.save(agent.target_net.state_dict(), url)
--            except RuntimeError:
--                print("!!!")
--
--def test(env):
--    """
--    Test the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    testing_agent = Agent(env)
--    testing_agent.target_net.load_state_dict(torch.load("Tables/DDQN2850.pt"))
--    for _ in range(1):
--        state = env.reset().reshape(48)
--        while True:
--            tempstate = state
--            for i in range(12):
--                for j in range(4):
--                    tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
--            Q = testing_agent.target_net(
--                torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--            action = int(torch.argmax(Q).numpy())
--            next_state, _, done, _ = env.step(action)
--            if done:
--                break
--            state = next_state.reshape(48)
--    print(env._total_profit)
--    print(env._total_reward)
--
--
--if __name__ == "__main__":
--    env = buildEnv.createEnv(2330)        
--    os.makedirs("./Tables", exist_ok=True)
--    os.makedirs("./Rewards", exist_ok=True)
--    # training section:
--    for i in range(1):
--        print(f"#{i + 1} training progress")
--        #with tf.device('/device:GPU:0'):
--        #train(env)
--        
--    # testing section:
--    test(env)
--    env.close()
--    #np.save("./Rewards/DDQN_rewards.npy", np.array(total_rewards))
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py b/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-deleted file mode 100644
-index d788c38..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-+++ /dev/null
-@@ -1,86 +0,0 @@
--import numpy as np
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions
--import pandas as pd
--
--def my_process_data(env):
--    start = env.frame_bound[0] - env.window_size
--    end = env.frame_bound[1]
--
--    prices = env.df['Close'].to_numpy()
--    prices = prices[start:end]
--    signal_features = env.df.loc[:, ['Open', 'Close', 'High', 'Low']].to_numpy()[start:end]
--    return prices, signal_features
--
--def my_calculate_reward(self, action):
--    
--    '''
--    # this is the original one
--    step_reward = 0
--    trade = False
--    if ((action == Actions.Buy.value and self._position == Positions.Short) or
--        (action == Actions.Sell.value and self._position == Positions.Long)):
--        trade = True
--    '''
--    '''
--    for i in range(13,3,-2):
--        ismin, ismax = self.knowIs(i)
--        if(ismax and action == Actions.Buy.value):
--            return (i*-5 + 15)/10
--        if(ismin and action == Actions.Sell.value):
--            return (-5 * i + 15)/10
--    '''
--    '''  
--    if trade:
--        current_price = self.prices[self._current_tick]
--        last_trade_price = self.prices[self._last_trade_tick]
--        price_diff = current_price - last_trade_price
--        #step_reward = 0.5
--        #if action == Actions.Sell.value:
--        #    step_reward += price_diff
--        #if action == Actions.Sell.value and ismax:
--        #    step_reward += 3
--        #if action == Actions.Buy.value and ismin:
--        #    step_reward += 3
--        #else:
--        #    step_reward -= price_diff
--    
--    
--    
--    return step_reward
--    '''
--
--    if action == Actions.Sell.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick] - self.prices[self._current_tick+1]
--    if action == Actions.Buy.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick+1] - self.prices[self._current_tick]
--    return 0
--
--
--class MyStocksEnv(StocksEnv):
--    _process_data = my_process_data
--    _calculate_reward = my_calculate_reward
--    def knowIs(self, window):
--        ismax = False
--        ismin = False 
--        if self._current_tick < self._end_tick-window/2:
--            ismax = True
--            ismin = True
--            for i in range(int(-window/2),int(window/2+1)):
--                if(self.prices[self._current_tick + i] > self.prices[self._current_tick]):
--                    ismax = False
--                if(self.prices[self._current_tick + i] < self.prices[self._current_tick]):
--                    ismin = False
--        return ismax, ismin
--
--
--def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
--    csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
--    data = pd.read_csv(csv_name)
--    read_df = pd.DataFrame(data)
--    read_df = read_df.loc[::-1].reset_index(drop=True)
--    env = MyStocksEnv(df = read_df, window_size = window_size, frame_bound = frame_bounds)
--    return env
--if __name__ == "__main__":
--    createEnv(2330)
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-deleted file mode 100644
-index 67bdff1..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-+++ /dev/null
-@@ -1,57 +0,0 @@
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
--from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--import matplotlib.pyplot as plt
--import numpy as np
--import pickle
--import os
--import sys
--from buildEnv import createEnv
--from DDQN import Agent
--import torch
--from tqdm import tqdm
--
--quat_type = 2330
--env = createEnv(2330)
--# env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--
--testing_agent = Agent(env)
--testing_agent.target_net.load_state_dict(torch.load("/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Tables/DDQN.pt"))
--
--action_dim = env.action_space.n
--
--episode = 100
--T = 0
--episode_data = {}
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = []
--for _ in tqdm(range(episode)):
--    observation = env.reset().reshape(-1)
--    while True:
--        tempstate = observation.reshape(-1)
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (observation[44+j] - observation[i*4+j])/observation[44+j]
--        Q = testing_agent.target_net(torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--        action = int(torch.argmax(Q).numpy())
--        next_observation, reward, done, _ = env.step(action)
--        observation = next_observation.reshape(48)
--        episode_data['observations'].append(tempstate.astype('float32'))
--        next_observation = next_observation.reshape(-1)
--        tempstate = next_observation
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (next_observation[44+j] - next_observation[i*4+j])/next_observation[44+j]
--        episode_data['next_observations'].append(tempstate.astype('float32'))
--        episode_data['actions'].append(np.array(Q))
--        #print(Q)
--        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--        episode_data['terminals'].append(done)
--        if done:
--            break
--
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Medium/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
--    pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 3c3bb2b..49041a2 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -62,12 +62,12 @@ class SequenceDataset(torch.utils.data.Dataset):
-         #     print(f'[ datasets/sequence ] Modifying environment')
-         #     dataset = preprocess_fn(dataset)
-         ##
--        observations = dataset['observations']
--        actions = dataset['actions']
--        next_observations = dataset['next_observations']
--        rewards = dataset['rewards']
--        terminals = dataset['terminals']
--        realterminals = [False]*len(dataset['terminals'])
-+        observations = np.array(dataset['observations'])
-+        actions = np.array(dataset['actions'])
-+        next_observations = np.array(dataset['next_observations'])
-+        rewards = np.array(dataset['rewards'])
-+        terminals = np.array(dataset['terminals'])
-+        realterminals = np.array(dataset['terminals'])
- 
-         self.observations_raw = observations
-         self.actions_raw = actions
-diff --git a/logs/stock_2330/gpt/azure/state_0.pt b/logs/stock_2330/gpt/azure/state_0.pt
-index 215a98c..2008ae4 100644
-Binary files a/logs/stock_2330/gpt/azure/state_0.pt and b/logs/stock_2330/gpt/azure/state_0.pt differ
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/args.json b/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/args.json
deleted file mode 100644
index df36684..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1YmgzhpRSlC4="
-    },
-    "beam_width": 32,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "c38fed077310b11b3ed50a9137bef173cac138df main",
-    "config": "config.offline",
-    "dataset": "DDQN_1_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H10_beam32",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1Ymg9hpRSlC4="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1YmgthpRSlC4="
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 10,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1YmgThpRSlC4="
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1YmgwhpRSlC4="
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/c38fed077310b11b3ed50a9137bef173cac138df",
-        "time": "Sun May 28 21:41:21 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1YmgchpRSlC4="
-    },
-    "savepath": "logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2xvZ2Jhc2WUjAVsb2dzL5SMB2hvcml6b26USwqMCXBsYW5fZnJlcZRLAYwFa19hY3SUTowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMB2NkZl9vYnOUTowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgThpRSlIwIZXhwX25hbWWUjB9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTBfYmVhbTMylIwGZGV2aWNllIwEY3VkYZSMBWtfb2JzlEsBjA5wcmVmaXhfY29udGV4dJSIjAlzYXZlX2RpZmaUaAJoBmgchpRSlIwGY29tbWl0lIwtYzM4ZmVkMDc3MzEwYjExYjNlZDUwYTkxMzdiZWYxNzNjYWMxMzhkZiBtYWlulIwHZGF0YXNldJSMC0REUU5fMV8yMzMwlIwIbl9leHBhbmSUSwKMCmJlYW1fd2lkdGiUSyCMBnN1ZmZpeJSMATCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwIdmlzX2ZyZXGUSzKMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaC2GlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAphZGRfZXh0cmFzlGgCaAZoM4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwIc2F2ZXBhdGiUjDJsb2dzL0REUU5fMV8yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMzIvMJSMCHNldF9zZWVklGgCaAZoOoaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoPYaUUpSMCnBlcmNlbnRpbGWUjARtZWFulIwHY2RmX2FjdJRHP+MzMzMzMzN1Ymg6hpRSlC4="
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/diff.txt b/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/diff.txt
deleted file mode 100644
index c232121..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H10_beam32/0/diff.txt
+++ /dev/null
@@ -1,629 +0,0 @@
-diff --git a/DDQN.py b/DDQN.py
-index 2e34be3..6b01dd9 100644
---- a/DDQN.py
-+++ b/DDQN.py
-@@ -277,6 +277,37 @@ def test(env):
-     print(env._total_profit)
-     print(env._total_reward)
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
-+
-+def gen_offline_data(episodes, env):
-+    agent = Agent(env)
-+    agent.target_net.load_state_dict(torch.load("./Tables/DDQN.pt"))
-+    episode_data = {}
-+    for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-+        episode_data[k] = []
-+    for _ in range(episodes):
-+        observation = env.reset()
-+        observation = state_preprocess(observation.reshape(-1))
-+        while True:
-+            Q = agent.target_net.forward(torch.FloatTensor(observation)).squeeze(0).detach()
-+            action = int(torch.argmax(Q).numpy())
-+            next_observation, reward, done, info = env.step(action)
-+            episode_data['observations'].append(np.array(observation))
-+            next_observation = state_preprocess(next_observation.reshape(-1))
-+            episode_data['next_observations'].append(np.array(next_observation))
-+            episode_data['actions'].append(np.array(Q))
-+            episode_data['rewards'].append(np.array([reward]).astype('float32'))
-+            episode_data['terminals'].append(np.array([done]))
-+            observation = next_observation
-+            if done:
-+                print(info)
-+                break
-+    return episode_data
- 
- if __name__ == "__main__":
-     env = buildEnv.createEnv(2330)        
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 73c5b28..a05b7cd 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -17,7 +17,7 @@ args_to_watch = [
- base = {
- 
-     'train': {
--        'N': 20,
-+        'N': 100,
-         'discount': 0.99,
-         'n_layer': 4,
-         'n_head': 4,
-@@ -58,7 +58,7 @@ base = {
- 
-         'plan_freq': 1,
-         'horizon': 10,
--        'beam_width': 128,
-+        'beam_width': 32,
-         'n_expand': 2,
- 
-         'k_obs': 1,
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index 8979c32..0b5cd38 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -20,11 +20,11 @@ from trajectory.search import (
-     update_context,
- )
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '3'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'stock_'+code
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -67,17 +67,28 @@ value_fn = lambda x: discretizer.value_fn(x, args.percentile)
- observation = env.reset()
- total_reward = 0
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
- ## observations for rendering
-+observation = observation.reshape(-1)
-+observation = state_preprocess(observation)
- rollout = [observation.copy()]
- 
- ## previous (tokenized) transitions for conditioning transformer
- context = []
- 
-+
-+
- T = 1187
- for t in range(T):
- 
-     #observation = preprocess_fn(observation)
--    observation = observation.reshape(-1)
-+    #observation = observation.reshape(-1)
-+    #observation = state_preprocess(observation)
- 
-     if t % args.plan_freq == 0:
-         ## concatenate previous transitions and current observations to input to model
-@@ -108,6 +119,7 @@ for t in range(T):
-     #score = env.get_normalized_score(total_reward)
- 
-     ## update rollout observations and context transitions
-+    next_observation = state_preprocess(next_observation.reshape(-1))
-     rollout.append(next_observation.copy())
-     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-     print(
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index bb35461..b2cfabd 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -12,10 +12,10 @@ import trajectory.datasets as datasets
- from trajectory.models.transformers import GPT
- 
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stock_2330'
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 10000
-+n_epochs = 3000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py b/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-deleted file mode 100644
-index 2e34be3..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-+++ /dev/null
-@@ -1,294 +0,0 @@
--import torch
--import torch.nn as nn
--import torch.nn.functional as F
--import numpy as np
--import gym
--import random
--from collections import deque
--from torch import Tensor
--import os
--from tqdm import tqdm
--import buildEnv
--import math
--import math
--total_rewards = []
--
--
--class replay_buffer():
--    '''
--    A deque storing trajectories
--    '''
--    def __init__(self, capacity):
--        self.capacity = capacity  # the size of the replay buffer
--        self.memory = deque(maxlen=capacity)  # replay buffer itself
--
--    def insert(self, state, action, reward, next_state, done):
--        '''
--        Insert a sequence of data gotten by the agent into the replay buffer.
--        Parameter:
--            state: the current state
--            action: the action done by the agent
--            reward: the reward agent got
--            next_state: the next state
--            done: the status showing whether the episode finish        
--        Return:
--            None
--        '''
--        
--        self.memory.append([state, action, reward, next_state.reshape(48), done])
--
--    def sample(self, batch_size):
--        '''
--        Sample a batch size of data from the replay buffer.
--        Parameter:
--            batch_size: the number of samples which will be propagated through the neural network
--        Returns:
--            observations: a batch size of states stored in the replay buffer
--            actions: a batch size of actions stored in the replay buffer
--            rewards: a batch size of rewards stored in the replay buffer
--            next_observations: a batch size of "next_state"s stored in the replay buffer
--            done: a batch size of done stored in the replay buffer
--        '''
--        batch = random.sample(self.memory, batch_size)
--        observations, actions, rewards, next_observations, done = zip(*batch)
--        return observations, actions, rewards, next_observations, done
--
--    def __len__(self):
--        return len(self.memory)
--
--
--class Net(nn.Module):
--    '''
--    The structure of the Neural Network calculating Q values of each state.
--    '''
--    def __init__(self,  num_actions, hidden_layer_size=600):
--        super(Net, self).__init__()
--        self.input_state = 48  # the dimension of state space
--        self.num_actions = num_actions  # the dimension of action space
--        self.fc1 = nn.Linear(self.input_state, 32*12)  # input layer
--        self.fc2 = nn.Linear(32*12, hidden_layer_size)  # hidden layer
--        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)
--        self.fc4 = nn.Linear(hidden_layer_size, num_actions)  # output layer
--
--    def forward(self, states):
--        '''
--        Forward the state to the neural network.        
--        Parameter:
--            states: a batch size of states
--        Return:
--            q_values: a batch size of q_values
--        '''
--        x = F.relu(self.fc1(states))
--        x = F.relu(self.fc2(x))
--        x = F.relu(self.fc3(x))
--        q_values = self.fc4(x)
--        return q_values
--
--
--class Agent():
--    def __init__(self, env, epsilon=10, learning_rate=0.0002, GAMMA=0.97, batch_size=32, capacity=10000):
--        """
--        The agent learning how to control the action of the cart pole.
--        Hyperparameters:
--            epsilon: Determines the explore/expliot rate of the agent
--            learning_rate: Determines the step size while moving toward a minimum of a loss function
--            GAMMA: the discount factor (tradeoff between immediate rewards and future rewards)
--            batch_size: the number of samples which will be propagated through the neural network
--            capacity: the size of the replay buffer/memory
--        """
--        self.env = env
--        self.n_actions = 2  # the number of actions
--        self.count = 0
--
--        self.epsilon = epsilon
--        self.learning_rate = learning_rate
--        self.gamma = GAMMA
--        self.batch_size = batch_size
--        self.capacity = capacity
--
--        self.buffer = replay_buffer(self.capacity)
--        self.evaluate_net = Net(self.n_actions)  # the evaluate network
--        self.target_net = Net(self.n_actions)  # the target network
--        self.optimizer = torch.optim.Adam(
--            self.evaluate_net.parameters(), lr=self.learning_rate)  # Adam is a method using to optimize the neural network
--
--    def learn(self):
--        '''
--        - Implement the learning function.
--        - Here are the hints to implement.
--        Steps:
--        -----
--        1. Update target net by current net every 100 times. (we have done this for you)
--        2. Sample trajectories of batch size from the replay buffer.
--        3. Forward the data to the evaluate net and the target net.
--        4. Compute the loss with MSE.
--        5. Zero-out the gradients.
--        6. Backpropagation.
--        7. Optimize the loss function.
--        -----
--        Parameters:
--            self: the agent itself.
--            (Don't pass additional parameters to the function.)
--            (All you need have been initialized in the constructor.)
--        Returns:
--            None (Don't need to return anything)
--        '''
--        if self.count % 10 == 0:
--            self.target_net.load_state_dict(self.evaluate_net.state_dict())
--
--        # Begin your code
--        # TODO
--        # Step2: Sample the data stored in the buffer and store them into data type Tensor 
--        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)
--        states = torch.tensor(np.array(states), dtype=torch.float)
--        actions = torch.tensor(np.array(actions), dtype=torch.int64).unsqueeze(-1)
--        rewards = torch.tensor(np.array(rewards), dtype=torch.float)
--        next_states = torch.tensor(np.array(next_states), dtype=torch.float)
--        dones = torch.tensor(np.array(dones), dtype=torch.float)
--
--        # Step3: Forward the data to the evaluate net and the target net with a few adjustment of the size
--        
--        q_values = torch.gather(self.evaluate_net(states), 1, actions)
--        
--        next_actions = self.evaluate_net(next_states).argmax(dim=1, keepdim=True)
--        next_q_values = self.target_net(next_states).gather(1, next_actions).reshape(32)
--        target_q_values = (rewards + self.gamma * (1 - dones) * next_q_values).unsqueeze(1)
--        # Step4: Compute the loss with MSE.
--        loss = F.mse_loss(q_values, target_q_values)
--        
--        # Step5: Zero-out the gradients.
--        self.optimizer.zero_grad()
--
--        # Step6: Backpropagation.
--        loss.backward()
--        # Step7: Optimize the loss function.
--        self.optimizer.step()
--        
--            
--        # End your code
--        
--
--
--    def choose_action(self, state):
--
--        with torch.no_grad():
--            # Begin your code
--            # TODO
--            temp = np.random.random()
--            if temp < math.exp(-1*self.epsilon) or temp<0.005:
--                return np.random.randint(self.n_actions)
--            # forward the state to nn and find the argmax of the actions
--            
--            action = torch.argmax(self.evaluate_net(Tensor(state).reshape(48))).item()
--            # End your code
--        return action
--
--
--def train(env):
--    """
--    Train the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    agent = Agent(env)
--    #agent.target_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    #agent.evaluate_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    episode = 150
--    rewards = []
--    cnt = 0
--    for _ in tqdm(range(episode)):
--        cnt += 1
--        state = env.reset()
--        #print(state)
--        count0 = 0
--        count1 = 0
--        while True:
--            agent.count += 1
--            #env.render()
--            tempstate1 = state.reshape(48)
--            state = state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate1[i*4+j] = (state[44+j] - state[4*i+j])/state[44+j]
--            action = agent.choose_action(tempstate1)
--            next_state, reward, done, _ = env.step(action)
--            tempstate2 = next_state.reshape(48)
--            next_state = next_state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate2[i*4+j] = (next_state[44+j] - next_state[4*i+j])/next_state[44+j]
--            agent.buffer.insert(tempstate1, int(action), reward, tempstate2, int(done))
--            if(action==1):
--                count1 += 1
--            else:
--                count0 += 1
--            if len(agent.buffer) >= 100:
--                agent.learn()
--            if done:
--                rewards.append(env._total_reward)
--                #print("!")
--                #print(count0)
--                #print(count1)
--                #print(agent.env._total_reward)
--                #print(agent.env._total_profit)
--                break
--            state = next_state
--        agent.epsilon += 0.1
--        
--        if(cnt % 50 ==0):
--            url = "Tables/DDQN"+str(cnt+3850)+".pt"
--            url2 = "Rewards/DDQN_rewards_iter2_new"+str(cnt+3850)+".npy"
--            try:
--                np.save(url2, np.array(rewards))
--                print(".np saved at "+url2)
--            except RuntimeError:
--                print("!!")  
--            try:
--                torch.save(agent.target_net.state_dict(), url)
--            except RuntimeError:
--                print("!!!")
--
--def test(env):
--    """
--    Test the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    testing_agent = Agent(env)
--    testing_agent.target_net.load_state_dict(torch.load("Tables/DDQN2850.pt"))
--    for _ in range(1):
--        state = env.reset().reshape(48)
--        while True:
--            tempstate = state
--            for i in range(12):
--                for j in range(4):
--                    tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
--            Q = testing_agent.target_net(
--                torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--            action = int(torch.argmax(Q).numpy())
--            next_state, _, done, _ = env.step(action)
--            if done:
--                break
--            state = next_state.reshape(48)
--    print(env._total_profit)
--    print(env._total_reward)
--
--
--if __name__ == "__main__":
--    env = buildEnv.createEnv(2330)        
--    os.makedirs("./Tables", exist_ok=True)
--    os.makedirs("./Rewards", exist_ok=True)
--    # training section:
--    for i in range(1):
--        print(f"#{i + 1} training progress")
--        #with tf.device('/device:GPU:0'):
--        #train(env)
--        
--    # testing section:
--    test(env)
--    env.close()
--    #np.save("./Rewards/DDQN_rewards.npy", np.array(total_rewards))
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py b/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-deleted file mode 100644
-index d788c38..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-+++ /dev/null
-@@ -1,86 +0,0 @@
--import numpy as np
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions
--import pandas as pd
--
--def my_process_data(env):
--    start = env.frame_bound[0] - env.window_size
--    end = env.frame_bound[1]
--
--    prices = env.df['Close'].to_numpy()
--    prices = prices[start:end]
--    signal_features = env.df.loc[:, ['Open', 'Close', 'High', 'Low']].to_numpy()[start:end]
--    return prices, signal_features
--
--def my_calculate_reward(self, action):
--    
--    '''
--    # this is the original one
--    step_reward = 0
--    trade = False
--    if ((action == Actions.Buy.value and self._position == Positions.Short) or
--        (action == Actions.Sell.value and self._position == Positions.Long)):
--        trade = True
--    '''
--    '''
--    for i in range(13,3,-2):
--        ismin, ismax = self.knowIs(i)
--        if(ismax and action == Actions.Buy.value):
--            return (i*-5 + 15)/10
--        if(ismin and action == Actions.Sell.value):
--            return (-5 * i + 15)/10
--    '''
--    '''  
--    if trade:
--        current_price = self.prices[self._current_tick]
--        last_trade_price = self.prices[self._last_trade_tick]
--        price_diff = current_price - last_trade_price
--        #step_reward = 0.5
--        #if action == Actions.Sell.value:
--        #    step_reward += price_diff
--        #if action == Actions.Sell.value and ismax:
--        #    step_reward += 3
--        #if action == Actions.Buy.value and ismin:
--        #    step_reward += 3
--        #else:
--        #    step_reward -= price_diff
--    
--    
--    
--    return step_reward
--    '''
--
--    if action == Actions.Sell.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick] - self.prices[self._current_tick+1]
--    if action == Actions.Buy.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick+1] - self.prices[self._current_tick]
--    return 0
--
--
--class MyStocksEnv(StocksEnv):
--    _process_data = my_process_data
--    _calculate_reward = my_calculate_reward
--    def knowIs(self, window):
--        ismax = False
--        ismin = False 
--        if self._current_tick < self._end_tick-window/2:
--            ismax = True
--            ismin = True
--            for i in range(int(-window/2),int(window/2+1)):
--                if(self.prices[self._current_tick + i] > self.prices[self._current_tick]):
--                    ismax = False
--                if(self.prices[self._current_tick + i] < self.prices[self._current_tick]):
--                    ismin = False
--        return ismax, ismin
--
--
--def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
--    csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
--    data = pd.read_csv(csv_name)
--    read_df = pd.DataFrame(data)
--    read_df = read_df.loc[::-1].reset_index(drop=True)
--    env = MyStocksEnv(df = read_df, window_size = window_size, frame_bound = frame_bounds)
--    return env
--if __name__ == "__main__":
--    createEnv(2330)
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-deleted file mode 100644
-index 67bdff1..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-+++ /dev/null
-@@ -1,57 +0,0 @@
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
--from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--import matplotlib.pyplot as plt
--import numpy as np
--import pickle
--import os
--import sys
--from buildEnv import createEnv
--from DDQN import Agent
--import torch
--from tqdm import tqdm
--
--quat_type = 2330
--env = createEnv(2330)
--# env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--
--testing_agent = Agent(env)
--testing_agent.target_net.load_state_dict(torch.load("/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Tables/DDQN.pt"))
--
--action_dim = env.action_space.n
--
--episode = 100
--T = 0
--episode_data = {}
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = []
--for _ in tqdm(range(episode)):
--    observation = env.reset().reshape(-1)
--    while True:
--        tempstate = observation.reshape(-1)
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (observation[44+j] - observation[i*4+j])/observation[44+j]
--        Q = testing_agent.target_net(torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--        action = int(torch.argmax(Q).numpy())
--        next_observation, reward, done, _ = env.step(action)
--        observation = next_observation.reshape(48)
--        episode_data['observations'].append(tempstate.astype('float32'))
--        next_observation = next_observation.reshape(-1)
--        tempstate = next_observation
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (next_observation[44+j] - next_observation[i*4+j])/next_observation[44+j]
--        episode_data['next_observations'].append(tempstate.astype('float32'))
--        episode_data['actions'].append(np.array(Q))
--        #print(Q)
--        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--        episode_data['terminals'].append(done)
--        if done:
--            break
--
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Medium/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
--    pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 3c3bb2b..49041a2 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -62,12 +62,12 @@ class SequenceDataset(torch.utils.data.Dataset):
-         #     print(f'[ datasets/sequence ] Modifying environment')
-         #     dataset = preprocess_fn(dataset)
-         ##
--        observations = dataset['observations']
--        actions = dataset['actions']
--        next_observations = dataset['next_observations']
--        rewards = dataset['rewards']
--        terminals = dataset['terminals']
--        realterminals = [False]*len(dataset['terminals'])
-+        observations = np.array(dataset['observations'])
-+        actions = np.array(dataset['actions'])
-+        next_observations = np.array(dataset['next_observations'])
-+        rewards = np.array(dataset['rewards'])
-+        terminals = np.array(dataset['terminals'])
-+        realterminals = np.array(dataset['terminals'])
- 
-         self.observations_raw = observations
-         self.actions_raw = actions
-diff --git a/logs/stock_2330/gpt/azure/state_0.pt b/logs/stock_2330/gpt/azure/state_0.pt
-index 215a98c..2008ae4 100644
-Binary files a/logs/stock_2330/gpt/azure/state_0.pt and b/logs/stock_2330/gpt/azure/state_0.pt differ
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/args.json b/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/args.json
deleted file mode 100644
index 2091d97..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoCIaUUpQu"
-    },
-    "beam_width": 32,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "c38fed077310b11b3ed50a9137bef173cac138df main",
-    "config": "config.offline",
-    "dataset": "DDQN_1_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H2_beam32",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoI4aUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoGYaUUpQu"
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 2,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoH4aUUpQu"
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoL4aUUpQu"
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/c38fed077310b11b3ed50a9137bef173cac138df",
-        "time": "Sun May 28 21:00:14 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoMoaUUpQu"
-    },
-    "savepath": "logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCmFkZF9leHRyYXOUaAJoBmgIhpRSlIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjAZwcmVmaXiUjA9wbGFucy9kZWZhdWx0cy+UjAh2aXNfZnJlcZRLMowIc2V0X3NlZWSUaAJoBmgRhpRSlIwKcGVyY2VudGlsZZSMBG1lYW6UjAdkYXRhc2V0lIwLRERRTl8xXzIzMzCUjAVrX2FjdJROjApnZXRfY29tbWl0lGgCaAZoGYaUUpSMBnN1ZmZpeJSMATCUjApiZWFtX3dpZHRolEsgjAVta2RpcpRoAmgGaB+GlFKUjAdjZGZfb2JzlE6MEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoI4aUUpSMCHNhdmVwYXRolIwxbG9ncy9ERFFOXzFfMjMzMC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMl9iZWFtMzIvMJSMDnByZWZpeF9jb250ZXh0lIiMBmNvbW1pdJSMLWMzOGZlZDA3NzMxMGIxMWIzZWQ1MGE5MTM3YmVmMTczY2FjMTM4ZGYgbWFpbpSMCG5fZXhwYW5klEsCjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMC3JlYWRfY29uZmlnlGgCaAZoL4aUUpSMCXNhdmVfZGlmZpRoAmgGaDKGlFKUjAdsb2diYXNllIwFbG9ncy+UjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhleHBfbmFtZZSMHnBsYW5zL2RlZmF1bHRzL2ZyZXExX0gyX2JlYW0zMpSMBmRldmljZZSMBGN1ZGGUjAdob3Jpem9ulEsCjAVrX29ic5RLAYwJcGxhbl9mcmVxlEsBjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUdWJoEYaUUpQu"
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/diff.txt b/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/diff.txt
deleted file mode 100644
index 681ef99..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/diff.txt
+++ /dev/null
@@ -1,622 +0,0 @@
-diff --git a/DDQN.py b/DDQN.py
-index 2e34be3..6b01dd9 100644
---- a/DDQN.py
-+++ b/DDQN.py
-@@ -277,6 +277,37 @@ def test(env):
-     print(env._total_profit)
-     print(env._total_reward)
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
-+
-+def gen_offline_data(episodes, env):
-+    agent = Agent(env)
-+    agent.target_net.load_state_dict(torch.load("./Tables/DDQN.pt"))
-+    episode_data = {}
-+    for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-+        episode_data[k] = []
-+    for _ in range(episodes):
-+        observation = env.reset()
-+        observation = state_preprocess(observation.reshape(-1))
-+        while True:
-+            Q = agent.target_net.forward(torch.FloatTensor(observation)).squeeze(0).detach()
-+            action = int(torch.argmax(Q).numpy())
-+            next_observation, reward, done, info = env.step(action)
-+            episode_data['observations'].append(np.array(observation))
-+            next_observation = state_preprocess(next_observation.reshape(-1))
-+            episode_data['next_observations'].append(np.array(next_observation))
-+            episode_data['actions'].append(np.array(Q))
-+            episode_data['rewards'].append(np.array([reward]).astype('float32'))
-+            episode_data['terminals'].append(np.array([done]))
-+            observation = next_observation
-+            if done:
-+                print(info)
-+                break
-+    return episode_data
- 
- if __name__ == "__main__":
-     env = buildEnv.createEnv(2330)        
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 73c5b28..70300f8 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -57,8 +57,8 @@ base = {
-         'renderer': 'Renderer',
- 
-         'plan_freq': 1,
--        'horizon': 10,
--        'beam_width': 128,
-+        'horizon': 2,
-+        'beam_width': 32,
-         'n_expand': 2,
- 
-         'k_obs': 1,
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index 8979c32..0b5cd38 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -20,11 +20,11 @@ from trajectory.search import (
-     update_context,
- )
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '3'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'stock_'+code
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -67,17 +67,28 @@ value_fn = lambda x: discretizer.value_fn(x, args.percentile)
- observation = env.reset()
- total_reward = 0
- 
-+def state_preprocess(state):
-+    tempstate = state
-+    for i in range(12):
-+        for j in range(4):
-+            tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+    return tempstate
- ## observations for rendering
-+observation = observation.reshape(-1)
-+observation = state_preprocess(observation)
- rollout = [observation.copy()]
- 
- ## previous (tokenized) transitions for conditioning transformer
- context = []
- 
-+
-+
- T = 1187
- for t in range(T):
- 
-     #observation = preprocess_fn(observation)
--    observation = observation.reshape(-1)
-+    #observation = observation.reshape(-1)
-+    #observation = state_preprocess(observation)
- 
-     if t % args.plan_freq == 0:
-         ## concatenate previous transitions and current observations to input to model
-@@ -108,6 +119,7 @@ for t in range(T):
-     #score = env.get_normalized_score(total_reward)
- 
-     ## update rollout observations and context transitions
-+    next_observation = state_preprocess(next_observation.reshape(-1))
-     rollout.append(next_observation.copy())
-     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-     print(
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index bb35461..b2cfabd 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -12,10 +12,10 @@ import trajectory.datasets as datasets
- from trajectory.models.transformers import GPT
- 
- os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-+os.environ["CUDA_VISIBLE_DEVICES"] = '0'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stock_2330'
-+    dataset: str = 'DDQN_1_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 10000
-+n_epochs = 3000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py b/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-deleted file mode 100644
-index 2e34be3..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/DDQN.py
-+++ /dev/null
-@@ -1,294 +0,0 @@
--import torch
--import torch.nn as nn
--import torch.nn.functional as F
--import numpy as np
--import gym
--import random
--from collections import deque
--from torch import Tensor
--import os
--from tqdm import tqdm
--import buildEnv
--import math
--import math
--total_rewards = []
--
--
--class replay_buffer():
--    '''
--    A deque storing trajectories
--    '''
--    def __init__(self, capacity):
--        self.capacity = capacity  # the size of the replay buffer
--        self.memory = deque(maxlen=capacity)  # replay buffer itself
--
--    def insert(self, state, action, reward, next_state, done):
--        '''
--        Insert a sequence of data gotten by the agent into the replay buffer.
--        Parameter:
--            state: the current state
--            action: the action done by the agent
--            reward: the reward agent got
--            next_state: the next state
--            done: the status showing whether the episode finish        
--        Return:
--            None
--        '''
--        
--        self.memory.append([state, action, reward, next_state.reshape(48), done])
--
--    def sample(self, batch_size):
--        '''
--        Sample a batch size of data from the replay buffer.
--        Parameter:
--            batch_size: the number of samples which will be propagated through the neural network
--        Returns:
--            observations: a batch size of states stored in the replay buffer
--            actions: a batch size of actions stored in the replay buffer
--            rewards: a batch size of rewards stored in the replay buffer
--            next_observations: a batch size of "next_state"s stored in the replay buffer
--            done: a batch size of done stored in the replay buffer
--        '''
--        batch = random.sample(self.memory, batch_size)
--        observations, actions, rewards, next_observations, done = zip(*batch)
--        return observations, actions, rewards, next_observations, done
--
--    def __len__(self):
--        return len(self.memory)
--
--
--class Net(nn.Module):
--    '''
--    The structure of the Neural Network calculating Q values of each state.
--    '''
--    def __init__(self,  num_actions, hidden_layer_size=600):
--        super(Net, self).__init__()
--        self.input_state = 48  # the dimension of state space
--        self.num_actions = num_actions  # the dimension of action space
--        self.fc1 = nn.Linear(self.input_state, 32*12)  # input layer
--        self.fc2 = nn.Linear(32*12, hidden_layer_size)  # hidden layer
--        self.fc3 = nn.Linear(hidden_layer_size, hidden_layer_size)
--        self.fc4 = nn.Linear(hidden_layer_size, num_actions)  # output layer
--
--    def forward(self, states):
--        '''
--        Forward the state to the neural network.        
--        Parameter:
--            states: a batch size of states
--        Return:
--            q_values: a batch size of q_values
--        '''
--        x = F.relu(self.fc1(states))
--        x = F.relu(self.fc2(x))
--        x = F.relu(self.fc3(x))
--        q_values = self.fc4(x)
--        return q_values
--
--
--class Agent():
--    def __init__(self, env, epsilon=10, learning_rate=0.0002, GAMMA=0.97, batch_size=32, capacity=10000):
--        """
--        The agent learning how to control the action of the cart pole.
--        Hyperparameters:
--            epsilon: Determines the explore/expliot rate of the agent
--            learning_rate: Determines the step size while moving toward a minimum of a loss function
--            GAMMA: the discount factor (tradeoff between immediate rewards and future rewards)
--            batch_size: the number of samples which will be propagated through the neural network
--            capacity: the size of the replay buffer/memory
--        """
--        self.env = env
--        self.n_actions = 2  # the number of actions
--        self.count = 0
--
--        self.epsilon = epsilon
--        self.learning_rate = learning_rate
--        self.gamma = GAMMA
--        self.batch_size = batch_size
--        self.capacity = capacity
--
--        self.buffer = replay_buffer(self.capacity)
--        self.evaluate_net = Net(self.n_actions)  # the evaluate network
--        self.target_net = Net(self.n_actions)  # the target network
--        self.optimizer = torch.optim.Adam(
--            self.evaluate_net.parameters(), lr=self.learning_rate)  # Adam is a method using to optimize the neural network
--
--    def learn(self):
--        '''
--        - Implement the learning function.
--        - Here are the hints to implement.
--        Steps:
--        -----
--        1. Update target net by current net every 100 times. (we have done this for you)
--        2. Sample trajectories of batch size from the replay buffer.
--        3. Forward the data to the evaluate net and the target net.
--        4. Compute the loss with MSE.
--        5. Zero-out the gradients.
--        6. Backpropagation.
--        7. Optimize the loss function.
--        -----
--        Parameters:
--            self: the agent itself.
--            (Don't pass additional parameters to the function.)
--            (All you need have been initialized in the constructor.)
--        Returns:
--            None (Don't need to return anything)
--        '''
--        if self.count % 10 == 0:
--            self.target_net.load_state_dict(self.evaluate_net.state_dict())
--
--        # Begin your code
--        # TODO
--        # Step2: Sample the data stored in the buffer and store them into data type Tensor 
--        states, actions, rewards, next_states, dones = self.buffer.sample(self.batch_size)
--        states = torch.tensor(np.array(states), dtype=torch.float)
--        actions = torch.tensor(np.array(actions), dtype=torch.int64).unsqueeze(-1)
--        rewards = torch.tensor(np.array(rewards), dtype=torch.float)
--        next_states = torch.tensor(np.array(next_states), dtype=torch.float)
--        dones = torch.tensor(np.array(dones), dtype=torch.float)
--
--        # Step3: Forward the data to the evaluate net and the target net with a few adjustment of the size
--        
--        q_values = torch.gather(self.evaluate_net(states), 1, actions)
--        
--        next_actions = self.evaluate_net(next_states).argmax(dim=1, keepdim=True)
--        next_q_values = self.target_net(next_states).gather(1, next_actions).reshape(32)
--        target_q_values = (rewards + self.gamma * (1 - dones) * next_q_values).unsqueeze(1)
--        # Step4: Compute the loss with MSE.
--        loss = F.mse_loss(q_values, target_q_values)
--        
--        # Step5: Zero-out the gradients.
--        self.optimizer.zero_grad()
--
--        # Step6: Backpropagation.
--        loss.backward()
--        # Step7: Optimize the loss function.
--        self.optimizer.step()
--        
--            
--        # End your code
--        
--
--
--    def choose_action(self, state):
--
--        with torch.no_grad():
--            # Begin your code
--            # TODO
--            temp = np.random.random()
--            if temp < math.exp(-1*self.epsilon) or temp<0.005:
--                return np.random.randint(self.n_actions)
--            # forward the state to nn and find the argmax of the actions
--            
--            action = torch.argmax(self.evaluate_net(Tensor(state).reshape(48))).item()
--            # End your code
--        return action
--
--
--def train(env):
--    """
--    Train the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    agent = Agent(env)
--    #agent.target_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    #agent.evaluate_net.load_state_dict(torch.load("/content/drive/My Drive/Colab/RL_for_Quatitatitive_Trading/Tables/DDQN3850.pt"))
--    episode = 150
--    rewards = []
--    cnt = 0
--    for _ in tqdm(range(episode)):
--        cnt += 1
--        state = env.reset()
--        #print(state)
--        count0 = 0
--        count1 = 0
--        while True:
--            agent.count += 1
--            #env.render()
--            tempstate1 = state.reshape(48)
--            state = state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate1[i*4+j] = (state[44+j] - state[4*i+j])/state[44+j]
--            action = agent.choose_action(tempstate1)
--            next_state, reward, done, _ = env.step(action)
--            tempstate2 = next_state.reshape(48)
--            next_state = next_state.reshape(48)
--            for i in range(12):
--                for j in range(4):
--                    tempstate2[i*4+j] = (next_state[44+j] - next_state[4*i+j])/next_state[44+j]
--            agent.buffer.insert(tempstate1, int(action), reward, tempstate2, int(done))
--            if(action==1):
--                count1 += 1
--            else:
--                count0 += 1
--            if len(agent.buffer) >= 100:
--                agent.learn()
--            if done:
--                rewards.append(env._total_reward)
--                #print("!")
--                #print(count0)
--                #print(count1)
--                #print(agent.env._total_reward)
--                #print(agent.env._total_profit)
--                break
--            state = next_state
--        agent.epsilon += 0.1
--        
--        if(cnt % 50 ==0):
--            url = "Tables/DDQN"+str(cnt+3850)+".pt"
--            url2 = "Rewards/DDQN_rewards_iter2_new"+str(cnt+3850)+".npy"
--            try:
--                np.save(url2, np.array(rewards))
--                print(".np saved at "+url2)
--            except RuntimeError:
--                print("!!")  
--            try:
--                torch.save(agent.target_net.state_dict(), url)
--            except RuntimeError:
--                print("!!!")
--
--def test(env):
--    """
--    Test the agent on the given environment.
--    Paramenters:
--        env: the given environment.
--    Returns:
--        None (Don't need to return anything)
--    """
--    testing_agent = Agent(env)
--    testing_agent.target_net.load_state_dict(torch.load("Tables/DDQN2850.pt"))
--    for _ in range(1):
--        state = env.reset().reshape(48)
--        while True:
--            tempstate = state
--            for i in range(12):
--                for j in range(4):
--                    tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
--            Q = testing_agent.target_net(
--                torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--            action = int(torch.argmax(Q).numpy())
--            next_state, _, done, _ = env.step(action)
--            if done:
--                break
--            state = next_state.reshape(48)
--    print(env._total_profit)
--    print(env._total_reward)
--
--
--if __name__ == "__main__":
--    env = buildEnv.createEnv(2330)        
--    os.makedirs("./Tables", exist_ok=True)
--    os.makedirs("./Rewards", exist_ok=True)
--    # training section:
--    for i in range(1):
--        print(f"#{i + 1} training progress")
--        #with tf.device('/device:GPU:0'):
--        #train(env)
--        
--    # testing section:
--    test(env)
--    env.close()
--    #np.save("./Rewards/DDQN_rewards.npy", np.array(total_rewards))
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py b/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-deleted file mode 100644
-index d788c38..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/buildEnv.py
-+++ /dev/null
-@@ -1,86 +0,0 @@
--import numpy as np
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions
--import pandas as pd
--
--def my_process_data(env):
--    start = env.frame_bound[0] - env.window_size
--    end = env.frame_bound[1]
--
--    prices = env.df['Close'].to_numpy()
--    prices = prices[start:end]
--    signal_features = env.df.loc[:, ['Open', 'Close', 'High', 'Low']].to_numpy()[start:end]
--    return prices, signal_features
--
--def my_calculate_reward(self, action):
--    
--    '''
--    # this is the original one
--    step_reward = 0
--    trade = False
--    if ((action == Actions.Buy.value and self._position == Positions.Short) or
--        (action == Actions.Sell.value and self._position == Positions.Long)):
--        trade = True
--    '''
--    '''
--    for i in range(13,3,-2):
--        ismin, ismax = self.knowIs(i)
--        if(ismax and action == Actions.Buy.value):
--            return (i*-5 + 15)/10
--        if(ismin and action == Actions.Sell.value):
--            return (-5 * i + 15)/10
--    '''
--    '''  
--    if trade:
--        current_price = self.prices[self._current_tick]
--        last_trade_price = self.prices[self._last_trade_tick]
--        price_diff = current_price - last_trade_price
--        #step_reward = 0.5
--        #if action == Actions.Sell.value:
--        #    step_reward += price_diff
--        #if action == Actions.Sell.value and ismax:
--        #    step_reward += 3
--        #if action == Actions.Buy.value and ismin:
--        #    step_reward += 3
--        #else:
--        #    step_reward -= price_diff
--    
--    
--    
--    return step_reward
--    '''
--
--    if action == Actions.Sell.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick] - self.prices[self._current_tick+1]
--    if action == Actions.Buy.value and self._current_tick!= self._end_tick:
--        return self.prices[self._current_tick+1] - self.prices[self._current_tick]
--    return 0
--
--
--class MyStocksEnv(StocksEnv):
--    _process_data = my_process_data
--    _calculate_reward = my_calculate_reward
--    def knowIs(self, window):
--        ismax = False
--        ismin = False 
--        if self._current_tick < self._end_tick-window/2:
--            ismax = True
--            ismin = True
--            for i in range(int(-window/2),int(window/2+1)):
--                if(self.prices[self._current_tick + i] > self.prices[self._current_tick]):
--                    ismax = False
--                if(self.prices[self._current_tick + i] < self.prices[self._current_tick]):
--                    ismin = False
--        return ismax, ismin
--
--
--def createEnv(stock_no, window_size = 12, frame_bounds = (12, 1200)):
--    csv_name = './dataset/stock_data_' + str(stock_no) + '.csv'
--    data = pd.read_csv(csv_name)
--    read_df = pd.DataFrame(data)
--    read_df = read_df.loc[::-1].reset_index(drop=True)
--    env = MyStocksEnv(df = read_df, window_size = window_size, frame_bound = frame_bounds)
--    return env
--if __name__ == "__main__":
--    createEnv(2330)
-diff --git a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-deleted file mode 100644
-index 67bdff1..0000000
---- a/Trajectory_Transformer/trajectory/datasets/Medium/gen_data.py
-+++ /dev/null
-@@ -1,57 +0,0 @@
--import gym
--import gym_anytrading
--from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
--from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--import matplotlib.pyplot as plt
--import numpy as np
--import pickle
--import os
--import sys
--from buildEnv import createEnv
--from DDQN import Agent
--import torch
--from tqdm import tqdm
--
--quat_type = 2330
--env = createEnv(2330)
--# env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--
--testing_agent = Agent(env)
--testing_agent.target_net.load_state_dict(torch.load("/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Tables/DDQN.pt"))
--
--action_dim = env.action_space.n
--
--episode = 100
--T = 0
--episode_data = {}
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = []
--for _ in tqdm(range(episode)):
--    observation = env.reset().reshape(-1)
--    while True:
--        tempstate = observation.reshape(-1)
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (observation[44+j] - observation[i*4+j])/observation[44+j]
--        Q = testing_agent.target_net(torch.FloatTensor(tempstate.reshape(48))).squeeze(0).detach()
--        action = int(torch.argmax(Q).numpy())
--        next_observation, reward, done, _ = env.step(action)
--        observation = next_observation.reshape(48)
--        episode_data['observations'].append(tempstate.astype('float32'))
--        next_observation = next_observation.reshape(-1)
--        tempstate = next_observation
--        for i in range(12):
--            for j in range(4):
--                tempstate[i*4+j] = (next_observation[44+j] - next_observation[i*4+j])/next_observation[44+j]
--        episode_data['next_observations'].append(tempstate.astype('float32'))
--        episode_data['actions'].append(np.array(Q))
--        #print(Q)
--        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--        episode_data['terminals'].append(done)
--        if done:
--            break
--
--for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--    episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Medium/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
--    pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 3c3bb2b..49041a2 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -62,12 +62,12 @@ class SequenceDataset(torch.utils.data.Dataset):
-         #     print(f'[ datasets/sequence ] Modifying environment')
-         #     dataset = preprocess_fn(dataset)
-         ##
--        observations = dataset['observations']
--        actions = dataset['actions']
--        next_observations = dataset['next_observations']
--        rewards = dataset['rewards']
--        terminals = dataset['terminals']
--        realterminals = [False]*len(dataset['terminals'])
-+        observations = np.array(dataset['observations'])
-+        actions = np.array(dataset['actions'])
-+        next_observations = np.array(dataset['next_observations'])
-+        rewards = np.array(dataset['rewards'])
-+        terminals = np.array(dataset['terminals'])
-+        realterminals = np.array(dataset['terminals'])
- 
-         self.observations_raw = observations
-         self.actions_raw = actions
-diff --git a/logs/stock_2330/gpt/azure/state_0.pt b/logs/stock_2330/gpt/azure/state_0.pt
-index 215a98c..2008ae4 100644
-Binary files a/logs/stock_2330/gpt/azure/state_0.pt and b/logs/stock_2330/gpt/azure/state_0.pt differ
\ No newline at end of file
diff --git a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/rollout.json b/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/rollout.json
deleted file mode 100644
index cc80aad..0000000
--- a/logs/DDQN_1_2330/plans/defaults/freq1_H2_beam32/0/rollout.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-  "gpt_epoch": 1000,
-  "return": 2588.0,
-  "step": 1186,
-  "term": true
-}
\ No newline at end of file
diff --git a/logs/Random_policy-20230509135523-stock_market.log b/logs/Random_policy-20230509135523-stock_market.log
deleted file mode 100644
index e9c502f..0000000
--- a/logs/Random_policy-20230509135523-stock_market.log
+++ /dev/null
@@ -1,1582 +0,0 @@
-[2023-05-09 13:55:23,326] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,328] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,329] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,329] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,331] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,332] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,333] Code: 2303, buy success, cash: 93790.00, holding value:6210.00
-[2023-05-09 13:55:23,335] Code: 2303, hold success, cash: 93790.00, holding value:6190.00
-[2023-05-09 13:55:23,336] Code: 2303, hold success, cash: 93790.00, holding value:6330.00
-[2023-05-09 13:55:23,337] Code: 2303, sell success, cash: 100060.00, holding value:0.00
-[2023-05-09 13:55:23,338] Code: 2303, buy success, cash: 93630.00, holding value:6430.00
-[2023-05-09 13:55:23,339] Code: 2303, sell success, cash: 100010.00, holding value:0.00
-[2023-05-09 13:55:23,341] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,342] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,343] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,344] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,344] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,345] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,346] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,348] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,354] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,355] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,356] Code: 2303, buy success, cash: 94470.00, holding value:5540.00
-[2023-05-09 13:55:23,358] Code: 2303, buy success, cash: 89170.00, holding value:10600.00
-[2023-05-09 13:55:23,361] Code: 2303, hold success, cash: 89170.00, holding value:10700.00
-[2023-05-09 13:55:23,362] Code: 2303, sell success, cash: 94580.00, holding value:5410.00
-[2023-05-09 13:55:23,365] Code: 2303, sell success, cash: 100020.00, holding value:0.00
-[2023-05-09 13:55:23,369] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,375] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,377] Code: 2303, buy success, cash: 94740.00, holding value:5280.00
-[2023-05-09 13:55:23,378] Code: 2303, buy success, cash: 89380.00, holding value:10720.00
-[2023-05-09 13:55:23,380] Code: 2303, buy success, cash: 84200.00, holding value:15540.00
-[2023-05-09 13:55:23,382] Code: 2303, buy success, cash: 78990.00, holding value:20840.00
-[2023-05-09 13:55:23,384] Code: 2303, hold success, cash: 78990.00, holding value:21640.00
-[2023-05-09 13:55:23,390] Code: 2303, buy success, cash: 73630.00, holding value:26800.00
-[2023-05-09 13:55:23,393] Code: 2303, hold success, cash: 73630.00, holding value:27100.00
-[2023-05-09 13:55:23,395] Code: 2303, sell success, cash: 78970.00, holding value:21360.00
-[2023-05-09 13:55:23,395] Code: 2303, sell success, cash: 84130.00, holding value:15480.00
-[2023-05-09 13:55:23,397] Code: 2303, buy success, cash: 79160.00, holding value:19880.00
-[2023-05-09 13:55:23,398] Code: 2303, buy success, cash: 73980.00, holding value:25900.00
-[2023-05-09 13:55:23,405] Code: 2303, sell success, cash: 79260.00, holding value:21120.00
-[2023-05-09 13:55:23,406] Code: 2303, sell success, cash: 84510.00, holding value:15750.00
-[2023-05-09 13:55:23,408] Code: 2303, hold success, cash: 84510.00, holding value:15750.00
-[2023-05-09 13:55:23,409] Code: 2303, hold success, cash: 84510.00, holding value:15120.00
-[2023-05-09 13:55:23,411] Code: 2303, buy success, cash: 79430.00, holding value:20320.00
-[2023-05-09 13:55:23,412] Code: 2303, hold success, cash: 79430.00, holding value:21040.00
-[2023-05-09 13:55:23,414] Code: 2303, sell success, cash: 84710.00, holding value:15840.00
-[2023-05-09 13:55:23,415] Code: 2303, hold success, cash: 84710.00, holding value:16050.00
-[2023-05-09 13:55:23,420] Code: 2303, buy success, cash: 79360.00, holding value:21400.00
-[2023-05-09 13:55:23,424] Code: 2303, hold success, cash: 79360.00, holding value:21520.00
-[2023-05-09 13:55:23,425] Code: 2303, sell success, cash: 84680.00, holding value:15960.00
-[2023-05-09 13:55:23,427] Code: 2303, buy success, cash: 79350.00, holding value:21320.00
-[2023-05-09 13:55:23,429] Code: 2303, sell success, cash: 84710.00, holding value:16080.00
-[2023-05-09 13:55:23,430] Code: 2303, buy success, cash: 79340.00, holding value:21480.00
-[2023-05-09 13:55:23,431] Code: 2303, sell success, cash: 84790.00, holding value:16350.00
-[2023-05-09 13:55:23,437] Code: 2303, sell success, cash: 90190.00, holding value:10800.00
-[2023-05-09 13:55:23,440] Code: 2303, hold success, cash: 90190.00, holding value:10580.00
-[2023-05-09 13:55:23,442] Code: 2303, buy success, cash: 85080.00, holding value:15330.00
-[2023-05-09 13:55:23,443] Code: 2303, sell success, cash: 90080.00, holding value:10000.00
-[2023-05-09 13:55:23,444] Code: 2303, sell success, cash: 95080.00, holding value:5000.00
-[2023-05-09 13:55:23,446] Code: 2303, buy success, cash: 90260.00, holding value:9640.00
-[2023-05-09 13:55:23,447] Code: 2303, hold success, cash: 90260.00, holding value:9460.00
-[2023-05-09 13:55:23,448] Code: 2303, hold success, cash: 90260.00, holding value:9700.00
-[2023-05-09 13:55:23,455] Code: 2303, buy success, cash: 85435.00, holding value:14475.00
-[2023-05-09 13:55:23,457] Code: 2303, sell success, cash: 90140.00, holding value:9410.00
-[2023-05-09 13:55:23,459] Code: 2303, buy success, cash: 85520.00, holding value:13860.00
-[2023-05-09 13:55:23,461] Code: 2303, sell success, cash: 90185.00, holding value:9330.00
-[2023-05-09 13:55:23,463] Code: 2303, sell success, cash: 94950.00, holding value:4765.00
-[2023-05-09 13:55:23,463] Code: 2303, sell success, cash: 99755.00, holding value:0.00
-[2023-05-09 13:55:23,465] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,466] Code: 2303, buy success, cash: 95205.00, holding value:4550.00
-[2023-05-09 13:55:23,470] Code: 2303, hold success, cash: 95205.00, holding value:4575.00
-[2023-05-09 13:55:23,471] Code: 2303, buy success, cash: 90765.00, holding value:8880.00
-[2023-05-09 13:55:23,474] Code: 2303, buy success, cash: 85915.00, holding value:14550.00
-[2023-05-09 13:55:23,475] Code: 2303, hold success, cash: 85915.00, holding value:14340.00
-[2023-05-09 13:55:23,477] Code: 2303, hold success, cash: 85915.00, holding value:14175.00
-[2023-05-09 13:55:23,479] Code: 2303, buy success, cash: 81085.00, holding value:19320.00
-[2023-05-09 13:55:23,480] Code: 2303, hold success, cash: 81085.00, holding value:19640.00
-[2023-05-09 13:55:23,481] Code: 2303, hold success, cash: 81085.00, holding value:19420.00
-[2023-05-09 13:55:23,483] Code: 2303, buy success, cash: 76295.00, holding value:23950.00
-[2023-05-09 13:55:23,483] Code: 2303, sell success, cash: 81185.00, holding value:19560.00
-[2023-05-09 13:55:23,489] Code: 2303, sell success, cash: 86050.00, holding value:14595.00
-[2023-05-09 13:55:23,490] Code: 2303, sell success, cash: 90830.00, holding value:9560.00
-[2023-05-09 13:55:23,492] Code: 2303, sell success, cash: 95715.00, holding value:4885.00
-[2023-05-09 13:55:23,494] Code: 2303, buy success, cash: 90770.00, holding value:9890.00
-[2023-05-09 13:55:23,496] Code: 2303, hold success, cash: 90770.00, holding value:10020.00
-[2023-05-09 13:55:23,497] Code: 2303, sell success, cash: 95860.00, holding value:5090.00
-[2023-05-09 13:55:23,498] Code: 2303, sell success, cash: 100940.00, holding value:0.00
-[2023-05-09 13:55:23,501] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,501] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,502] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,507] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,510] Code: 2303, buy success, cash: 96000.00, holding value:4940.00
-[2023-05-09 13:55:23,512] Code: 2303, hold success, cash: 96000.00, holding value:5020.00
-[2023-05-09 13:55:23,513] Code: 2303, sell success, cash: 101100.00, holding value:0.00
-[2023-05-09 13:55:23,514] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:23,516] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,516] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,522] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:23,523] Code: 2303, buy success, cash: 95930.00, holding value:5170.00
-[2023-05-09 13:55:23,526] Code: 2303, hold success, cash: 95930.00, holding value:5240.00
-[2023-05-09 13:55:23,526] Code: 2303, sell success, cash: 101110.00, holding value:0.00
-[2023-05-09 13:55:23,528] Code: 2303, buy success, cash: 95990.00, holding value:5120.00
-[2023-05-09 13:55:23,529] Code: 2303, hold success, cash: 95990.00, holding value:5000.00
-[2023-05-09 13:55:23,532] Code: 2303, sell success, cash: 100950.00, holding value:0.00
-[2023-05-09 13:55:23,533] Code: 2303, buy success, cash: 95985.00, holding value:4965.00
-[2023-05-09 13:55:23,534] Code: 2303, hold success, cash: 95985.00, holding value:4910.00
-[2023-05-09 13:55:23,538] Code: 2303, hold success, cash: 95985.00, holding value:4765.00
-[2023-05-09 13:55:23,541] Code: 2303, sell success, cash: 100790.00, holding value:0.00
-[2023-05-09 13:55:23,543] Code: 2303, buy success, cash: 95860.00, holding value:4930.00
-[2023-05-09 13:55:23,544] Code: 2303, hold success, cash: 95860.00, holding value:4410.00
-[2023-05-09 13:55:23,546] Code: 2303, hold success, cash: 95860.00, holding value:4200.00
-[2023-05-09 13:55:23,547] Code: 2303, buy success, cash: 91700.00, holding value:8320.00
-[2023-05-09 13:55:23,548] Code: 2303, hold success, cash: 91700.00, holding value:8580.00
-[2023-05-09 13:55:23,550] Code: 2303, sell success, cash: 95885.00, holding value:4185.00
-[2023-05-09 13:55:23,553] Code: 2303, buy success, cash: 91795.00, holding value:8180.00
-[2023-05-09 13:55:23,557] Code: 2303, hold success, cash: 91795.00, holding value:7830.00
-[2023-05-09 13:55:23,558] Code: 2303, buy success, cash: 87990.00, holding value:11415.00
-[2023-05-09 13:55:23,559] Code: 2303, sell success, cash: 91805.00, holding value:7630.00
-[2023-05-09 13:55:23,561] Code: 2303, hold success, cash: 91805.00, holding value:7780.00
-[2023-05-09 13:55:23,562] Code: 2303, buy success, cash: 88090.00, holding value:11145.00
-[2023-05-09 13:55:23,564] Code: 2303, hold success, cash: 88090.00, holding value:11955.00
-[2023-05-09 13:55:23,565] Code: 2303, hold success, cash: 88090.00, holding value:11910.00
-[2023-05-09 13:55:23,566] Code: 2303, hold success, cash: 88090.00, holding value:11580.00
-[2023-05-09 13:55:23,568] Code: 2303, hold success, cash: 88090.00, holding value:11025.00
-[2023-05-09 13:55:23,573] Code: 2303, hold success, cash: 88090.00, holding value:11415.00
-[2023-05-09 13:55:23,575] Code: 2303, buy success, cash: 84210.00, holding value:15520.00
-[2023-05-09 13:55:23,577] Code: 2303, hold success, cash: 84210.00, holding value:15580.00
-[2023-05-09 13:55:23,577] Code: 2303, hold success, cash: 84210.00, holding value:16000.00
-[2023-05-09 13:55:23,579] Code: 2303, sell success, cash: 88200.00, holding value:11970.00
-[2023-05-09 13:55:23,580] Code: 2303, hold success, cash: 88200.00, holding value:12225.00
-[2023-05-09 13:55:23,583] Code: 2303, sell success, cash: 92480.00, holding value:8560.00
-[2023-05-09 13:55:23,586] Code: 2303, hold success, cash: 92480.00, holding value:8490.00
-[2023-05-09 13:55:23,588] Code: 2303, hold success, cash: 92480.00, holding value:8100.00
-[2023-05-09 13:55:23,590] Code: 2303, hold success, cash: 92480.00, holding value:7720.00
-[2023-05-09 13:55:23,592] Code: 2303, buy success, cash: 88535.00, holding value:11835.00
-[2023-05-09 13:55:23,594] Code: 2303, buy success, cash: 84655.00, holding value:15520.00
-[2023-05-09 13:55:23,595] Code: 2303, hold success, cash: 84655.00, holding value:16060.00
-[2023-05-09 13:55:23,597] Code: 2303, hold success, cash: 84655.00, holding value:16120.00
-[2023-05-09 13:55:23,598] Code: 2303, hold success, cash: 84655.00, holding value:15640.00
-[2023-05-09 13:55:23,600] Code: 2303, sell success, cash: 88585.00, holding value:11790.00
-[2023-05-09 13:55:23,600] Code: 2303, buy success, cash: 84585.00, holding value:16000.00
-[2023-05-09 13:55:23,604] Code: 2303, hold success, cash: 84585.00, holding value:16860.00
-[2023-05-09 13:55:23,607] Code: 2303, hold success, cash: 84585.00, holding value:16420.00
-[2023-05-09 13:55:23,610] Code: 2303, sell success, cash: 88690.00, holding value:12315.00
-[2023-05-09 13:55:23,610] Code: 2303, buy success, cash: 84660.00, holding value:16120.00
-[2023-05-09 13:55:23,612] Code: 2303, buy success, cash: 80490.00, holding value:20850.00
-[2023-05-09 13:55:23,613] Code: 2303, hold success, cash: 80490.00, holding value:21175.00
-[2023-05-09 13:55:23,615] Code: 2303, sell success, cash: 84840.00, holding value:17400.00
-[2023-05-09 13:55:23,616] Code: 2303, hold success, cash: 84840.00, holding value:17220.00
-[2023-05-09 13:55:23,619] Code: 2303, hold success, cash: 84840.00, holding value:17140.00
-[2023-05-09 13:55:23,623] Code: 2303, hold success, cash: 84840.00, holding value:17000.00
-[2023-05-09 13:55:23,624] Code: 2303, sell success, cash: 89140.00, holding value:12900.00
-[2023-05-09 13:55:23,627] Code: 2303, buy success, cash: 84955.00, holding value:16740.00
-[2023-05-09 13:55:23,628] Code: 2303, hold success, cash: 84955.00, holding value:16320.00
-[2023-05-09 13:55:23,629] Code: 2303, buy success, cash: 80865.00, holding value:20450.00
-[2023-05-09 13:55:23,631] Code: 2303, sell success, cash: 85005.00, holding value:16560.00
-[2023-05-09 13:55:23,633] Code: 2303, hold success, cash: 85005.00, holding value:16520.00
-[2023-05-09 13:55:23,634] Code: 2303, hold success, cash: 85005.00, holding value:15980.00
-[2023-05-09 13:55:23,639] Code: 2303, buy success, cash: 80965.00, holding value:20200.00
-[2023-05-09 13:55:23,640] Code: 2303, buy success, cash: 76855.00, holding value:24660.00
-[2023-05-09 13:55:23,645] Code: 2303, buy success, cash: 72810.00, holding value:28315.00
-[2023-05-09 13:55:23,646] Code: 2303, sell success, cash: 76860.00, holding value:24300.00
-[2023-05-09 13:55:23,647] Code: 2303, buy success, cash: 72880.00, holding value:27860.00
-[2023-05-09 13:55:23,649] Code: 2303, hold success, cash: 72880.00, holding value:27965.00
-[2023-05-09 13:55:23,650] Code: 2303, hold success, cash: 72880.00, holding value:27440.00
-[2023-05-09 13:55:23,652] Code: 2303, hold success, cash: 72880.00, holding value:27510.00
-[2023-05-09 13:55:23,654] Code: 2303, sell success, cash: 76895.00, holding value:24090.00
-[2023-05-09 13:55:23,655] Code: 2303, hold success, cash: 76895.00, holding value:24450.00
-[2023-05-09 13:55:23,657] Code: 2303, sell success, cash: 80910.00, holding value:20075.00
-[2023-05-09 13:55:23,662] Code: 2303, buy success, cash: 76870.00, holding value:24240.00
-[2023-05-09 13:55:23,663] Code: 2303, hold success, cash: 76870.00, holding value:23970.00
-[2023-05-09 13:55:23,665] Code: 2303, sell success, cash: 80865.00, holding value:19975.00
-[2023-05-09 13:55:23,666] Code: 2303, sell success, cash: 84880.00, holding value:16060.00
-[2023-05-09 13:55:23,668] Code: 2303, sell success, cash: 88840.00, holding value:11880.00
-[2023-05-09 13:55:23,671] Code: 2303, buy success, cash: 84965.00, holding value:15500.00
-[2023-05-09 13:55:23,674] Code: 2303, hold success, cash: 84965.00, holding value:15320.00
-[2023-05-09 13:55:23,676] Code: 2303, buy success, cash: 81280.00, holding value:18425.00
-[2023-05-09 13:55:23,678] Code: 2303, sell success, cash: 85010.00, holding value:14920.00
-[2023-05-09 13:55:23,679] Code: 2303, buy success, cash: 81390.00, holding value:18100.00
-[2023-05-09 13:55:23,681] Code: 2303, sell success, cash: 85045.00, holding value:14620.00
-[2023-05-09 13:55:23,682] Code: 2303, hold success, cash: 85045.00, holding value:14300.00
-[2023-05-09 13:55:23,684] Code: 2303, hold success, cash: 85045.00, holding value:14140.00
-[2023-05-09 13:55:23,684] Code: 2303, sell success, cash: 88815.00, holding value:11310.00
-[2023-05-09 13:55:23,690] Code: 2303, sell success, cash: 92645.00, holding value:7660.00
-[2023-05-09 13:55:23,691] Code: 2303, hold success, cash: 92645.00, holding value:7790.00
-[2023-05-09 13:55:23,693] Code: 2303, hold success, cash: 92645.00, holding value:7610.00
-[2023-05-09 13:55:23,695] Code: 2303, sell success, cash: 96185.00, holding value:3540.00
-[2023-05-09 13:55:23,777] Code: 2303, buy success, cash: 92515.00, holding value:7340.00
-[2023-05-09 13:55:23,781] Code: 2303, hold success, cash: 92515.00, holding value:7280.00
-[2023-05-09 13:55:23,784] Code: 2303, hold success, cash: 92515.00, holding value:7740.00
-[2023-05-09 13:55:23,785] Code: 2303, buy success, cash: 88740.00, holding value:11325.00
-[2023-05-09 13:55:23,791] Code: 2303, buy success, cash: 84915.00, holding value:15300.00
-[2023-05-09 13:55:23,793] Code: 2303, buy success, cash: 81095.00, holding value:19100.00
-[2023-05-09 13:55:23,795] Code: 2303, hold success, cash: 81095.00, holding value:19750.00
-[2023-05-09 13:55:23,796] Code: 2303, hold success, cash: 81095.00, holding value:19525.00
-[2023-05-09 13:55:23,796] Code: 2303, sell success, cash: 85035.00, holding value:15760.00
-[2023-05-09 13:55:23,797] Code: 2303, buy success, cash: 81090.00, holding value:19725.00
-[2023-05-09 13:55:23,799] Code: 2303, sell success, cash: 84900.00, holding value:15240.00
-[2023-05-09 13:55:23,799] Code: 2303, hold success, cash: 84900.00, holding value:15700.00
-[2023-05-09 13:55:23,800] Code: 2303, sell success, cash: 88730.00, holding value:11490.00
-[2023-05-09 13:55:23,801] Code: 2303, hold success, cash: 88730.00, holding value:11730.00
-[2023-05-09 13:55:23,801] Code: 2303, buy success, cash: 84825.00, holding value:15620.00
-[2023-05-09 13:55:23,802] Code: 2303, hold success, cash: 84825.00, holding value:15740.00
-[2023-05-09 13:55:23,803] Code: 2303, hold success, cash: 84825.00, holding value:15600.00
-[2023-05-09 13:55:23,807] Code: 2303, buy success, cash: 80935.00, holding value:19450.00
-[2023-05-09 13:55:23,809] Code: 2303, buy success, cash: 76930.00, holding value:24030.00
-[2023-05-09 13:55:23,810] Code: 2303, sell success, cash: 80945.00, holding value:20075.00
-[2023-05-09 13:55:23,811] Code: 2303, sell success, cash: 85090.00, holding value:16580.00
-[2023-05-09 13:55:23,814] Code: 2303, hold success, cash: 85090.00, holding value:16660.00
-[2023-05-09 13:55:23,817] Code: 2303, hold success, cash: 85090.00, holding value:17600.00
-[2023-05-09 13:55:23,820] Code: 2303, buy success, cash: 80600.00, holding value:22450.00
-[2023-05-09 13:55:23,820] Code: 2303, hold success, cash: 80600.00, holding value:23300.00
-[2023-05-09 13:55:23,821] Code: 2303, hold success, cash: 80600.00, holding value:22625.00
-[2023-05-09 13:55:23,823] Code: 2303, buy success, cash: 76040.00, holding value:27360.00
-[2023-05-09 13:55:23,823] Code: 2303, sell success, cash: 80600.00, holding value:22800.00
-[2023-05-09 13:55:23,826] Code: 2303, hold success, cash: 80600.00, holding value:22825.00
-[2023-05-09 13:55:23,827] Code: 2303, buy success, cash: 75990.00, holding value:27660.00
-[2023-05-09 13:55:23,828] Code: 2303, hold success, cash: 75990.00, holding value:27660.00
-[2023-05-09 13:55:23,830] Code: 2303, sell success, cash: 80610.00, holding value:23100.00
-[2023-05-09 13:55:23,830] Code: 2303, sell success, cash: 85190.00, holding value:18320.00
-[2023-05-09 13:55:23,831] Code: 2303, hold success, cash: 85190.00, holding value:17760.00
-[2023-05-09 13:55:23,832] Code: 2303, hold success, cash: 85190.00, holding value:17860.00
-[2023-05-09 13:55:23,835] Code: 2303, buy success, cash: 80610.00, holding value:22900.00
-[2023-05-09 13:55:23,836] Code: 2303, hold success, cash: 80610.00, holding value:22800.00
-[2023-05-09 13:55:23,838] Code: 2303, sell success, cash: 85160.00, holding value:18200.00
-[2023-05-09 13:55:23,840] Code: 2303, buy success, cash: 80620.00, holding value:22700.00
-[2023-05-09 13:55:23,841] Code: 2303, sell success, cash: 85070.00, holding value:17800.00
-[2023-05-09 13:55:23,842] Code: 2303, buy success, cash: 80705.00, holding value:21825.00
-[2023-05-09 13:55:23,845] Code: 2303, hold success, cash: 80705.00, holding value:21250.00
-[2023-05-09 13:55:23,846] Code: 2303, hold success, cash: 80705.00, holding value:21750.00
-[2023-05-09 13:55:23,848] Code: 2303, sell success, cash: 85055.00, holding value:17400.00
-[2023-05-09 13:55:23,848] Code: 2303, hold success, cash: 85055.00, holding value:17520.00
-[2023-05-09 13:55:23,850] Code: 2303, buy success, cash: 80610.00, holding value:22225.00
-[2023-05-09 13:55:23,850] Code: 2303, hold success, cash: 80610.00, holding value:22125.00
-[2023-05-09 13:55:23,853] Code: 2303, hold success, cash: 80610.00, holding value:22150.00
-[2023-05-09 13:55:23,855] Code: 2303, buy success, cash: 76315.00, holding value:25770.00
-[2023-05-09 13:55:23,856] Code: 2303, buy success, cash: 72130.00, holding value:29295.00
-[2023-05-09 13:55:23,858] Code: 2303, hold success, cash: 72130.00, holding value:29400.00
-[2023-05-09 13:55:23,859] Code: 2303, buy success, cash: 67845.00, holding value:34280.00
-[2023-05-09 13:55:23,860] Code: 2303, buy success, cash: 63650.00, holding value:37755.00
-[2023-05-09 13:55:23,862] Code: 2303, sell success, cash: 67840.00, holding value:33520.00
-[2023-05-09 13:55:23,863] Code: 2303, sell success, cash: 72025.00, holding value:29295.00
-[2023-05-09 13:55:23,864] Code: 2303, buy success, cash: 67945.00, holding value:32640.00
-[2023-05-09 13:55:23,866] Code: 2303, hold success, cash: 67945.00, holding value:32600.00
-[2023-05-09 13:55:23,870] Code: 2303, hold success, cash: 67945.00, holding value:32560.00
-[2023-05-09 13:55:23,872] Code: 2303, sell success, cash: 72500.00, holding value:31885.00
-[2023-05-09 13:55:23,873] Code: 2303, sell success, cash: 77135.00, holding value:27810.00
-[2023-05-09 13:55:23,875] Code: 2303, sell success, cash: 81830.00, holding value:23475.00
-[2023-05-09 13:55:23,876] Code: 2303, buy success, cash: 77210.00, holding value:27720.00
-[2023-05-09 13:55:23,877] Code: 2303, hold success, cash: 77210.00, holding value:28710.00
-[2023-05-09 13:55:23,879] Code: 2303, sell success, cash: 82210.00, holding value:25000.00
-[2023-05-09 13:55:23,880] Code: 2303, sell success, cash: 87055.00, holding value:19380.00
-[2023-05-09 13:55:23,881] Code: 2303, hold success, cash: 87055.00, holding value:20000.00
-[2023-05-09 13:55:23,883] Code: 2303, hold success, cash: 87055.00, holding value:19960.00
-[2023-05-09 13:55:23,886] Code: 2303, hold success, cash: 87055.00, holding value:19500.00
-[2023-05-09 13:55:23,888] Code: 2303, hold success, cash: 87055.00, holding value:19860.00
-[2023-05-09 13:55:23,889] Code: 2303, hold success, cash: 87055.00, holding value:21200.00
-[2023-05-09 13:55:23,891] Code: 2303, buy success, cash: 81845.00, holding value:26050.00
-[2023-05-09 13:55:23,891] Code: 2303, buy success, cash: 76445.00, holding value:32400.00
-[2023-05-09 13:55:23,895] Code: 2303, buy success, cash: 70795.00, holding value:39550.00
-[2023-05-09 13:55:23,895] Code: 2303, sell success, cash: 76515.00, holding value:34320.00
-[2023-05-09 13:55:23,897] Code: 2303, buy success, cash: 71035.00, holding value:38360.00
-[2023-05-09 13:55:23,898] Code: 2303, hold success, cash: 71035.00, holding value:38360.00
-[2023-05-09 13:55:23,900] Code: 2303, hold success, cash: 71035.00, holding value:35840.00
-[2023-05-09 13:55:23,901] Code: 2303, buy success, cash: 66035.00, holding value:40000.00
-[2023-05-09 13:55:23,903] Code: 2303, buy success, cash: 60955.00, holding value:45720.00
-[2023-05-09 13:55:23,905] Code: 2303, hold success, cash: 60955.00, holding value:47340.00
-[2023-05-09 13:55:23,906] Code: 2303, buy success, cash: 55755.00, holding value:52000.00
-[2023-05-09 13:55:23,907] Code: 2303, buy success, cash: 50565.00, holding value:57090.00
-[2023-05-09 13:55:23,909] Code: 2303, sell success, cash: 55855.00, holding value:52900.00
-[2023-05-09 13:55:23,912] Code: 2303, sell success, cash: 61615.00, holding value:51840.00
-[2023-05-09 13:55:23,913] Code: 2303, hold success, cash: 61615.00, holding value:52380.00
-[2023-05-09 13:55:23,914] Code: 2303, buy success, cash: 55895.00, holding value:57200.00
-[2023-05-09 13:55:23,915] Code: 2303, hold success, cash: 55895.00, holding value:56800.00
-[2023-05-09 13:55:23,917] Code: 2303, buy success, cash: 50315.00, holding value:61380.00
-[2023-05-09 13:55:23,920] Code: 2303, hold success, cash: 50315.00, holding value:60170.00
-[2023-05-09 13:55:23,921] Code: 2303, hold success, cash: 50315.00, holding value:61270.00
-[2023-05-09 13:55:23,923] Code: 2303, hold success, cash: 50315.00, holding value:59620.00
-[2023-05-09 13:55:23,924] Code: 2303, buy success, cash: 45045.00, holding value:63240.00
-[2023-05-09 13:55:23,926] Code: 2303, buy success, cash: 39855.00, holding value:67470.00
-[2023-05-09 13:55:23,928] Code: 2303, hold success, cash: 39855.00, holding value:63765.00
-[2023-05-09 13:55:23,930] Code: 2303, buy success, cash: 35150.00, holding value:65870.00
-[2023-05-09 13:55:23,931] Code: 2303, hold success, cash: 35150.00, holding value:64540.00
-[2023-05-09 13:55:23,933] Code: 2303, sell success, cash: 39785.00, holding value:60255.00
-[2023-05-09 13:55:23,934] Code: 2303, sell success, cash: 44440.00, holding value:55860.00
-[2023-05-09 13:55:23,934] Code: 2303, sell success, cash: 49305.00, holding value:53515.00
-[2023-05-09 13:55:23,938] Code: 2303, sell success, cash: 54215.00, holding value:49100.00
-[2023-05-09 13:55:23,939] Code: 2303, buy success, cash: 49400.00, holding value:52965.00
-[2023-05-09 13:55:23,941] Code: 2303, sell success, cash: 54230.00, holding value:48300.00
-[2023-05-09 13:55:23,942] Code: 2303, sell success, cash: 59030.00, holding value:43200.00
-[2023-05-09 13:55:23,945] Code: 2303, hold success, cash: 59030.00, holding value:42345.00
-[2023-05-09 13:55:23,946] Code: 2303, buy success, cash: 54425.00, holding value:46050.00
-[2023-05-09 13:55:23,947] Code: 2303, sell success, cash: 59245.00, holding value:43380.00
-[2023-05-09 13:55:23,948] Code: 2303, sell success, cash: 64095.00, holding value:38800.00
-[2023-05-09 13:55:23,950] Code: 2303, sell success, cash: 68810.00, holding value:33005.00
-[2023-05-09 13:55:23,951] Code: 2303, buy success, cash: 63945.00, holding value:38920.00
-[2023-05-09 13:55:23,955] Code: 2303, hold success, cash: 63945.00, holding value:39800.00
-[2023-05-09 13:55:23,956] Code: 2303, hold success, cash: 63945.00, holding value:39480.00
-[2023-05-09 13:55:23,958] Code: 2303, buy success, cash: 58885.00, holding value:45540.00
-[2023-05-09 13:55:23,959] Code: 2303, hold success, cash: 58885.00, holding value:45180.00
-[2023-05-09 13:55:23,962] Code: 2303, buy success, cash: 53835.00, holding value:50500.00
-[2023-05-09 13:55:23,963] Code: 2303, buy success, cash: 48765.00, holding value:55770.00
-[2023-05-09 13:55:24,038] Code: 2303, sell success, cash: 53915.00, holding value:51500.00
-[2023-05-09 13:55:24,040] Code: 2303, sell success, cash: 59315.00, holding value:48600.00
-[2023-05-09 13:55:24,041] Code: 2303, buy success, cash: 54015.00, holding value:53000.00
-[2023-05-09 13:55:24,043] Code: 2303, hold success, cash: 54015.00, holding value:53600.00
-[2023-05-09 13:55:24,045] Code: 2303, sell success, cash: 59455.00, holding value:48960.00
-[2023-05-09 13:55:24,046] Code: 2303, sell success, cash: 64725.00, holding value:42160.00
-[2023-05-09 13:55:24,047] Code: 2303, sell success, cash: 70035.00, holding value:37170.00
-[2023-05-09 13:55:24,048] Code: 2303, sell success, cash: 75435.00, holding value:32400.00
-[2023-05-09 13:55:24,049] Code: 2303, sell success, cash: 80895.00, holding value:27300.00
-[2023-05-09 13:55:24,050] Code: 2303, buy success, cash: 75485.00, holding value:32460.00
-[2023-05-09 13:55:24,051] Code: 2303, sell success, cash: 80825.00, holding value:26700.00
-[2023-05-09 13:55:24,054] Code: 2303, buy success, cash: 75345.00, holding value:32880.00
-[2023-05-09 13:55:24,056] Code: 2303, buy success, cash: 69645.00, holding value:39900.00
-[2023-05-09 13:55:24,057] Code: 2303, sell success, cash: 75825.00, holding value:37080.00
-[2023-05-09 13:55:24,058] Code: 2303, hold success, cash: 75825.00, holding value:36300.00
-[2023-05-09 13:55:24,061] Code: 2303, sell success, cash: 81825.00, holding value:30000.00
-[2023-05-09 13:55:24,062] Code: 2303, buy success, cash: 76155.00, holding value:34020.00
-[2023-05-09 13:55:24,063] Code: 2303, hold success, cash: 76155.00, holding value:31800.00
-[2023-05-09 13:55:24,064] Code: 2303, hold success, cash: 76155.00, holding value:32760.00
-[2023-05-09 13:55:24,065] Code: 2303, buy success, cash: 70975.00, holding value:36260.00
-[2023-05-09 13:55:24,067] Code: 2303, hold success, cash: 70975.00, holding value:35910.00
-[2023-05-09 13:55:24,070] Code: 2303, buy success, cash: 65575.00, holding value:43200.00
-[2023-05-09 13:55:24,072] Code: 2303, buy success, cash: 60325.00, holding value:47250.00
-[2023-05-09 13:55:24,073] Code: 2303, buy success, cash: 55425.00, holding value:49000.00
-[2023-05-09 13:55:24,075] Code: 2303, sell success, cash: 60060.00, holding value:41715.00
-[2023-05-09 13:55:24,076] Code: 2303, buy success, cash: 55305.00, holding value:47550.00
-[2023-05-09 13:55:24,078] Code: 2303, hold success, cash: 55305.00, holding value:46800.00
-[2023-05-09 13:55:24,079] Code: 2303, hold success, cash: 55305.00, holding value:43950.00
-[2023-05-09 13:55:24,080] Code: 2303, hold success, cash: 55305.00, holding value:48300.00
-[2023-05-09 13:55:24,081] Code: 2303, hold success, cash: 55305.00, holding value:48300.00
-[2023-05-09 13:55:24,082] Code: 2303, hold success, cash: 55305.00, holding value:46500.00
-[2023-05-09 13:55:24,084] Code: 2303, buy success, cash: 50610.00, holding value:51645.00
-[2023-05-09 13:55:24,088] Code: 2303, sell success, cash: 55480.00, holding value:48700.00
-[2023-05-09 13:55:24,089] Code: 2303, buy success, cash: 50290.00, holding value:57090.00
-[2023-05-09 13:55:24,090] Code: 2303, sell success, cash: 55420.00, holding value:51300.00
-[2023-05-09 13:55:24,092] Code: 2303, hold success, cash: 55420.00, holding value:50600.00
-[2023-05-09 13:55:24,092] Code: 2303, buy success, cash: 50180.00, holding value:57640.00
-[2023-05-09 13:55:24,093] Code: 2303, sell success, cash: 55480.00, holding value:53000.00
-[2023-05-09 13:55:24,095] Code: 2303, buy success, cash: 50260.00, holding value:57420.00
-[2023-05-09 13:55:24,096] Code: 2303, buy success, cash: 45060.00, holding value:62400.00
-[2023-05-09 13:55:24,097] Code: 2303, sell success, cash: 50560.00, holding value:60500.00
-[2023-05-09 13:55:24,099] Code: 2303, buy success, cash: 45260.00, holding value:63600.00
-[2023-05-09 13:55:24,101] Code: 2303, buy success, cash: 40030.00, holding value:67990.00
-[2023-05-09 13:55:24,102] Code: 2303, buy success, cash: 34810.00, holding value:73080.00
-[2023-05-09 13:55:24,105] Code: 2303, sell success, cash: 39880.00, holding value:65910.00
-[2023-05-09 13:55:24,106] Code: 2303, hold success, cash: 39880.00, holding value:66950.00
-[2023-05-09 13:55:24,107] Code: 2303, hold success, cash: 39880.00, holding value:67340.00
-[2023-05-09 13:55:24,109] Code: 2303, hold success, cash: 39880.00, holding value:69810.00
-[2023-05-09 13:55:24,110] Code: 2303, sell success, cash: 45120.00, holding value:62880.00
-[2023-05-09 13:55:24,111] Code: 2303, buy success, cash: 39790.00, holding value:69290.00
-[2023-05-09 13:55:24,112] Code: 2303, buy success, cash: 34570.00, holding value:73080.00
-[2023-05-09 13:55:24,114] Code: 2303, sell success, cash: 39690.00, holding value:66560.00
-[2023-05-09 13:55:24,116] Code: 2303, hold success, cash: 39690.00, holding value:66300.00
-[2023-05-09 13:55:24,117] Code: 2303, hold success, cash: 39690.00, holding value:68900.00
-[2023-05-09 13:55:24,120] Code: 2303, buy success, cash: 34390.00, holding value:74200.00
-[2023-05-09 13:55:24,122] Code: 2303, hold success, cash: 34390.00, holding value:74060.00
-[2023-05-09 13:55:24,123] Code: 2303, hold success, cash: 34390.00, holding value:73640.00
-[2023-05-09 13:55:24,124] Code: 2303, hold success, cash: 34390.00, holding value:74200.00
-[2023-05-09 13:55:24,125] Code: 2303, buy success, cash: 29080.00, holding value:79650.00
-[2023-05-09 13:55:24,221] Code: 2303, buy success, cash: 23330.00, holding value:92000.00
-[2023-05-09 13:55:24,226] Code: 2303, buy success, cash: 17390.00, holding value:100980.00
-[2023-05-09 13:55:24,229] Code: 2303, sell success, cash: 23440.00, holding value:96800.00
-[2023-05-09 13:55:24,230] Code: 2303, hold success, cash: 23440.00, holding value:101440.00
-[2023-05-09 13:55:24,231] Code: 2303, hold success, cash: 23440.00, holding value:99360.00
-[2023-05-09 13:55:24,242] Code: 2303, buy success, cash: 17250.00, holding value:105230.00
-[2023-05-09 13:55:24,290] Code: 2303, buy success, cash: 11270.00, holding value:107640.00
-[2023-05-09 13:55:24,292] Code: 2303, hold success, cash: 11270.00, holding value:107820.00
-[2023-05-09 13:55:24,294] Code: 2303, hold success, cash: 11270.00, holding value:108180.00
-[2023-05-09 13:55:24,295] Code: 2303, buy success, cash: 5510.00, holding value:109440.00
-[2023-05-09 13:55:24,296] Code: 2303, buy success, cash: 28.40, holding value:113971.60
-[2023-05-09 13:55:24,297] Code: 2303, not enough cash, cannot buy.
-[2023-05-09 13:55:24,299] Code: 2303, sell success, cash: 5838.40, holding value:110157.60
-[2023-05-09 13:55:24,300] Code: 2303, sell success, cash: 11388.40, holding value:99678.00
-[2023-05-09 13:55:24,305] Code: 2303, sell success, cash: 16958.40, holding value:94467.20
-[2023-05-09 13:55:24,307] Code: 2303, sell success, cash: 22818.40, holding value:93525.60
-[2023-05-09 13:55:24,308] Code: 2303, hold success, cash: 22818.40, holding value:93206.40
-[2023-05-09 13:55:24,312] Code: 2303, sell success, cash: 28818.40, holding value:89760.00
-[2023-05-09 13:55:24,313] Code: 2303, hold success, cash: 28818.40, holding value:91555.20
-[2023-05-09 13:55:24,315] Code: 2303, hold success, cash: 28818.40, holding value:92303.20
-[2023-05-09 13:55:24,318] Code: 2303, buy success, cash: 22538.40, holding value:100228.80
-[2023-05-09 13:55:24,319] Code: 2303, hold success, cash: 22538.40, holding value:100707.60
-[2023-05-09 13:55:24,327] Code: 2303, buy success, cash: 16128.40, holding value:108713.60
-[2023-05-09 13:55:24,330] Code: 2303, hold success, cash: 16128.40, holding value:108544.00
-[2023-05-09 13:55:24,331] Code: 2303, sell success, cash: 23128.40, holding value:111720.00
-[2023-05-09 13:55:24,332] Code: 2303, buy success, cash: 16138.40, holding value:118550.40
-[2023-05-09 13:55:24,335] Code: 2303, sell success, cash: 22958.40, holding value:108847.20
-[2023-05-09 13:55:24,341] Code: 2303, buy success, cash: 16378.40, holding value:111596.80
-[2023-05-09 13:55:24,343] Code: 2303, hold success, cash: 16378.40, holding value:114480.00
-[2023-05-09 13:55:24,344] Code: 2303, buy success, cash: 9558.40, holding value:122487.20
-[2023-05-09 13:55:24,345] Code: 2303, hold success, cash: 9558.40, holding value:119972.80
-[2023-05-09 13:55:24,346] Code: 2303, buy success, cash: 2958.40, holding value:125136.00
-[2023-05-09 13:55:24,347] Code: 2303, hold success, cash: 2958.40, holding value:124377.60
-[2023-05-09 13:55:24,348] Code: 2303, buy success, cash: 45.60, holding value:128428.00
-[2023-05-09 13:55:24,348] Code: 2303, not enough cash, cannot buy.
-[2023-05-09 13:55:24,349] Code: 2303, not enough cash, cannot buy.
-[2023-05-09 13:55:24,350] Code: 2303, sell success, cash: 6565.60, holding value:119968.00
-[2023-05-09 13:55:24,357] Code: 2303, hold success, cash: 6565.60, holding value:123280.00
-[2023-05-09 13:55:24,358] Code: 2303, buy success, cash: 1.90, holding value:128555.70
-[2023-05-09 13:55:24,360] Code: 2303, sell success, cash: 6531.90, holding value:120086.70
-[2023-05-09 13:55:24,362] Code: 2303, sell success, cash: 12831.90, holding value:109557.00
-[2023-05-09 13:55:24,364] Code: 2303, hold success, cash: 12831.90, holding value:111296.00
-[2023-05-09 13:55:24,365] Code: 2303, hold success, cash: 12831.90, holding value:108861.40
-[2023-05-09 13:55:24,366] Code: 2303, hold success, cash: 12831.90, holding value:105731.20
-[2023-05-09 13:55:24,369] Code: 2303, buy success, cash: 6721.90, holding value:112362.90
-[2023-05-09 13:55:24,371] Code: 2303, hold success, cash: 6721.90, holding value:110156.10
-[2023-05-09 13:55:24,372] Code: 2303, hold success, cash: 6721.90, holding value:114937.50
-[2023-05-09 13:55:24,373] Code: 2303, sell success, cash: 12831.90, holding value:106252.90
-[2023-05-09 13:55:24,374] Code: 2303, hold success, cash: 12831.90, holding value:101731.50
-[2023-05-09 13:55:24,378] Code: 2303, hold success, cash: 12831.90, holding value:98079.60
-[2023-05-09 13:55:24,380] Code: 2303, hold success, cash: 12831.90, holding value:98601.30
-[2023-05-09 13:55:24,382] Code: 2303, sell success, cash: 18741.90, holding value:96864.90
-[2023-05-09 13:55:24,383] Code: 2303, sell success, cash: 24581.90, holding value:89877.60
-[2023-05-09 13:55:24,388] Code: 2303, hold success, cash: 24581.90, holding value:91724.40
-[2023-05-09 13:55:24,392] Code: 2303, sell success, cash: 30451.90, holding value:84469.30
-[2023-05-09 13:55:24,393] Code: 2303, buy success, cash: 24651.90, holding value:89262.00
-[2023-05-09 13:55:24,394] Code: 2303, buy success, cash: 18821.90, holding value:95553.70
-[2023-05-09 13:55:24,395] Code: 2303, sell success, cash: 24761.90, holding value:91416.60
-[2023-05-09 13:55:24,396] Code: 2303, sell success, cash: 30741.90, holding value:86052.20
-[2023-05-09 13:55:24,397] Code: 2303, sell success, cash: 36931.90, holding value:82884.10
-[2023-05-09 13:55:24,399] Code: 2303, hold success, cash: 36931.90, holding value:80072.20
-[2023-05-09 13:55:24,401] Code: 2303, hold success, cash: 36931.90, holding value:77662.00
-[2023-05-09 13:55:24,402] Code: 2303, hold success, cash: 36931.90, holding value:77126.40
-[2023-05-09 13:55:24,403] Code: 2303, sell success, cash: 42831.90, holding value:73101.00
-[2023-05-09 13:55:24,405] Code: 2303, hold success, cash: 42831.90, holding value:73348.80
-[2023-05-09 13:55:24,407] Code: 2303, hold success, cash: 42831.90, holding value:72605.40
-[2023-05-09 13:55:24,408] Code: 2303, buy success, cash: 36791.90, holding value:80875.60
-[2023-05-09 13:55:24,411] Code: 2303, sell success, cash: 43041.90, holding value:77437.50
-[2023-05-09 13:55:24,412] Code: 2303, sell success, cash: 49351.90, holding value:71870.90
-[2023-05-09 13:55:24,415] Code: 2303, sell success, cash: 55661.90, holding value:65560.90
-[2023-05-09 13:55:24,417] Code: 2303, buy success, cash: 49441.90, holding value:70845.80
-[2023-05-09 13:55:24,422] Code: 2303, hold success, cash: 49441.90, holding value:71301.40
-[2023-05-09 13:55:24,425] Code: 2303, buy success, cash: 43101.90, holding value:78552.60
-[2023-05-09 13:55:24,428] Code: 2303, buy success, cash: 36801.90, holding value:84357.00
-[2023-05-09 13:55:24,430] Code: 2303, buy success, cash: 30441.90, holding value:91520.40
-[2023-05-09 13:55:24,431] Code: 2303, sell success, cash: 36751.90, holding value:84490.90
-[2023-05-09 13:55:24,432] Code: 2303, sell success, cash: 43261.90, holding value:80658.90
-[2023-05-09 13:55:24,434] Code: 2303, hold success, cash: 43261.90, holding value:80163.30
-[2023-05-09 13:55:24,439] Code: 2303, buy success, cash: 36941.90, holding value:84624.80
-[2023-05-09 13:55:24,441] Code: 2303, sell success, cash: 43251.90, holding value:78180.90
-[2023-05-09 13:55:24,442] Code: 2303, hold success, cash: 43251.90, holding value:78057.00
-[2023-05-09 13:55:24,443] Code: 2303, hold success, cash: 43251.90, holding value:77437.50
-[2023-05-09 13:55:24,445] Code: 2303, buy success, cash: 37011.90, holding value:83553.60
-[2023-05-09 13:55:24,446] Code: 2303, hold success, cash: 37011.90, holding value:85294.30
-[2023-05-09 13:55:24,447] Code: 2303, sell success, cash: 43711.90, holding value:83013.00
-[2023-05-09 13:55:24,449] Code: 2303, sell success, cash: 50381.90, holding value:75971.30
-[2023-05-09 13:55:24,450] Code: 2303, buy success, cash: 43551.90, holding value:84623.70
-[2023-05-09 13:55:24,455] Code: 2303, hold success, cash: 43551.90, holding value:83384.70
-[2023-05-09 13:55:24,458] Code: 2303, sell success, cash: 50201.90, holding value:75743.50
-[2023-05-09 13:55:24,459] Code: 2303, hold success, cash: 50201.90, holding value:75743.50
-[2023-05-09 13:55:24,460] Code: 2303, hold success, cash: 50201.90, holding value:72896.00
-[2023-05-09 13:55:24,460] Code: 2303, buy success, cash: 43851.90, holding value:78676.50
-[2023-05-09 13:55:24,461] Code: 2303, buy success, cash: 37571.90, holding value:84089.20
-[2023-05-09 13:55:24,463] Code: 2303, buy success, cash: 31331.90, holding value:89793.60
-[2023-05-09 13:55:24,464] Code: 2303, hold success, cash: 31331.90, holding value:90225.30
-[2023-05-09 13:55:24,465] Code: 2303, buy success, cash: 25031.90, holding value:96957.00
-[2023-05-09 13:55:24,466] Code: 2303, sell success, cash: 31261.90, holding value:89649.70
-[2023-05-09 13:55:24,471] Code: 2303, sell success, cash: 37481.90, holding value:83285.80
-[2023-05-09 13:55:24,474] Code: 2303, buy success, cash: 31191.90, holding value:90513.10
-[2023-05-09 13:55:24,475] Code: 2303, buy success, cash: 24821.90, holding value:98034.30
-[2023-05-09 13:55:24,476] Code: 2303, hold success, cash: 24821.90, holding value:98342.10
-[2023-05-09 13:55:24,477] Code: 2303, hold success, cash: 24821.90, holding value:98957.70
-[2023-05-09 13:55:24,479] Code: 2303, buy success, cash: 18391.90, holding value:105387.70
-[2023-05-09 13:55:24,480] Code: 2303, sell success, cash: 24861.90, holding value:99573.30
-[2023-05-09 13:55:24,482] Code: 2303, buy success, cash: 18361.90, holding value:106535.00
-[2023-05-09 13:55:24,483] Code: 2303, buy success, cash: 11861.90, holding value:113035.00
-[2023-05-09 13:55:24,485] Code: 2303, hold success, cash: 11861.90, holding value:28780.45
-[2023-05-09 13:55:24,486] Code: 2303, buy success, cash: 10231.90, holding value:29975.70
-[2023-05-09 13:55:24,490] Code: 2303, buy success, cash: 8626.90, holding value:31120.95
-[2023-05-09 13:55:24,491] Code: 2303, sell success, cash: 10226.90, holding value:29424.00
-[2023-05-09 13:55:24,492] Code: 2303, sell success, cash: 11801.90, holding value:27389.25
-[2023-05-09 13:55:24,492] Code: 2303, hold success, cash: 11801.90, holding value:27910.95
-[2023-05-09 13:55:24,494] Code: 2303, sell success, cash: 13416.90, holding value:26469.85
-[2023-05-09 13:55:24,495] Code: 2303, buy success, cash: 11811.90, holding value:27910.95
-[2023-05-09 13:55:24,497] Code: 2303, sell success, cash: 13436.90, holding value:26633.75
-[2023-05-09 13:55:24,498] Code: 2303, hold success, cash: 13436.90, holding value:26469.85
-[2023-05-09 13:55:24,500] Code: 2303, sell success, cash: 15051.90, holding value:24854.85
-[2023-05-09 13:55:24,504] Code: 2303, sell success, cash: 16651.90, holding value:23024.00
-[2023-05-09 13:55:24,506] Code: 2303, sell success, cash: 18256.90, holding value:21490.95
-[2023-05-09 13:55:24,508] Code: 2303, sell success, cash: 19766.90, holding value:18708.90
-[2023-05-09 13:55:24,509] Code: 2303, buy success, cash: 18276.90, holding value:19951.10
-[2023-05-09 13:55:24,511] Code: 2303, hold success, cash: 18276.90, holding value:20085.00
-[2023-05-09 13:55:24,512] Code: 2303, hold success, cash: 18276.90, holding value:20352.80
-[2023-05-09 13:55:24,513] Code: 2303, sell success, cash: 19826.90, holding value:19204.50
-[2023-05-09 13:55:24,514] Code: 2303, hold success, cash: 19826.90, holding value:20133.75
-[2023-05-09 13:55:24,516] Code: 2303, buy success, cash: 18191.90, holding value:21892.65
-[2023-05-09 13:55:24,521] Code: 2303, buy success, cash: 16551.90, holding value:23599.60
-[2023-05-09 13:55:24,524] Code: 2303, buy success, cash: 14881.90, holding value:25701.30
-[2023-05-09 13:55:24,525] Code: 2303, sell success, cash: 16571.90, holding value:24319.10
-[2023-05-09 13:55:24,526] Code: 2303, buy success, cash: 14886.90, holding value:25932.15
-[2023-05-09 13:55:24,528] Code: 2303, hold success, cash: 14886.90, holding value:25393.50
-[2023-05-09 13:55:24,529] Code: 2303, hold success, cash: 14886.90, holding value:25239.60
-[2023-05-09 13:55:24,530] Code: 2303, hold success, cash: 14886.90, holding value:24854.85
-[2023-05-09 13:55:24,532] Code: 2303, sell success, cash: 16496.90, holding value:23167.90
-[2023-05-09 13:55:24,533] Code: 2303, sell success, cash: 18126.90, holding value:21825.70
-[2023-05-09 13:55:24,537] Code: 2303, buy success, cash: 16521.90, holding value:23095.95
-[2023-05-09 13:55:24,539] Code: 2303, buy success, cash: 14941.90, holding value:24316.20
-[2023-05-09 13:55:24,541] Code: 2303, buy success, cash: 13351.90, holding value:26060.10
-[2023-05-09 13:55:24,542] Code: 2303, hold success, cash: 13351.90, holding value:25568.40
-[2023-05-09 13:55:24,543] Code: 2303, hold success, cash: 13351.90, holding value:25076.70
-[2023-05-09 13:55:24,545] Code: 2303, hold success, cash: 13351.90, holding value:24994.75
-[2023-05-09 13:55:24,546] Code: 2303, buy success, cash: 11801.90, holding value:26954.50
-[2023-05-09 13:55:24,547] Code: 2303, hold success, cash: 11801.90, holding value:27476.20
-[2023-05-09 13:55:24,549] Code: 2303, sell success, cash: 13371.90, holding value:25732.30
-[2023-05-09 13:55:24,550] Code: 2303, sell success, cash: 14916.90, holding value:23777.55
-[2023-05-09 13:55:24,552] Code: 2303, buy success, cash: 13411.90, holding value:24666.95
-[2023-05-09 13:55:24,553] Code: 2303, buy success, cash: 11916.90, holding value:25998.05
-[2023-05-09 13:55:24,555] Code: 2303, buy success, cash: 10436.90, holding value:27217.20
-[2023-05-09 13:55:24,558] Code: 2303, sell success, cash: 11871.90, holding value:24954.65
-[2023-05-09 13:55:24,559] Code: 2303, sell success, cash: 13276.90, holding value:23027.95
-[2023-05-09 13:55:24,560] Code: 2303, sell success, cash: 14666.90, holding value:21392.10
-[2023-05-09 13:55:24,562] Code: 2303, hold success, cash: 14666.90, holding value:21161.25
-[2023-05-09 13:55:24,563] Code: 2303, hold success, cash: 14666.90, holding value:21238.20
-[2023-05-09 13:55:24,565] Code: 2303, buy success, cash: 13296.90, holding value:22454.30
-[2023-05-09 13:55:24,566] Code: 2303, buy success, cash: 11911.90, holding value:24085.15
-[2023-05-09 13:55:24,570] Code: 2303, hold success, cash: 11911.90, holding value:23911.25
-[2023-05-09 13:55:24,577] Code: 2303, hold success, cash: 11911.90, holding value:24085.15
-[2023-05-09 13:55:24,579] Code: 2303, sell success, cash: 13321.90, holding value:23109.90
-[2023-05-09 13:55:24,580] Code: 2303, sell success, cash: 14731.90, holding value:21699.90
-[2023-05-09 13:55:24,581] Code: 2303, hold success, cash: 14731.90, holding value:21546.00
-[2023-05-09 13:55:24,582] Code: 2303, sell success, cash: 16126.90, holding value:20074.05
-[2023-05-09 13:55:24,584] Code: 2303, hold success, cash: 16126.90, holding value:19642.35
-[2023-05-09 13:55:24,585] Code: 2303, buy success, cash: 14746.90, holding value:21238.20
-[2023-05-09 13:55:24,587] Code: 2303, sell success, cash: 16156.90, holding value:20289.90
-[2023-05-09 13:55:24,589] Code: 2303, buy success, cash: 14741.90, holding value:21776.85
-[2023-05-09 13:55:24,591] Code: 2303, hold success, cash: 14741.90, holding value:21853.80
-[2023-05-09 13:55:24,592] Code: 2303, hold success, cash: 14741.90, holding value:21853.80
-[2023-05-09 13:55:24,593] Code: 2303, hold success, cash: 14741.90, holding value:22007.70
-[2023-05-09 13:55:24,594] Code: 2303, hold success, cash: 14741.90, holding value:22777.20
-[2023-05-09 13:55:24,595] Code: 2303, buy success, cash: 13226.90, holding value:24830.85
-[2023-05-09 13:55:24,596] Code: 2303, buy success, cash: 11716.90, holding value:26258.90
-[2023-05-09 13:55:24,597] Code: 2303, buy success, cash: 10226.90, holding value:27401.10
-[2023-05-09 13:55:24,598] Code: 2303, sell success, cash: 11731.90, holding value:26171.95
-[2023-05-09 13:55:24,600] Code: 2303, hold success, cash: 11731.90, holding value:26345.85
-[2023-05-09 13:55:24,605] Code: 2303, buy success, cash: 10251.90, holding value:27217.20
-[2023-05-09 13:55:24,607] Code: 2303, hold success, cash: 10251.90, holding value:27952.80
-[2023-05-09 13:55:24,608] Code: 2303, hold success, cash: 10251.90, holding value:29056.20
-[2023-05-09 13:55:24,609] Code: 2303, sell success, cash: 11841.90, holding value:27650.10
-[2023-05-09 13:55:24,610] Code: 2303, hold success, cash: 11841.90, holding value:28084.85
-[2023-05-09 13:55:24,611] Code: 2303, sell success, cash: 13341.90, holding value:24585.00
-[2023-05-09 13:55:24,612] Code: 2303, sell success, cash: 14871.90, holding value:23546.70
-[2023-05-09 13:55:24,613] Code: 2303, sell success, cash: 16426.90, holding value:22376.45
-[2023-05-09 13:55:24,614] Code: 2303, sell success, cash: 17961.90, holding value:20553.65
-[2023-05-09 13:55:24,615] Code: 2303, sell success, cash: 19486.90, holding value:18894.75
-[2023-05-09 13:55:24,616] Code: 2303, buy success, cash: 17956.90, holding value:20486.70
-[2023-05-09 13:55:24,617] Code: 2303, hold success, cash: 17956.90, holding value:20888.40
-[2023-05-09 13:55:24,622] Code: 2303, sell success, cash: 19521.90, holding value:19390.35
-[2023-05-09 13:55:24,624] Code: 2303, buy success, cash: 17961.90, holding value:20888.40
-[2023-05-09 13:55:24,625] Code: 2303, hold success, cash: 17961.90, holding value:20687.55
-[2023-05-09 13:55:24,626] Code: 2303, buy success, cash: 16401.90, holding value:22448.40
-[2023-05-09 13:55:24,627] Code: 2303, buy success, cash: 14866.90, holding value:23623.65
-[2023-05-09 13:55:24,628] Code: 2303, sell success, cash: 16406.90, holding value:22160.60
-[2023-05-09 13:55:24,629] Code: 2303, buy success, cash: 14896.90, holding value:23238.90
-[2023-05-09 13:55:24,630] Code: 2303, buy success, cash: 13401.90, holding value:24503.05
-[2023-05-09 13:55:24,631] Code: 2303, sell success, cash: 14886.90, holding value:22854.15
-[2023-05-09 13:55:24,632] Code: 2303, hold success, cash: 14886.90, holding value:23546.70
-[2023-05-09 13:55:24,633] Code: 2303, buy success, cash: 13376.90, holding value:24748.90
-[2023-05-09 13:55:24,638] Code: 2303, sell success, cash: 14886.90, holding value:23238.90
-[2023-05-09 13:55:24,640] Code: 2303, buy success, cash: 13366.90, holding value:24912.80
-[2023-05-09 13:55:24,641] Code: 2303, buy success, cash: 11856.90, holding value:26258.90
-[2023-05-09 13:55:24,642] Code: 2303, hold success, cash: 11856.90, holding value:26693.65
-[2023-05-09 13:55:24,643] Code: 2303, sell success, cash: 13401.90, holding value:25322.55
-[2023-05-09 13:55:24,644] Code: 2303, buy success, cash: 11836.90, holding value:27215.35
-[2023-05-09 13:55:24,645] Code: 2303, hold success, cash: 11836.90, holding value:27563.15
-[2023-05-09 13:55:24,646] Code: 2303, hold success, cash: 11836.90, holding value:28171.80
-[2023-05-09 13:55:24,647] Code: 2303, hold success, cash: 11836.90, holding value:28345.70
-[2023-05-09 13:55:24,648] Code: 2303, hold success, cash: 11836.90, holding value:28693.50
-[2023-05-09 13:55:24,649] Code: 2303, buy success, cash: 10131.90, holding value:31354.95
-[2023-05-09 13:55:24,650] Code: 2303, hold success, cash: 10131.90, holding value:30987.15
-[2023-05-09 13:55:24,652] Code: 2303, sell success, cash: 11791.90, holding value:28867.40
-[2023-05-09 13:55:24,653] Code: 2303, sell success, cash: 13396.90, holding value:26305.95
-[2023-05-09 13:55:24,656] Code: 2303, buy success, cash: 11826.90, holding value:27302.30
-[2023-05-09 13:55:24,657] Code: 2303, buy success, cash: 10286.90, holding value:28320.60
-[2023-05-09 13:55:24,659] Code: 2303, sell success, cash: 11836.90, holding value:26954.50
-[2023-05-09 13:55:24,660] Code: 2303, sell success, cash: 13366.90, holding value:25076.70
-[2023-05-09 13:55:24,661] Code: 2303, sell success, cash: 14901.90, holding value:23623.65
-[2023-05-09 13:55:24,662] Code: 2303, buy success, cash: 13361.90, holding value:25240.60
-[2023-05-09 13:55:24,663] Code: 2303, sell success, cash: 14931.90, holding value:24162.30
-[2023-05-09 13:55:24,664] Code: 2303, buy success, cash: 13386.90, holding value:25322.55
-[2023-05-09 13:55:24,665] Code: 2303, hold success, cash: 13386.90, holding value:25814.25
-[2023-05-09 13:55:24,667] Code: 2303, hold success, cash: 13386.90, holding value:25486.45
-[2023-05-09 13:55:24,672] Code: 2303, sell success, cash: 14976.90, holding value:24470.10
-[2023-05-09 13:55:24,673] Code: 2303, hold success, cash: 14976.90, holding value:24777.90
-[2023-05-09 13:55:24,674] Code: 2303, sell success, cash: 16611.90, holding value:23527.65
-[2023-05-09 13:55:24,675] Code: 2303, hold success, cash: 16611.90, holding value:23671.55
-[2023-05-09 13:55:24,676] Code: 2303, buy success, cash: 14946.90, holding value:25624.35
-[2023-05-09 13:55:24,677] Code: 2303, sell success, cash: 16606.90, holding value:23887.40
-[2023-05-09 13:55:24,678] Code: 2303, buy success, cash: 14941.90, holding value:25624.35
-[2023-05-09 13:55:24,680] Code: 2303, sell success, cash: 16586.90, holding value:23671.55
-[2023-05-09 13:55:24,681] Code: 2303, hold success, cash: 16586.90, holding value:23671.55
-[2023-05-09 13:55:24,682] Code: 2303, hold success, cash: 16586.90, holding value:24534.95
-[2023-05-09 13:55:24,683] Code: 2303, sell success, cash: 18266.90, holding value:22495.20
-[2023-05-09 13:55:24,688] Code: 2303, sell success, cash: 19866.90, holding value:19824.00
-[2023-05-09 13:55:24,690] Code: 2303, buy success, cash: 18206.90, holding value:22227.40
-[2023-05-09 13:55:24,691] Code: 2303, hold success, cash: 18206.90, holding value:21959.60
-[2023-05-09 13:55:24,692] Code: 2303, hold success, cash: 18206.90, holding value:22160.45
-[2023-05-09 13:55:24,693] Code: 2303, sell success, cash: 19921.90, holding value:21248.85
-[2023-05-09 13:55:24,694] Code: 2303, sell success, cash: 21671.90, holding value:19932.50
-[2023-05-09 13:55:24,695] Code: 2303, buy success, cash: 19746.90, holding value:23850.75
-[2023-05-09 13:55:24,696] Code: 2303, sell success, cash: 21721.90, holding value:22495.25
-[2023-05-09 13:55:24,697] Code: 2303, sell success, cash: 23891.90, holding value:22546.30
-[2023-05-09 13:55:24,698] Code: 2303, hold success, cash: 23891.90, holding value:23117.75
-[2023-05-09 13:55:24,699] Code: 2303, sell success, cash: 26131.90, holding value:21033.60
-[2023-05-09 13:55:24,700] Code: 2303, hold success, cash: 26131.90, holding value:20845.80
-[2023-05-09 13:55:24,702] Code: 2303, sell success, cash: 28366.90, holding value:18751.65
-[2023-05-09 13:55:24,705] Code: 2303, buy success, cash: 25986.90, holding value:22348.20
-[2023-05-09 13:55:24,707] Code: 2303, buy success, cash: 23531.90, holding value:25507.45
-[2023-05-09 13:55:24,709] Code: 2303, hold success, cash: 23531.90, holding value:25871.10
-[2023-05-09 13:55:24,710] Code: 2303, sell success, cash: 26191.90, holding value:24977.40
-[2023-05-09 13:55:24,711] Code: 2303, hold success, cash: 26191.90, holding value:24038.40
-[2023-05-09 13:55:24,712] Code: 2303, hold success, cash: 26191.90, holding value:23756.70
-[2023-05-09 13:55:24,713] Code: 2303, buy success, cash: 23691.90, holding value:25975.00
-[2023-05-09 13:55:24,714] Code: 2303, hold success, cash: 23691.90, holding value:24884.05
-[2023-05-09 13:55:24,715] Code: 2303, hold success, cash: 23691.90, holding value:24676.25
-[2023-05-09 13:55:24,716] Code: 2303, buy success, cash: 21336.90, holding value:26823.45
-[2023-05-09 13:55:24,722] Code: 2303, sell success, cash: 23751.90, holding value:25091.85
-[2023-05-09 13:55:24,722] Code: 2303, hold success, cash: 23751.90, holding value:25039.90
-[2023-05-09 13:55:24,724] Code: 2303, sell success, cash: 26091.90, holding value:21972.60
-[2023-05-09 13:55:24,725] Code: 2303, buy success, cash: 23911.90, holding value:22650.20
-[2023-05-09 13:55:24,726] Code: 2303, sell success, cash: 26091.90, holding value:20470.20
-[2023-05-09 13:55:24,727] Code: 2303, buy success, cash: 23831.90, holding value:23481.40
-[2023-05-09 13:55:24,728] Code: 2303, hold success, cash: 23831.90, holding value:23013.85
-[2023-05-09 13:55:24,729] Code: 2303, hold success, cash: 23831.90, holding value:23221.65
-[2023-05-09 13:55:24,730] Code: 2303, buy success, cash: 21636.90, holding value:25001.05
-[2023-05-09 13:55:24,731] Code: 2303, hold success, cash: 21636.90, holding value:24944.10
-[2023-05-09 13:55:24,732] Code: 2303, buy success, cash: 19516.90, holding value:26266.80
-[2023-05-09 13:55:24,733] Code: 2303, sell success, cash: 21706.90, holding value:24944.10
-[2023-05-09 13:55:24,735] Code: 2303, buy success, cash: 19536.90, holding value:26886.30
-[2023-05-09 13:55:24,736] Code: 2303, hold success, cash: 19536.90, holding value:26700.45
-[2023-05-09 13:55:24,739] Code: 2303, sell success, cash: 21681.90, holding value:24431.55
-[2023-05-09 13:55:24,741] Code: 2303, hold success, cash: 21681.90, holding value:26823.45
-[2023-05-09 13:55:24,742] Code: 2303, hold success, cash: 21681.90, holding value:25855.30
-[2023-05-09 13:55:24,743] Code: 2303, buy success, cash: 19311.90, holding value:29364.30
-[2023-05-09 13:55:24,744] Code: 2303, buy success, cash: 16976.90, holding value:31265.65
-[2023-05-09 13:55:24,745] Code: 2303, sell success, cash: 19276.90, holding value:28497.00
-[2023-05-09 13:55:24,746] Code: 2303, buy success, cash: 16886.90, holding value:32002.10
-[2023-05-09 13:55:24,747] Code: 2303, buy success, cash: 14356.90, holding value:36406.70
-[2023-05-09 13:55:24,748] Code: 2303, sell success, cash: 16926.90, holding value:34412.30
-[2023-05-09 13:55:24,749] Code: 2303, hold success, cash: 16926.90, holding value:34479.25
-[2023-05-09 13:55:24,755] Code: 2303, buy success, cash: 14346.90, holding value:37126.20
-[2023-05-09 13:55:24,756] Code: 2303, buy success, cash: 11831.90, holding value:38705.85
-[2023-05-09 13:55:24,757] Code: 2303, sell success, cash: 14341.90, holding value:36118.90
-[2023-05-09 13:55:24,758] Code: 2303, sell success, cash: 16941.90, holding value:34814.00
-[2023-05-09 13:55:24,759] Code: 2303, hold success, cash: 16941.90, holding value:34747.05
-[2023-05-09 13:55:24,760] Code: 2303, hold success, cash: 16941.90, holding value:33475.00
-[2023-05-09 13:55:24,761] Code: 2303, hold success, cash: 16941.90, holding value:36822.50
-[2023-05-09 13:55:24,762] Code: 2303, hold success, cash: 16941.90, holding value:36822.50
-[2023-05-09 13:55:24,763] Code: 2303, hold success, cash: 16941.90, holding value:38228.45
-[2023-05-09 13:55:24,764] Code: 2303, hold success, cash: 16941.90, holding value:38429.30
-[2023-05-09 13:55:24,765] Code: 2303, buy success, cash: 14106.90, holding value:40795.65
-[2023-05-09 13:55:24,766] Code: 2303, sell success, cash: 17056.90, holding value:39500.50
-[2023-05-09 13:55:24,771] Code: 2303, sell success, cash: 20276.90, holding value:39895.80
-[2023-05-09 13:55:24,772] Code: 2303, buy success, cash: 17071.90, holding value:42914.95
-[2023-05-09 13:55:24,774] Code: 2303, buy success, cash: 13916.90, holding value:45400.45
-[2023-05-09 13:55:24,854] Code: 2303, sell success, cash: 17136.90, holding value:43115.80
-[2023-05-09 13:55:24,857] Code: 2303, buy success, cash: 13981.90, holding value:45400.45
-[2023-05-09 13:55:24,859] Code: 2303, hold success, cash: 13981.90, holding value:44105.35
-[2023-05-09 13:55:24,860] Code: 2303, hold success, cash: 13981.90, holding value:44609.00
-[2023-05-09 13:55:24,861] Code: 2303, hold success, cash: 13981.90, holding value:44896.80
-[2023-05-09 13:55:24,862] Code: 2303, buy success, cash: 10846.90, holding value:48247.65
-[2023-05-09 13:55:24,862] Code: 2303, hold success, cash: 10846.90, holding value:50787.00
-[2023-05-09 13:55:24,864] Code: 2303, buy success, cash: 7571.90, holding value:53677.25
-[2023-05-09 13:55:24,864] Code: 2303, hold success, cash: 7571.90, holding value:54087.00
-[2023-05-09 13:55:24,865] Code: 2303, buy success, cash: 4221.90, holding value:58256.50
-[2023-05-09 13:55:24,866] Code: 2303, buy success, cash: 956.90, holding value:60043.35
-[2023-05-09 13:55:24,871] Code: 2303, sell success, cash: 4251.90, holding value:57300.05
-[2023-05-09 13:55:24,873] Code: 2303, hold success, cash: 4251.90, holding value:53387.30
-[2023-05-09 13:55:24,874] Code: 2303, buy success, cash: 1286.90, holding value:54526.35
-[2023-05-09 13:55:24,875] Code: 2303, sell success, cash: 4266.90, holding value:51822.20
-[2023-05-09 13:55:24,876] Code: 2303, hold success, cash: 4266.90, holding value:55039.35
-[2023-05-09 13:55:24,877] Code: 2303, hold success, cash: 4266.90, holding value:53126.45
-[2023-05-09 13:55:24,878] Code: 2303, buy success, cash: 1216.90, holding value:56089.50
-[2023-05-09 13:55:24,879] Code: 2303, hold success, cash: 1216.90, holding value:58480.20
-[2023-05-09 13:55:24,881] Code: 2303, hold success, cash: 1216.90, holding value:57009.00
-[2023-05-09 13:55:24,881] Code: 2303, sell success, cash: 4316.90, holding value:53909.00
-[2023-05-09 13:55:24,883] Code: 2303, sell success, cash: 7426.90, holding value:50972.90
-[2023-05-09 13:55:24,883] Code: 2303, buy success, cash: 4296.90, holding value:54430.70
-[2023-05-09 13:55:24,887] Code: 2303, hold success, cash: 4296.90, holding value:55995.80
-[2023-05-09 13:55:24,890] Code: 2303, hold success, cash: 4296.90, holding value:55908.85
-[2023-05-09 13:55:24,891] Code: 2303, buy success, cash: 1061.90, holding value:59491.65
-[2023-05-09 13:55:24,892] Code: 2303, buy success, cash: 2.60, holding value:60091.20
-[2023-05-09 13:55:24,893] Code: 2303, not enough cash, cannot buy.
-[2023-05-09 13:55:24,894] Code: 2303, not enough cash, cannot buy.
-[2023-05-09 13:55:24,895] Code: 2303, sell success, cash: 3817.60, holding value:67601.80
-[2023-05-09 13:55:24,896] Code: 2303, buy success, cash: 11.05, holding value:71939.95
-[2023-05-09 13:55:24,897] Code: 2303, sell success, cash: 3961.05, holding value:69954.50
-[2023-05-09 13:55:24,898] Code: 2303, hold success, cash: 3961.05, holding value:69334.65
-[2023-05-09 13:55:24,899] Code: 2303, sell success, cash: 8011.05, holding value:67675.50
-[2023-05-09 13:55:24,900] Code: 2303, hold success, cash: 8011.05, holding value:69430.05
-[2023-05-09 13:55:24,905] Code: 2303, hold success, cash: 8011.05, holding value:69262.95
-[2023-05-09 13:55:24,907] Code: 2303, sell success, cash: 12341.05, holding value:68024.30
-[2023-05-09 13:55:24,908] Code: 2303, hold success, cash: 12341.05, holding value:74779.60
-[2023-05-09 13:55:24,909] Code: 2303, sell success, cash: 17341.05, holding value:73550.00
-[2023-05-09 13:55:24,912] Code: 2303, hold success, cash: 17341.05, holding value:74873.90
-[2023-05-09 13:55:24,913] Code: 2303, hold success, cash: 17341.05, holding value:73402.90
-[2023-05-09 13:55:24,914] Code: 2303, buy success, cash: 12611.05, holding value:74308.30
-[2023-05-09 13:55:24,915] Code: 2303, sell success, cash: 17221.05, holding value:67813.10
-[2023-05-09 13:55:24,916] Code: 2303, hold success, cash: 17221.05, holding value:67886.65
-[2023-05-09 13:55:24,920] Code: 2303, buy success, cash: 12821.05, holding value:69124.00
-[2023-05-09 13:55:24,921] Code: 2303, hold success, cash: 12821.05, holding value:70537.90
-[2023-05-09 13:55:24,922] Code: 2303, hold success, cash: 12821.05, holding value:72344.55
-[2023-05-09 13:55:24,923] Code: 2303, sell success, cash: 17406.05, holding value:67445.35
-[2023-05-09 13:55:24,925] Code: 2303, hold success, cash: 17406.05, holding value:69798.95
-[2023-05-09 13:55:24,926] Code: 2303, buy success, cash: 12836.05, holding value:71794.70
-[2023-05-09 13:55:24,927] Code: 2303, hold success, cash: 12836.05, holding value:72423.10
-[2023-05-09 13:55:24,928] Code: 2303, sell success, cash: 17491.05, holding value:68475.05
-[2023-05-09 13:55:24,929] Code: 2303, hold success, cash: 17491.05, holding value:68769.25
-[2023-05-09 13:55:24,930] Code: 2303, buy success, cash: 12631.05, holding value:76350.60
-[2023-05-09 13:55:24,931] Code: 2303, sell success, cash: 17371.05, holding value:69725.40
-[2023-05-09 13:55:24,932] Code: 2303, sell success, cash: 22201.05, holding value:66219.30
-[2023-05-09 13:55:24,935] Code: 2303, sell success, cash: 26916.05, holding value:59927.65
-[2023-05-09 13:55:24,936] Code: 2303, sell success, cash: 28026.05, holding value:12998.10
-[2023-05-09 13:55:24,939] Code: 2303, sell success, cash: 29116.05, holding value:11673.90
-[2023-05-09 13:55:24,940] Code: 2303, buy success, cash: 28046.05, holding value:12529.70
-[2023-05-09 13:55:24,942] Code: 2303, sell success, cash: 29146.05, holding value:11781.00
-[2023-05-09 13:55:24,943] Code: 2303, buy success, cash: 28051.05, holding value:12822.45
-[2023-05-09 13:55:24,943] Code: 2303, buy success, cash: 26941.05, holding value:14108.10
-[2023-05-09 13:55:24,944] Code: 2303, sell success, cash: 28056.05, holding value:13056.65
-[2023-05-09 13:55:24,945] Code: 2303, hold success, cash: 28056.05, holding value:13115.20
-[2023-05-09 13:55:24,946] Code: 2303, buy success, cash: 26946.05, holding value:14108.10
-[2023-05-09 13:55:24,947] Code: 2303, buy success, cash: 25821.05, holding value:15423.75
-[2023-05-09 13:55:24,948] Code: 2303, hold success, cash: 25821.05, holding value:15492.30
-[2023-05-09 13:55:24,949] Code: 2303, sell success, cash: 26946.05, holding value:14298.75
-[2023-05-09 13:55:24,956] Code: 2303, sell success, cash: 28086.05, holding value:13349.40
-[2023-05-09 13:55:24,957] Code: 2303, hold success, cash: 28086.05, holding value:13700.70
-[2023-05-09 13:55:24,958] Code: 2303, buy success, cash: 26916.05, holding value:14870.70
-[2023-05-09 13:55:24,959] Code: 2303, sell success, cash: 28071.05, holding value:13525.05
-[2023-05-09 13:55:24,960] Code: 2303, buy success, cash: 26901.05, holding value:14870.70
-[2023-05-09 13:55:24,961] Code: 2303, buy success, cash: 25706.05, holding value:16383.45
-[2023-05-09 13:55:24,962] Code: 2303, hold success, cash: 25706.05, holding value:16246.35
-[2023-05-09 13:55:24,964] Code: 2303, sell success, cash: 26906.05, holding value:15252.00
-[2023-05-09 13:55:24,966] Code: 2303, sell success, cash: 28041.05, holding value:13290.85
-[2023-05-09 13:55:24,966] Code: 2303, buy success, cash: 26956.05, holding value:13790.35
-[2023-05-09 13:55:24,972] Code: 2303, sell success, cash: 28066.05, holding value:12998.10
-[2023-05-09 13:55:24,974] Code: 2303, hold success, cash: 28066.05, holding value:12998.10
-[2023-05-09 13:55:24,975] Code: 2303, buy success, cash: 26936.05, holding value:14362.30
-[2023-05-09 13:55:24,976] Code: 2303, hold success, cash: 26936.05, holding value:14489.40
-[2023-05-09 13:55:24,978] Code: 2303, buy success, cash: 25791.05, holding value:15697.95
-[2023-05-09 13:55:24,979] Code: 2303, sell success, cash: 26936.05, holding value:14552.95
-[2023-05-09 13:55:24,981] Code: 2303, hold success, cash: 26936.05, holding value:14489.40
-[2023-05-09 13:55:24,982] Code: 2303, hold success, cash: 26936.05, holding value:14552.95
-[2023-05-09 13:55:24,985] Code: 2303, sell success, cash: 28086.05, holding value:13466.50
-[2023-05-09 13:55:24,986] Code: 2303, sell success, cash: 29251.05, holding value:12477.15
-[2023-05-09 13:55:24,990] Code: 2303, buy success, cash: 28086.05, holding value:13642.15
-[2023-05-09 13:55:24,991] Code: 2303, buy success, cash: 26941.05, holding value:14552.95
-[2023-05-09 13:55:24,992] Code: 2303, hold success, cash: 26941.05, holding value:14552.95
-[2023-05-09 13:55:24,994] Code: 2303, hold success, cash: 26941.05, holding value:14743.60
-[2023-05-09 13:55:24,995] Code: 2303, sell success, cash: 28111.05, holding value:13700.70
-[2023-05-09 13:55:24,997] Code: 2303, sell success, cash: 29296.05, holding value:12691.35
-[2023-05-09 13:55:24,998] Code: 2303, hold success, cash: 29296.05, holding value:12423.60
-[2023-05-09 13:55:24,999] Code: 2303, hold success, cash: 29296.05, holding value:12262.95
-[2023-05-09 13:55:25,003] Code: 2303, sell success, cash: 30461.05, holding value:11312.15
-[2023-05-09 13:55:25,003] Code: 2303, buy success, cash: 29306.05, holding value:12370.05
-[2023-05-09 13:55:25,004] Code: 2303, hold success, cash: 29306.05, holding value:12262.95
-[2023-05-09 13:55:25,005] Code: 2303, sell success, cash: 30471.05, holding value:11312.15
-[2023-05-09 13:55:25,006] Code: 2303, buy success, cash: 29301.05, holding value:12530.70
-[2023-05-09 13:55:25,006] Code: 2303, hold success, cash: 29301.05, holding value:12530.70
-[2023-05-09 13:55:25,009] Code: 2303, buy success, cash: 28146.05, holding value:13525.05
-[2023-05-09 13:55:25,098] Code: 2303, buy success, cash: 26986.05, holding value:14743.60
-[2023-05-09 13:55:25,098] Code: 2303, buy success, cash: 25806.05, holding value:16177.80
-[2023-05-09 13:55:25,100] Code: 2303, buy success, cash: 24641.05, holding value:17137.15
-[2023-05-09 13:55:25,101] Code: 2303, hold success, cash: 24641.05, holding value:17137.15
-[2023-05-09 13:55:25,102] Code: 2303, sell success, cash: 25806.05, holding value:15972.15
-[2023-05-09 13:55:25,106] Code: 2303, buy success, cash: 24641.05, holding value:17137.15
-[2023-05-09 13:55:25,108] Code: 2303, hold success, cash: 24641.05, holding value:17137.15
-[2023-05-09 13:55:25,109] Code: 2303, sell success, cash: 25796.05, holding value:15835.05
-[2023-05-09 13:55:25,146] Code: 2303, buy success, cash: 24636.05, holding value:17063.60
-[2023-05-09 13:55:25,152] Code: 2303, hold success, cash: 24636.05, holding value:16990.05
-[2023-05-09 13:55:25,153] Code: 2303, buy success, cash: 23446.05, holding value:18694.90
-[2023-05-09 13:55:25,154] Code: 2303, buy success, cash: 22216.05, holding value:20553.30
-[2023-05-09 13:55:25,155] Code: 2303, buy success, cash: 20991.05, holding value:21694.75
-[2023-05-09 13:55:25,157] Code: 2303, sell success, cash: 22201.05, holding value:20219.10
-[2023-05-09 13:55:25,158] Code: 2303, hold success, cash: 22201.05, holding value:20386.20
-[2023-05-09 13:55:25,160] Code: 2303, buy success, cash: 20996.05, holding value:21340.55
-[2023-05-09 13:55:25,161] Code: 2303, buy success, cash: 19786.05, holding value:22639.10
-[2023-05-09 13:55:25,162] Code: 2303, sell success, cash: 21006.05, holding value:21606.20
-[2023-05-09 13:55:25,164] Code: 2303, hold success, cash: 21006.05, holding value:21252.00
-[2023-05-09 13:55:25,165] Code: 2303, sell success, cash: 22216.05, holding value:20219.10
-[2023-05-09 13:55:25,166] Code: 2303, hold success, cash: 22216.05, holding value:19884.90
-[2023-05-09 13:55:25,170] Code: 2303, sell success, cash: 23411.05, holding value:18773.45
-[2023-05-09 13:55:25,172] Code: 2303, hold success, cash: 23411.05, holding value:18773.45
-[2023-05-09 13:55:25,173] Code: 2303, sell success, cash: 24721.05, holding value:19270.10
-[2023-05-09 13:55:25,175] Code: 2303, sell success, cash: 26066.05, holding value:18439.95
-[2023-05-09 13:55:25,177] Code: 2303, sell success, cash: 27401.05, holding value:16967.85
-[2023-05-09 13:55:25,178] Code: 2303, sell success, cash: 28746.05, holding value:15749.95
-[2023-05-09 13:55:25,179] Code: 2303, hold success, cash: 28746.05, holding value:15867.05
-[2023-05-09 13:55:25,180] Code: 2303, hold success, cash: 28746.05, holding value:16218.35
-[2023-05-09 13:55:25,181] Code: 2303, hold success, cash: 28746.05, holding value:15457.20
-[2023-05-09 13:55:25,182] Code: 2303, hold success, cash: 28746.05, holding value:15925.60
-[2023-05-09 13:55:25,183] Code: 2303, sell success, cash: 30091.05, holding value:14404.95
-[2023-05-09 13:55:25,184] Code: 2303, buy success, cash: 28776.05, holding value:15398.65
-[2023-05-09 13:55:25,186] Code: 2303, sell success, cash: 30096.05, holding value:14137.20
-[2023-05-09 13:55:25,188] Code: 2303, sell success, cash: 31391.05, holding value:12574.45
-[2023-05-09 13:55:25,191] Code: 2303, hold success, cash: 31391.05, holding value:12623.00
-[2023-05-09 13:55:25,192] Code: 2303, hold success, cash: 31391.05, holding value:12525.90
-[2023-05-09 13:55:25,193] Code: 2303, sell success, cash: 32686.05, holding value:11279.45
-[2023-05-09 13:55:25,194] Code: 2303, sell success, cash: 33986.05, holding value:10023.00
-[2023-05-09 13:55:25,195] Code: 2303, sell success, cash: 35261.05, holding value:8555.25
-[2023-05-09 13:55:25,197] Code: 2303, hold success, cash: 35261.05, holding value:8689.45
-[2023-05-09 13:55:25,198] Code: 2303, sell success, cash: 36561.05, holding value:7423.00
-[2023-05-09 13:55:25,200] Code: 2303, sell success, cash: 37846.05, holding value:6052.35
-[2023-05-09 13:55:25,200] Code: 2303, buy success, cash: 36551.05, holding value:7394.45
-[2023-05-09 13:55:25,204] Code: 2303, sell success, cash: 37831.05, holding value:6028.80
-[2023-05-09 13:55:25,206] Code: 2303, hold success, cash: 37831.05, holding value:5863.95
-[2023-05-09 13:55:25,208] Code: 2303, hold success, cash: 37831.05, holding value:5934.60
-[2023-05-09 13:55:25,209] Code: 2303, buy success, cash: 36556.05, holding value:7280.25
-[2023-05-09 13:55:25,212] Code: 2303, hold success, cash: 36556.05, holding value:7365.90
-[2023-05-09 13:55:25,213] Code: 2303, sell success, cash: 37876.05, holding value:6217.20
-[2023-05-09 13:55:25,214] Code: 2303, hold success, cash: 37876.05, holding value:6123.00
-[2023-05-09 13:55:25,216] Code: 2303, sell success, cash: 39166.05, holding value:4785.90
-[2023-05-09 13:55:25,216] Code: 2303, hold success, cash: 39166.05, holding value:4841.55
-[2023-05-09 13:55:25,218] Code: 2303, hold success, cash: 39166.05, holding value:4934.30
-[2023-05-09 13:55:25,219] Code: 2303, sell success, cash: 40506.05, holding value:3631.40
-[2023-05-09 13:55:25,222] Code: 2303, buy success, cash: 39151.05, holding value:5027.05
-[2023-05-09 13:55:25,224] Code: 2303, hold success, cash: 39151.05, holding value:5101.25
-[2023-05-09 13:55:25,225] Code: 2303, buy success, cash: 37781.05, holding value:6452.70
-[2023-05-09 13:55:25,226] Code: 2303, hold success, cash: 37781.05, holding value:6429.15
-[2023-05-09 13:55:25,227] Code: 2303, buy success, cash: 36456.05, holding value:7565.75
-[2023-05-09 13:55:25,228] Code: 2303, sell success, cash: 37821.05, holding value:6429.15
-[2023-05-09 13:55:25,230] Code: 2303, sell success, cash: 39161.05, holding value:4971.40
-[2023-05-09 13:55:25,231] Code: 2303, sell success, cash: 40531.05, holding value:3712.70
-[2023-05-09 13:55:25,232] Code: 2303, sell success, cash: 41906.05, holding value:2351.25
-[2023-05-09 13:55:25,233] Code: 2303, buy success, cash: 40536.05, holding value:3712.70
-[2023-05-09 13:55:25,235] Code: 2303, sell success, cash: 41916.05, holding value:2359.80
-[2023-05-09 13:55:25,237] Code: 2303, buy success, cash: 40516.05, holding value:3794.00
-[2023-05-09 13:55:25,238] Code: 2303, hold success, cash: 40516.05, holding value:3780.45
-[2023-05-09 13:55:25,240] Code: 2303, sell success, cash: 41951.05, holding value:2453.85
-[2023-05-09 13:55:25,242] Code: 2303, sell success, cash: 43376.05, holding value:1011.75
-[2023-05-09 13:55:25,243] Code: 2303, buy success, cash: 41971.05, holding value:2402.55
-[2023-05-09 13:55:25,245] Code: 2303, hold success, cash: 41971.05, holding value:2419.65
-[2023-05-09 13:55:25,246] Code: 2303, sell success, cash: 43381.05, holding value:1001.10
-[2023-05-09 13:55:25,247] Code: 2303, sell success, cash: 44371.50, holding value:0.00
-[2023-05-09 13:55:25,248] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,249] Code: 2303, buy success, cash: 42906.50, holding value:1465.00
-[2023-05-09 13:55:25,251] Code: 2303, sell success, cash: 44401.50, holding value:0.00
-[2023-05-09 13:55:25,253] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,255] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,257] Code: 2303, buy success, cash: 43001.50, holding value:1400.00
-[2023-05-09 13:55:25,259] Code: 2303, sell success, cash: 44376.50, holding value:0.00
-[2023-05-09 13:55:25,259] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,261] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,262] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,263] Code: 2303, buy success, cash: 43016.50, holding value:1360.00
-[2023-05-09 13:55:25,264] Code: 2303, hold success, cash: 43016.50, holding value:1385.00
-[2023-05-09 13:55:25,265] Code: 2303, buy success, cash: 41661.50, holding value:2710.00
-[2023-05-09 13:55:25,266] Code: 2303, hold success, cash: 41661.50, holding value:2640.00
-[2023-05-09 13:55:25,267] Code: 2303, sell success, cash: 43001.50, holding value:1340.00
-[2023-05-09 13:55:25,268] Code: 2303, sell success, cash: 44361.50, holding value:0.00
-[2023-05-09 13:55:25,270] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,275] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,276] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,278] Code: 2303, buy success, cash: 43051.50, holding value:1310.00
-[2023-05-09 13:55:25,279] Code: 2303, sell success, cash: 44351.50, holding value:0.00
-[2023-05-09 13:55:25,280] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,281] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,282] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,283] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,284] Code: 2303, buy success, cash: 43041.50, holding value:1310.00
-[2023-05-09 13:55:25,286] Code: 2303, buy success, cash: 41751.50, holding value:2580.00
-[2023-05-09 13:55:25,288] Code: 2303, hold success, cash: 41751.50, holding value:2670.00
-[2023-05-09 13:55:25,289] Code: 2303, hold success, cash: 41751.50, holding value:2690.00
-[2023-05-09 13:55:25,292] Code: 2303, sell success, cash: 43101.50, holding value:1350.00
-[2023-05-09 13:55:25,293] Code: 2303, buy success, cash: 41751.50, holding value:2700.00
-[2023-05-09 13:55:25,294] Code: 2303, sell success, cash: 43076.50, holding value:1325.00
-[2023-05-09 13:55:25,295] Code: 2303, buy success, cash: 41741.50, holding value:2670.00
-[2023-05-09 13:55:25,297] Code: 2303, buy success, cash: 40441.50, holding value:3900.00
-[2023-05-09 13:55:25,298] Code: 2303, hold success, cash: 40441.50, holding value:3915.00
-[2023-05-09 13:55:25,299] Code: 2303, hold success, cash: 40441.50, holding value:3945.00
-[2023-05-09 13:55:25,302] Code: 2303, sell success, cash: 41761.50, holding value:2640.00
-[2023-05-09 13:55:25,304] Code: 2303, hold success, cash: 41761.50, holding value:2690.00
-[2023-05-09 13:55:25,305] Code: 2303, sell success, cash: 43096.50, holding value:1335.00
-[2023-05-09 13:55:25,307] Code: 2303, buy success, cash: 41776.50, holding value:2640.00
-[2023-05-09 13:55:25,309] Code: 2303, hold success, cash: 41776.50, holding value:2720.00
-[2023-05-09 13:55:25,310] Code: 2303, sell success, cash: 43136.50, holding value:1360.00
-[2023-05-09 13:55:25,311] Code: 2303, buy success, cash: 41781.50, holding value:2710.00
-[2023-05-09 13:55:25,313] Code: 2303, sell success, cash: 43141.50, holding value:1360.00
-[2023-05-09 13:55:25,313] Code: 2303, hold success, cash: 43141.50, holding value:1360.00
-[2023-05-09 13:55:25,314] Code: 2303, sell success, cash: 44511.50, holding value:0.00
-[2023-05-09 13:55:25,316] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,320] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,321] Code: 2303, buy success, cash: 43156.50, holding value:1355.00
-[2023-05-09 13:55:25,322] Code: 2303, sell success, cash: 44511.50, holding value:0.00
-[2023-05-09 13:55:25,324] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,326] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,327] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,328] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,329] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,330] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,331] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,332] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,333] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,337] Code: 2303, buy success, cash: 43171.50, holding value:1340.00
-[2023-05-09 13:55:25,339] Code: 2303, buy success, cash: 41826.50, holding value:2690.00
-[2023-05-09 13:55:25,341] Code: 2303, buy success, cash: 40491.50, holding value:4005.00
-[2023-05-09 13:55:25,342] Code: 2303, buy success, cash: 39156.50, holding value:5340.00
-[2023-05-09 13:55:25,343] Code: 2303, sell success, cash: 40471.50, holding value:3945.00
-[2023-05-09 13:55:25,344] Code: 2303, hold success, cash: 40471.50, holding value:4050.00
-[2023-05-09 13:55:25,346] Code: 2303, sell success, cash: 41841.50, holding value:2740.00
-[2023-05-09 13:55:25,347] Code: 2303, sell success, cash: 43216.50, holding value:1375.00
-[2023-05-09 13:55:25,348] Code: 2303, buy success, cash: 41836.50, holding value:2760.00
-[2023-05-09 13:55:25,349] Code: 2303, hold success, cash: 41836.50, holding value:2790.00
-[2023-05-09 13:55:25,350] Code: 2303, sell success, cash: 43226.50, holding value:1390.00
-[2023-05-09 13:55:25,351] Code: 2303, sell success, cash: 44626.50, holding value:0.00
-[2023-05-09 13:55:25,352] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,353] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:25,354] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,355] Code: 2303, buy success, cash: 43201.50, holding value:1425.00
-[2023-05-09 13:55:25,356] Code: 2303, buy success, cash: 41751.50, holding value:2900.00
-[2023-05-09 13:55:25,357] Code: 2303, buy success, cash: 40311.50, holding value:4320.00
-[2023-05-09 13:55:25,358] Code: 2303, buy success, cash: 38911.50, holding value:5600.00
-[2023-05-09 13:55:25,359] Code: 2303, buy success, cash: 37461.50, holding value:7250.00
-[2023-05-09 13:55:25,360] Code: 2303, sell success, cash: 38926.50, holding value:5860.00
-[2023-05-09 13:55:25,361] Code: 2303, hold success, cash: 38926.50, holding value:5800.00
-[2023-05-09 13:55:25,363] Code: 2303, sell success, cash: 40376.50, holding value:4350.00
-[2023-05-09 13:55:25,364] Code: 2303, sell success, cash: 41801.50, holding value:2850.00
-[2023-05-09 13:55:25,366] Code: 2303, sell success, cash: 43226.50, holding value:1425.00
-[2023-05-09 13:55:25,367] Code: 2303, sell success, cash: 44651.50, holding value:0.00
-[2023-05-09 13:55:25,368] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:25,369] Code: 2303, buy success, cash: 43231.50, holding value:1420.00
-[2023-05-09 13:55:25,369] Code: 2303, sell success, cash: 44681.50, holding value:0.00
-[2023-05-09 13:55:25,371] Code: 2303, buy success, cash: 43251.50, holding value:1430.00
-[2023-05-09 13:55:25,372] Code: 2303, hold success, cash: 43251.50, holding value:1450.00
-[2023-05-09 13:55:25,373] Code: 2303, hold success, cash: 43251.50, holding value:1455.00
-[2023-05-09 13:55:25,375] Code: 2303, buy success, cash: 41776.50, holding value:2950.00
-[2023-05-09 13:55:25,377] Code: 2303, buy success, cash: 40311.50, holding value:4395.00
-[2023-05-09 13:55:25,378] Code: 2303, sell success, cash: 41771.50, holding value:2920.00
-[2023-05-09 13:55:25,379] Code: 2303, buy success, cash: 40271.50, holding value:4500.00
-[2023-05-09 13:55:25,380] Code: 2303, sell success, cash: 41791.50, holding value:3040.00
-[2023-05-09 13:55:25,381] Code: 2303, hold success, cash: 41791.50, holding value:3040.00
-[2023-05-09 13:55:25,382] Code: 2303, buy success, cash: 40281.50, holding value:4530.00
-[2023-05-09 13:55:25,383] Code: 2303, buy success, cash: 38786.50, holding value:5980.00
-[2023-05-09 13:55:25,384] Code: 2303, buy success, cash: 37276.50, holding value:7550.00
-[2023-05-09 13:55:25,385] Code: 2303, buy success, cash: 35741.50, holding value:9210.00
-[2023-05-09 13:55:25,386] Code: 2303, buy success, cash: 34156.50, holding value:11095.00
-[2023-05-09 13:55:25,387] Code: 2303, buy success, cash: 32501.50, holding value:13240.00
-[2023-05-09 13:55:25,388] Code: 2303, buy success, cash: 30881.50, holding value:14580.00
-[2023-05-09 13:55:25,390] Code: 2303, buy success, cash: 29256.50, holding value:16250.00
-[2023-05-09 13:55:25,391] Code: 2303, buy success, cash: 27611.50, holding value:18095.00
-[2023-05-09 13:55:25,393] Code: 2303, sell success, cash: 29236.50, holding value:16250.00
-[2023-05-09 13:55:25,394] Code: 2303, hold success, cash: 29236.50, holding value:16600.00
-[2023-05-09 13:55:25,396] Code: 2303, sell success, cash: 30896.50, holding value:14940.00
-[2023-05-09 13:55:25,397] Code: 2303, hold success, cash: 30896.50, holding value:14985.00
-[2023-05-09 13:55:25,398] Code: 2303, hold success, cash: 30896.50, holding value:15300.00
-[2023-05-09 13:55:25,399] Code: 2303, hold success, cash: 30896.50, holding value:15120.00
-[2023-05-09 13:55:25,401] Code: 2303, buy success, cash: 29226.50, holding value:16700.00
-[2023-05-09 13:55:25,402] Code: 2303, buy success, cash: 27556.50, holding value:18370.00
-[2023-05-09 13:55:25,403] Code: 2303, buy success, cash: 25901.50, holding value:19860.00
-[2023-05-09 13:55:25,404] Code: 2303, buy success, cash: 24246.50, holding value:21515.00
-[2023-05-09 13:55:25,405] Code: 2303, sell success, cash: 25911.50, holding value:19980.00
-[2023-05-09 13:55:25,407] Code: 2303, buy success, cash: 24256.50, holding value:21515.00
-[2023-05-09 13:55:25,409] Code: 2303, hold success, cash: 24256.50, holding value:21710.00
-[2023-05-09 13:55:25,411] Code: 2303, hold success, cash: 24256.50, holding value:21515.00
-[2023-05-09 13:55:25,412] Code: 2303, sell success, cash: 25901.50, holding value:19740.00
-[2023-05-09 13:55:25,413] Code: 2303, buy success, cash: 24476.50, holding value:18525.00
-[2023-05-09 13:55:25,414] Code: 2303, sell success, cash: 25916.50, holding value:17280.00
-[2023-05-09 13:55:25,415] Code: 2303, buy success, cash: 24481.50, holding value:18655.00
-[2023-05-09 13:55:25,416] Code: 2303, sell success, cash: 25936.50, holding value:17460.00
-[2023-05-09 13:55:25,417] Code: 2303, sell success, cash: 27406.50, holding value:16170.00
-[2023-05-09 13:55:25,418] Code: 2303, buy success, cash: 25931.50, holding value:17700.00
-[2023-05-09 13:55:25,419] Code: 2303, hold success, cash: 25931.50, holding value:17040.00
-[2023-05-09 13:55:25,420] Code: 2303, hold success, cash: 25931.50, holding value:16800.00
-[2023-05-09 13:55:25,422] Code: 2303, buy success, cash: 24511.50, holding value:18460.00
-[2023-05-09 13:55:25,424] Code: 2303, buy success, cash: 23081.50, holding value:20020.00
-[2023-05-09 13:55:25,425] Code: 2303, sell success, cash: 24511.50, holding value:18590.00
-[2023-05-09 13:55:25,426] Code: 2303, sell success, cash: 25941.50, holding value:17160.00
-[2023-05-09 13:55:25,427] Code: 2303, hold success, cash: 25941.50, holding value:17160.00
-[2023-05-09 13:55:25,429] Code: 2303, buy success, cash: 24521.50, holding value:18460.00
-[2023-05-09 13:55:25,430] Code: 2303, hold success, cash: 24521.50, holding value:18200.00
-[2023-05-09 13:55:25,431] Code: 2303, sell success, cash: 25981.50, holding value:17520.00
-[2023-05-09 13:55:25,432] Code: 2303, buy success, cash: 24541.50, holding value:18720.00
-[2023-05-09 13:55:25,433] Code: 2303, buy success, cash: 23091.50, holding value:20300.00
-[2023-05-09 13:55:25,434] Code: 2303, hold success, cash: 23091.50, holding value:20440.00
-[2023-05-09 13:55:25,434] Code: 2303, buy success, cash: 21636.50, holding value:21825.00
-[2023-05-09 13:55:25,435] Code: 2303, buy success, cash: 20191.50, holding value:23120.00
-[2023-05-09 13:55:25,436] Code: 2303, buy success, cash: 18766.50, holding value:24225.00
-[2023-05-09 13:55:25,438] Code: 2303, sell success, cash: 20206.50, holding value:23040.00
-[2023-05-09 13:55:25,440] Code: 2303, buy success, cash: 18751.50, holding value:24735.00
-[2023-05-09 13:55:25,441] Code: 2303, hold success, cash: 18751.50, holding value:24480.00
-[2023-05-09 13:55:25,443] Code: 2303, sell success, cash: 20146.50, holding value:22320.00
-[2023-05-09 13:55:25,444] Code: 2303, hold success, cash: 20146.50, holding value:22720.00
-[2023-05-09 13:55:25,445] Code: 2303, sell success, cash: 21561.50, holding value:21225.00
-[2023-05-09 13:55:25,446] Code: 2303, buy success, cash: 20156.50, holding value:22480.00
-[2023-05-09 13:55:25,447] Code: 2303, sell success, cash: 21541.50, holding value:20775.00
-[2023-05-09 13:55:25,448] Code: 2303, buy success, cash: 20131.50, holding value:22560.00
-[2023-05-09 13:55:25,449] Code: 2303, buy success, cash: 18736.50, holding value:23715.00
-[2023-05-09 13:55:25,450] Code: 2303, sell success, cash: 20151.50, holding value:22640.00
-[2023-05-09 13:55:25,451] Code: 2303, buy success, cash: 18741.50, holding value:23970.00
-[2023-05-09 13:55:25,451] Code: 2303, sell success, cash: 20156.50, holding value:22640.00
-[2023-05-09 13:55:25,452] Code: 2303, sell success, cash: 21556.50, holding value:21000.00
-[2023-05-09 13:55:25,541] Code: 2303, buy success, cash: 20156.50, holding value:22400.00
-[2023-05-09 13:55:25,542] Code: 2303, hold success, cash: 20156.50, holding value:22240.00
-[2023-05-09 13:55:25,544] Code: 2303, hold success, cash: 20156.50, holding value:22640.00
-[2023-05-09 13:55:25,546] Code: 2303, buy success, cash: 18751.50, holding value:23885.00
-[2023-05-09 13:55:25,547] Code: 2303, sell success, cash: 20296.50, holding value:24720.00
-[2023-05-09 13:55:25,549] Code: 2303, hold success, cash: 20296.50, holding value:24160.00
-[2023-05-09 13:55:25,549] Code: 2303, sell success, cash: 21821.50, holding value:22875.00
-[2023-05-09 13:55:25,552] Code: 2303, hold success, cash: 21821.50, holding value:22875.00
-[2023-05-09 13:55:25,554] Code: 2303, hold success, cash: 21821.50, holding value:22650.00
-[2023-05-09 13:55:25,560] Code: 2303, sell success, cash: 23331.50, holding value:21140.00
-[2023-05-09 13:55:25,562] Code: 2303, hold success, cash: 23331.50, holding value:21280.00
-[2023-05-09 13:55:25,563] Code: 2303, hold success, cash: 23331.50, holding value:21350.00
-[2023-05-09 13:55:25,565] Code: 2303, hold success, cash: 23331.50, holding value:21280.00
-[2023-05-09 13:55:25,571] Code: 2303, hold success, cash: 23331.50, holding value:21280.00
-[2023-05-09 13:55:25,573] Code: 2303, buy success, cash: 21806.50, holding value:22875.00
-[2023-05-09 13:55:25,573] Code: 2303, buy success, cash: 20286.50, holding value:24320.00
-[2023-05-09 13:55:25,574] Code: 2303, sell success, cash: 21801.50, holding value:22725.00
-[2023-05-09 13:55:25,575] Code: 2303, buy success, cash: 20246.50, holding value:24880.00
-[2023-05-09 13:55:25,575] Code: 2303, sell success, cash: 21786.50, holding value:23100.00
-[2023-05-09 13:55:25,576] Code: 2303, hold success, cash: 21786.50, holding value:22950.00
-[2023-05-09 13:55:25,580] Code: 2303, hold success, cash: 21786.50, holding value:23100.00
-[2023-05-09 13:55:25,581] Code: 2303, buy success, cash: 20236.50, holding value:24800.00
-[2023-05-09 13:55:25,583] Code: 2303, sell success, cash: 21781.50, holding value:23175.00
-[2023-05-09 13:55:25,586] Code: 2303, hold success, cash: 21781.50, holding value:23100.00
-[2023-05-09 13:55:25,588] Code: 2303, hold success, cash: 21781.50, holding value:22875.00
-[2023-05-09 13:55:25,589] Code: 2303, sell success, cash: 23311.50, holding value:21420.00
-[2023-05-09 13:55:25,591] Code: 2303, hold success, cash: 23311.50, holding value:21560.00
-[2023-05-09 13:55:25,592] Code: 2303, sell success, cash: 24856.50, holding value:20085.00
-[2023-05-09 13:55:25,594] Code: 2303, buy success, cash: 23316.50, holding value:21560.00
-[2023-05-09 13:55:25,596] Code: 2303, buy success, cash: 21781.50, holding value:23025.00
-[2023-05-09 13:55:25,597] Code: 2303, hold success, cash: 21781.50, holding value:23025.00
-[2023-05-09 13:55:25,598] Code: 2303, sell success, cash: 23341.50, holding value:21840.00
-[2023-05-09 13:55:25,599] Code: 2303, buy success, cash: 21756.50, holding value:23775.00
-[2023-05-09 13:55:25,600] Code: 2303, hold success, cash: 21756.50, holding value:23400.00
-[2023-05-09 13:55:25,601] Code: 2303, hold success, cash: 21756.50, holding value:23325.00
-[2023-05-09 13:55:25,602] Code: 2303, buy success, cash: 20221.50, holding value:24560.00
-[2023-05-09 13:55:25,603] Code: 2303, sell success, cash: 21771.50, holding value:23250.00
-[2023-05-09 13:55:25,605] Code: 2303, sell success, cash: 23341.50, holding value:21980.00
-[2023-05-09 13:55:25,606] Code: 2303, sell success, cash: 24911.50, holding value:20410.00
-[2023-05-09 13:55:25,607] Code: 2303, hold success, cash: 24911.50, holding value:20800.00
-[2023-05-09 13:55:25,608] Code: 2303, hold success, cash: 24911.50, holding value:21125.00
-[2023-05-09 13:55:25,609] Code: 2303, buy success, cash: 23306.50, holding value:22470.00
-[2023-05-09 13:55:25,610] Code: 2303, buy success, cash: 21706.50, holding value:24000.00
-[2023-05-09 13:55:25,611] Code: 2303, buy success, cash: 20141.50, holding value:25040.00
-[2023-05-09 13:55:25,612] Code: 2303, sell success, cash: 21726.50, holding value:23775.00
-[2023-05-09 13:55:25,614] Code: 2303, buy success, cash: 20106.50, holding value:25920.00
-[2023-05-09 13:55:25,615] Code: 2303, sell success, cash: 21701.50, holding value:23925.00
-[2023-05-09 13:55:25,616] Code: 2303, hold success, cash: 21701.50, holding value:24225.00
-[2023-05-09 13:55:25,617] Code: 2303, hold success, cash: 21701.50, holding value:24600.00
-[2023-05-09 13:55:25,618] Code: 2303, sell success, cash: 23346.50, holding value:23030.00
-[2023-05-09 13:55:25,619] Code: 2303, buy success, cash: 21716.50, holding value:24450.00
-[2023-05-09 13:55:25,620] Code: 2303, sell success, cash: 23321.50, holding value:22470.00
-[2023-05-09 13:55:25,621] Code: 2303, buy success, cash: 21716.50, holding value:24075.00
-[2023-05-09 13:55:25,622] Code: 2303, buy success, cash: 20111.50, holding value:25680.00
-[2023-05-09 13:55:25,622] Code: 2303, sell success, cash: 21731.50, holding value:24300.00
-[2023-05-09 13:55:25,623] Code: 2303, hold success, cash: 21731.50, holding value:24300.00
-[2023-05-09 13:55:25,625] Code: 2303, hold success, cash: 21731.50, holding value:24300.00
-[2023-05-09 13:55:25,626] Code: 2303, sell success, cash: 23356.50, holding value:22750.00
-[2023-05-09 13:55:25,628] Code: 2303, sell success, cash: 24996.50, holding value:21320.00
-[2023-05-09 13:55:25,629] Code: 2303, buy success, cash: 23351.50, holding value:23030.00
-[2023-05-09 13:55:25,630] Code: 2303, buy success, cash: 21711.50, holding value:24600.00
-[2023-05-09 13:55:25,632] Code: 2303, sell success, cash: 23376.50, holding value:23310.00
-[2023-05-09 13:55:25,633] Code: 2303, buy success, cash: 21731.50, holding value:24675.00
-[2023-05-09 13:55:25,634] Code: 2303, sell success, cash: 23381.50, holding value:23100.00
-[2023-05-09 13:55:25,634] Code: 2303, buy success, cash: 21731.50, holding value:24750.00
-[2023-05-09 13:55:25,635] Code: 2303, buy success, cash: 20091.50, holding value:26240.00
-[2023-05-09 13:55:25,637] Code: 2303, hold success, cash: 20091.50, holding value:26560.00
-[2023-05-09 13:55:25,638] Code: 2303, hold success, cash: 20091.50, holding value:26240.00
-[2023-05-09 13:55:25,639] Code: 2303, hold success, cash: 20091.50, holding value:26880.00
-[2023-05-09 13:55:25,641] Code: 2303, sell success, cash: 21776.50, holding value:25275.00
-[2023-05-09 13:55:25,642] Code: 2303, buy success, cash: 19926.50, holding value:29600.00
-[2023-05-09 13:55:25,643] Code: 2303, hold success, cash: 19926.50, holding value:28960.00
-[2023-05-09 13:55:25,644] Code: 2303, sell success, cash: 21791.50, holding value:27975.00
-[2023-05-09 13:55:25,645] Code: 2303, hold success, cash: 21791.50, holding value:27300.00
-[2023-05-09 13:55:25,647] Code: 2303, sell success, cash: 23596.50, holding value:25270.00
-[2023-05-09 13:55:25,648] Code: 2303, hold success, cash: 23596.50, holding value:24710.00
-[2023-05-09 13:55:25,649] Code: 2303, hold success, cash: 23596.50, holding value:24920.00
-[2023-05-09 13:55:25,650] Code: 2303, sell success, cash: 25376.50, holding value:23140.00
-[2023-05-09 13:55:25,651] Code: 2303, sell success, cash: 27136.50, holding value:21120.00
-[2023-05-09 13:55:25,652] Code: 2303, hold success, cash: 27136.50, holding value:21120.00
-[2023-05-09 13:55:25,653] Code: 2303, sell success, cash: 28831.50, holding value:18645.00
-[2023-05-09 13:55:25,654] Code: 2303, buy success, cash: 27011.50, holding value:21840.00
-[2023-05-09 13:55:25,655] Code: 2303, sell success, cash: 28806.50, holding value:19745.00
-[2023-05-09 13:55:25,656] Code: 2303, buy success, cash: 27011.50, holding value:21540.00
-[2023-05-09 13:55:25,658] Code: 2303, buy success, cash: 25216.50, holding value:23335.00
-[2023-05-09 13:55:25,659] Code: 2303, sell success, cash: 26976.50, holding value:21120.00
-[2023-05-09 13:55:25,661] Code: 2303, hold success, cash: 26976.50, holding value:21180.00
-[2023-05-09 13:55:25,661] Code: 2303, hold success, cash: 26976.50, holding value:20400.00
-[2023-05-09 13:55:25,662] Code: 2303, buy success, cash: 25286.50, holding value:21970.00
-[2023-05-09 13:55:25,664] Code: 2303, sell success, cash: 27031.50, holding value:20940.00
-[2023-05-09 13:55:25,665] Code: 2303, hold success, cash: 27031.50, holding value:20880.00
-[2023-05-09 13:55:25,666] Code: 2303, hold success, cash: 27031.50, holding value:20700.00
-[2023-05-09 13:55:25,667] Code: 2303, buy success, cash: 25306.50, holding value:22425.00
-[2023-05-09 13:55:25,668] Code: 2303, hold success, cash: 25306.50, holding value:22620.00
-[2023-05-09 13:55:25,669] Code: 2303, buy success, cash: 23546.50, holding value:24640.00
-[2023-05-09 13:55:25,670] Code: 2303, buy success, cash: 21761.50, holding value:26775.00
-[2023-05-09 13:55:25,671] Code: 2303, buy success, cash: 19936.50, holding value:29200.00
-[2023-05-09 13:55:25,673] Code: 2303, sell success, cash: 21756.50, holding value:27300.00
-[2023-05-09 13:55:25,674] Code: 2303, hold success, cash: 21756.50, holding value:27300.00
-[2023-05-09 13:55:25,675] Code: 2303, hold success, cash: 21756.50, holding value:26250.00
-[2023-05-09 13:55:25,676] Code: 2303, buy success, cash: 20026.50, holding value:27680.00
-[2023-05-09 13:55:25,678] Code: 2303, hold success, cash: 20026.50, holding value:27520.00
-[2023-05-09 13:55:25,679] Code: 2303, hold success, cash: 20026.50, holding value:28080.00
-[2023-05-09 13:55:25,681] Code: 2303, sell success, cash: 21766.50, holding value:26100.00
-[2023-05-09 13:55:25,682] Code: 2303, hold success, cash: 21766.50, holding value:25950.00
-[2023-05-09 13:55:25,683] Code: 2303, sell success, cash: 23536.50, holding value:24780.00
-[2023-05-09 13:55:25,684] Code: 2303, hold success, cash: 23536.50, holding value:25130.00
-[2023-05-09 13:55:25,685] Code: 2303, sell success, cash: 25321.50, holding value:23205.00
-[2023-05-09 13:55:25,686] Code: 2303, sell success, cash: 27116.50, holding value:21540.00
-[2023-05-09 13:55:25,687] Code: 2303, sell success, cash: 28901.50, holding value:19635.00
-[2023-05-09 13:55:25,688] Code: 2303, hold success, cash: 28901.50, holding value:19745.00
-[2023-05-09 13:55:25,689] Code: 2303, buy success, cash: 27171.50, holding value:20760.00
-[2023-05-09 13:55:25,691] Code: 2303, buy success, cash: 25431.50, holding value:22620.00
-[2023-05-09 13:55:25,692] Code: 2303, buy success, cash: 23736.50, holding value:23730.00
-[2023-05-09 13:55:25,693] Code: 2303, buy success, cash: 22021.50, holding value:25725.00
-[2023-05-09 13:55:25,694] Code: 2303, sell success, cash: 23741.50, holding value:24080.00
-[2023-05-09 13:55:25,695] Code: 2303, buy success, cash: 21986.50, holding value:26325.00
-[2023-05-09 13:55:25,697] Code: 2303, hold success, cash: 21986.50, holding value:27000.00
-[2023-05-09 13:55:25,698] Code: 2303, hold success, cash: 21986.50, holding value:26250.00
-[2023-05-09 13:55:25,699] Code: 2303, buy success, cash: 20221.50, holding value:28240.00
-[2023-05-09 13:55:25,701] Code: 2303, hold success, cash: 20221.50, holding value:27680.00
-[2023-05-09 13:55:25,702] Code: 2303, buy success, cash: 18481.50, holding value:29580.00
-[2023-05-09 13:55:25,703] Code: 2303, sell success, cash: 20231.50, holding value:28000.00
-[2023-05-09 13:55:25,704] Code: 2303, hold success, cash: 20231.50, holding value:28080.00
-[2023-05-09 13:55:25,706] Code: 2303, sell success, cash: 21966.50, holding value:26025.00
-[2023-05-09 13:55:25,707] Code: 2303, buy success, cash: 20231.50, holding value:27760.00
-[2023-05-09 13:55:25,708] Code: 2303, hold success, cash: 20231.50, holding value:27360.00
-[2023-05-09 13:55:25,710] Code: 2303, buy success, cash: 18511.50, holding value:29240.00
-[2023-05-09 13:55:25,712] Code: 2303, sell success, cash: 20211.50, holding value:27200.00
-[2023-05-09 13:55:25,714] Code: 2303, hold success, cash: 20211.50, holding value:27040.00
-[2023-05-09 13:55:25,718] Code: 2303, sell success, cash: 21841.50, holding value:24450.00
-[2023-05-09 13:55:25,722] Code: 2303, hold success, cash: 21841.50, holding value:23325.00
-[2023-05-09 13:55:25,724] Code: 2303, sell success, cash: 23406.50, holding value:21910.00
-[2023-05-09 13:55:25,727] Code: 2303, sell success, cash: 24946.50, holding value:20020.00
-[2023-05-09 13:55:25,730] Code: 2303, sell success, cash: 26506.50, holding value:18720.00
-[2023-05-09 13:55:25,733] Code: 2303, buy success, cash: 24936.50, holding value:20410.00
-[2023-05-09 13:55:25,736] Code: 2303, hold success, cash: 24936.50, holding value:20280.00
-[2023-05-09 13:55:25,739] Code: 2303, hold success, cash: 24936.50, holding value:19890.00
-[2023-05-09 13:55:25,742] Code: 2303, hold success, cash: 24936.50, holding value:20280.00
-[2023-05-09 13:55:25,744] Code: 2303, hold success, cash: 24936.50, holding value:20085.00
-[2023-05-09 13:55:25,748] Code: 2303, hold success, cash: 24936.50, holding value:20605.00
-[2023-05-09 13:55:25,750] Code: 2303, buy success, cash: 23371.50, holding value:21910.00
-[2023-05-09 13:55:25,755] Code: 2303, sell success, cash: 24961.50, holding value:20670.00
-[2023-05-09 13:55:25,759] Code: 2303, sell success, cash: 26556.50, holding value:19140.00
-[2023-05-09 13:55:25,764] Code: 2303, hold success, cash: 26556.50, holding value:19380.00
-[2023-05-09 13:55:25,767] Code: 2303, hold success, cash: 26556.50, holding value:19080.00
-[2023-05-09 13:55:25,771] Code: 2303, hold success, cash: 26556.50, holding value:18720.00
-[2023-05-09 13:55:25,776] Code: 2303, sell success, cash: 28106.50, holding value:17050.00
-[2023-05-09 13:55:25,781] Code: 2303, hold success, cash: 28106.50, holding value:16610.00
-[2023-05-09 13:55:25,783] Code: 2303, buy success, cash: 26636.50, holding value:17640.00
-[2023-05-09 13:55:25,788] Code: 2303, sell success, cash: 28116.50, holding value:16280.00
-[2023-05-09 13:55:25,791] Code: 2303, sell success, cash: 29596.50, holding value:14800.00
-[2023-05-09 13:55:25,796] Code: 2303, hold success, cash: 29596.50, holding value:13750.00
-[2023-05-09 13:55:25,799] Code: 2303, buy success, cash: 28231.50, holding value:15015.00
-[2023-05-09 13:55:25,803] Code: 2303, hold success, cash: 28231.50, holding value:14685.00
-[2023-05-09 13:55:25,807] Code: 2303, buy success, cash: 26911.50, holding value:15840.00
-[2023-05-09 13:55:25,809] Code: 2303, hold success, cash: 26911.50, holding value:16320.00
-[2023-05-09 13:55:25,812] Code: 2303, buy success, cash: 25586.50, holding value:17225.00
-[2023-05-09 13:55:25,815] Code: 2303, hold success, cash: 25586.50, holding value:17290.00
-[2023-05-09 13:55:25,819] Code: 2303, buy success, cash: 24276.50, holding value:18340.00
-[2023-05-09 13:55:25,823] Code: 2303, buy success, cash: 23001.50, holding value:19125.00
-[2023-05-09 13:55:25,826] Code: 2303, buy success, cash: 21736.50, holding value:20240.00
-[2023-05-09 13:55:25,829] Code: 2303, sell success, cash: 22966.50, holding value:18450.00
-[2023-05-09 13:55:25,831] Code: 2303, hold success, cash: 22966.50, holding value:17550.00
-[2023-05-09 13:55:25,834] Code: 2303, buy success, cash: 21806.50, holding value:18560.00
-[2023-05-09 13:55:25,837] Code: 2303, hold success, cash: 21806.50, holding value:18720.00
-[2023-05-09 13:55:25,839] Code: 2303, sell success, cash: 22986.50, holding value:17700.00
-[2023-05-09 13:55:25,840] Code: 2303, buy success, cash: 21791.50, holding value:19120.00
-[2023-05-09 13:55:25,842] Code: 2303, buy success, cash: 20601.50, holding value:20230.00
-[2023-05-09 13:55:25,843] Code: 2303, hold success, cash: 20601.50, holding value:18275.00
-[2023-05-09 13:55:25,844] Code: 2303, sell success, cash: 21691.50, holding value:17440.00
-[2023-05-09 13:55:25,848] Code: 2303, buy success, cash: 20596.50, holding value:18615.00
-[2023-05-09 13:55:25,849] Code: 2303, hold success, cash: 20596.50, holding value:18445.00
-[2023-05-09 13:55:25,853] Code: 2303, hold success, cash: 20596.50, holding value:18020.00
-[2023-05-09 13:55:25,855] Code: 2303, hold success, cash: 20596.50, holding value:18190.00
-[2023-05-09 13:55:25,855] Code: 2303, hold success, cash: 20596.50, holding value:17765.00
-[2023-05-09 13:55:25,856] Code: 2303, buy success, cash: 19516.50, holding value:19440.00
-[2023-05-09 13:55:25,857] Code: 2303, sell success, cash: 20636.50, holding value:19040.00
-[2023-05-09 13:55:25,858] Code: 2303, buy success, cash: 19536.50, holding value:19800.00
-[2023-05-09 13:55:25,859] Code: 2303, sell success, cash: 20646.50, holding value:18870.00
-[2023-05-09 13:55:25,861] Code: 2303, sell success, cash: 21746.50, holding value:17600.00
-[2023-05-09 13:55:25,865] Code: 2303, sell success, cash: 22846.50, holding value:16500.00
-[2023-05-09 13:55:25,867] Code: 2303, sell success, cash: 23966.50, holding value:15680.00
-[2023-05-09 13:55:25,871] Code: 2303, buy success, cash: 22851.50, holding value:16725.00
-[2023-05-09 13:55:25,873] Code: 2303, hold success, cash: 22851.50, holding value:17250.00
-[2023-05-09 13:55:25,875] Code: 2303, hold success, cash: 22851.50, holding value:17625.00
-[2023-05-09 13:55:25,876] Code: 2303, sell success, cash: 24026.50, holding value:16450.00
-[2023-05-09 13:55:25,879] Code: 2303, buy success, cash: 22876.50, holding value:17250.00
-[2023-05-09 13:55:25,881] Code: 2303, hold success, cash: 22876.50, holding value:17325.00
-[2023-05-09 13:55:25,884] Code: 2303, hold success, cash: 22876.50, holding value:17550.00
-[2023-05-09 13:55:25,887] Code: 2303, hold success, cash: 22876.50, holding value:17700.00
-[2023-05-09 13:55:25,889] Code: 2303, buy success, cash: 21721.50, holding value:18480.00
-[2023-05-09 13:55:25,891] Code: 2303, sell success, cash: 22851.50, holding value:16950.00
-[2023-05-09 13:55:25,893] Code: 2303, hold success, cash: 22851.50, holding value:16800.00
-[2023-05-09 13:55:25,896] Code: 2303, sell success, cash: 23961.50, holding value:15540.00
-[2023-05-09 13:55:25,898] Code: 2303, hold success, cash: 23961.50, holding value:15400.00
-[2023-05-09 13:55:25,903] Code: 2303, sell success, cash: 25091.50, holding value:14690.00
-[2023-05-09 13:55:25,905] Code: 2303, hold success, cash: 25091.50, holding value:14950.00
-[2023-05-09 13:55:25,907] Code: 2303, sell success, cash: 26226.50, holding value:13620.00
-[2023-05-09 13:55:25,908] Code: 2303, buy success, cash: 25086.50, holding value:14820.00
-[2023-05-09 13:55:25,910] Code: 2303, sell success, cash: 26206.50, holding value:13440.00
-[2023-05-09 13:55:25,913] Code: 2303, buy success, cash: 25076.50, holding value:14690.00
-[2023-05-09 13:55:25,914] Code: 2303, hold success, cash: 25076.50, holding value:14690.00
-[2023-05-09 13:55:25,919] Code: 2303, buy success, cash: 23936.50, holding value:15960.00
-[2023-05-09 13:55:25,921] Code: 2303, hold success, cash: 23936.50, holding value:15750.00
-[2023-05-09 13:55:25,922] Code: 2303, buy success, cash: 22816.50, holding value:16800.00
-[2023-05-09 13:55:25,924] Code: 2303, hold success, cash: 22816.50, holding value:16725.00
-[2023-05-09 13:55:25,926] Code: 2303, buy success, cash: 21696.50, holding value:17920.00
-[2023-05-09 13:55:25,928] Code: 2303, hold success, cash: 21696.50, holding value:18000.00
-[2023-05-09 13:55:25,929] Code: 2303, hold success, cash: 21696.50, holding value:18000.00
-[2023-05-09 13:55:25,931] Code: 2303, sell success, cash: 22836.50, holding value:17100.00
-[2023-05-09 13:55:25,935] Code: 2303, sell success, cash: 23971.50, holding value:15890.00
-[2023-05-09 13:55:25,937] Code: 2303, sell success, cash: 25111.50, holding value:14820.00
-[2023-05-09 13:55:25,938] Code: 2303, sell success, cash: 26271.50, holding value:13920.00
-[2023-05-09 13:55:25,940] Code: 2303, buy success, cash: 25111.50, holding value:15080.00
-[2023-05-09 13:55:25,941] Code: 2303, sell success, cash: 26276.50, holding value:13980.00
-[2023-05-09 13:55:25,943] Code: 2303, sell success, cash: 27441.50, holding value:12815.00
-[2023-05-09 13:55:25,945] Code: 2303, buy success, cash: 26261.50, holding value:14160.00
-[2023-05-09 13:55:25,946] Code: 2303, hold success, cash: 26261.50, holding value:14160.00
-[2023-05-09 13:55:25,949] Code: 2303, sell success, cash: 27426.50, holding value:12815.00
-[2023-05-09 13:55:25,952] Code: 2303, hold success, cash: 27426.50, holding value:12815.00
-[2023-05-09 13:55:25,954] Code: 2303, buy success, cash: 26261.50, holding value:13980.00
-[2023-05-09 13:55:25,955] Code: 2303, buy success, cash: 25101.50, holding value:15080.00
-[2023-05-09 13:55:25,957] Code: 2303, buy success, cash: 23941.50, holding value:16240.00
-[2023-05-09 13:55:25,958] Code: 2303, hold success, cash: 23941.50, holding value:16170.00
-[2023-05-09 13:55:25,959] Code: 2303, sell success, cash: 25076.50, holding value:14755.00
-[2023-05-09 13:55:25,962] Code: 2303, buy success, cash: 23946.50, holding value:15820.00
-[2023-05-09 13:55:25,964] Code: 2303, hold success, cash: 23946.50, holding value:15960.00
-[2023-05-09 13:55:25,965] Code: 2303, hold success, cash: 23946.50, holding value:16030.00
-[2023-05-09 13:55:25,968] Code: 2303, buy success, cash: 22796.50, holding value:17250.00
-[2023-05-09 13:55:25,970] Code: 2303, buy success, cash: 21651.50, holding value:18320.00
-[2023-05-09 13:55:25,972] Code: 2303, sell success, cash: 22801.50, holding value:17250.00
-[2023-05-09 13:55:25,974] Code: 2303, buy success, cash: 21641.50, holding value:18560.00
-[2023-05-09 13:55:25,975] Code: 2303, sell success, cash: 22811.50, holding value:17550.00
-[2023-05-09 13:55:25,976] Code: 2303, sell success, cash: 23981.50, holding value:16380.00
-[2023-05-09 13:55:25,978] Code: 2303, hold success, cash: 23981.50, holding value:16450.00
-[2023-05-09 13:55:25,980] Code: 2303, hold success, cash: 23981.50, holding value:16520.00
-[2023-05-09 13:55:25,982] Code: 2303, hold success, cash: 23981.50, holding value:16450.00
-[2023-05-09 13:55:25,986] Code: 2303, sell success, cash: 25156.50, holding value:15275.00
-[2023-05-09 13:55:25,989] Code: 2303, sell success, cash: 26331.50, holding value:14100.00
-[2023-05-09 13:55:25,990] Code: 2303, hold success, cash: 26331.50, holding value:14100.00
-[2023-05-09 13:55:25,992] Code: 2303, sell success, cash: 27486.50, holding value:12705.00
-[2023-05-09 13:55:25,994] Code: 2303, buy success, cash: 26311.50, holding value:14100.00
-[2023-05-09 13:55:25,995] Code: 2303, sell success, cash: 27586.50, holding value:14025.00
-[2023-05-09 13:55:25,997] Code: 2303, hold success, cash: 27586.50, holding value:13640.00
-[2023-05-09 13:55:25,999] Code: 2303, buy success, cash: 26356.50, holding value:14760.00
-[2023-05-09 13:55:26,002] Code: 2303, sell success, cash: 27571.50, holding value:13365.00
-[2023-05-09 13:55:26,005] Code: 2303, sell success, cash: 28781.50, holding value:12100.00
-[2023-05-09 13:55:26,006] Code: 2303, hold success, cash: 28781.50, holding value:12450.00
-[2023-05-09 13:55:26,007] Code: 2303, sell success, cash: 30006.50, holding value:11025.00
-[2023-05-09 13:55:26,010] Code: 2303, hold success, cash: 30006.50, holding value:10890.00
-[2023-05-09 13:55:26,011] Code: 2303, sell success, cash: 31216.50, holding value:9680.00
-[2023-05-09 13:55:26,013] Code: 2303, buy success, cash: 29996.50, holding value:10980.00
-[2023-05-09 13:55:26,015] Code: 2303, buy success, cash: 28776.50, holding value:12200.00
-[2023-05-09 13:55:26,018] Code: 2303, sell success, cash: 30001.50, holding value:11025.00
-[2023-05-09 13:55:26,020] Code: 2303, hold success, cash: 30001.50, holding value:11160.00
-[2023-05-09 13:55:26,022] Code: 2303, hold success, cash: 30001.50, holding value:11160.00
-[2023-05-09 13:55:26,024] Code: 2303, buy success, cash: 28771.50, holding value:12300.00
-[2023-05-09 13:55:26,027] Code: 2303, sell success, cash: 30001.50, holding value:11070.00
-[2023-05-09 13:55:26,028] Code: 2303, hold success, cash: 30001.50, holding value:10980.00
-[2023-05-09 13:55:26,030] Code: 2303, hold success, cash: 30001.50, holding value:11160.00
-[2023-05-09 13:55:26,031] Code: 2303, hold success, cash: 30001.50, holding value:11025.00
-[2023-05-09 13:55:26,033] Code: 2303, sell success, cash: 31226.50, holding value:9800.00
-[2023-05-09 13:55:26,035] Code: 2303, hold success, cash: 31226.50, holding value:9680.00
-[2023-05-09 13:55:26,036] Code: 2303, buy success, cash: 30016.50, holding value:10890.00
-[2023-05-09 13:55:26,037] Code: 2303, sell success, cash: 31236.50, holding value:9760.00
-[2023-05-09 13:55:26,038] Code: 2303, hold success, cash: 31236.50, holding value:9760.00
-[2023-05-09 13:55:26,039] Code: 2303, hold success, cash: 31236.50, holding value:9800.00
-[2023-05-09 13:55:26,039] Code: 2303, buy success, cash: 30016.50, holding value:10980.00
-[2023-05-09 13:55:26,042] Code: 2303, buy success, cash: 28801.50, holding value:12150.00
-[2023-05-09 13:55:26,044] Code: 2303, sell success, cash: 30016.50, holding value:10935.00
-[2023-05-09 13:55:26,045] Code: 2303, buy success, cash: 28801.50, holding value:12150.00
-[2023-05-09 13:55:26,047] Code: 2303, buy success, cash: 27601.50, holding value:13200.00
-[2023-05-09 13:55:26,049] Code: 2303, buy success, cash: 26391.50, holding value:14520.00
-[2023-05-09 13:55:26,050] Code: 2303, sell success, cash: 27591.50, holding value:13200.00
-[2023-05-09 13:55:26,054] Code: 2303, hold success, cash: 27591.50, holding value:13255.00
-[2023-05-09 13:55:26,057] Code: 2303, hold success, cash: 27591.50, holding value:13310.00
-[2023-05-09 13:55:26,058] Code: 2303, sell success, cash: 28786.50, holding value:11950.00
-[2023-05-09 13:55:26,059] Code: 2303, sell success, cash: 29971.50, holding value:10665.00
-[2023-05-09 13:55:26,062] Code: 2303, hold success, cash: 29971.50, holding value:10710.00
-[2023-05-09 13:55:26,064] Code: 2303, hold success, cash: 29971.50, holding value:10710.00
-[2023-05-09 13:55:26,065] Code: 2303, sell success, cash: 31171.50, holding value:9600.00
-[2023-05-09 13:55:26,069] Code: 2303, buy success, cash: 29961.50, holding value:10890.00
-[2023-05-09 13:55:26,072] Code: 2303, buy success, cash: 28751.50, holding value:12100.00
-[2023-05-09 13:55:26,074] Code: 2303, hold success, cash: 28751.50, holding value:12050.00
-[2023-05-09 13:55:26,075] Code: 2303, hold success, cash: 28751.50, holding value:12050.00
-[2023-05-09 13:55:26,076] Code: 2303, sell success, cash: 29956.50, holding value:10845.00
-[2023-05-09 13:55:26,078] Code: 2303, buy success, cash: 28736.50, holding value:12200.00
-[2023-05-09 13:55:26,080] Code: 2303, hold success, cash: 28736.50, holding value:12100.00
-[2023-05-09 13:55:26,081] Code: 2303, hold success, cash: 28736.50, holding value:12200.00
-[2023-05-09 13:55:26,084] Code: 2303, buy success, cash: 27526.50, holding value:13310.00
-[2023-05-09 13:55:26,086] Code: 2303, hold success, cash: 27526.50, holding value:13475.00
-[2023-05-09 13:55:26,088] Code: 2303, sell success, cash: 28746.50, holding value:12200.00
-[2023-05-09 13:55:26,089] Code: 2303, hold success, cash: 28746.50, holding value:12300.00
-[2023-05-09 13:55:26,090] Code: 2303, sell success, cash: 29971.50, holding value:11025.00
-[2023-05-09 13:55:26,091] Code: 2303, sell success, cash: 31186.50, holding value:9720.00
-[2023-05-09 13:55:26,092] Code: 2303, hold success, cash: 31186.50, holding value:9760.00
-[2023-05-09 13:55:26,093] Code: 2303, sell success, cash: 32411.50, holding value:8575.00
-[2023-05-09 13:55:26,095] Code: 2303, sell success, cash: 33631.50, holding value:7320.00
-[2023-05-09 13:55:26,096] Code: 2303, hold success, cash: 33631.50, holding value:7350.00
-[2023-05-09 13:55:26,100] Code: 2303, hold success, cash: 33631.50, holding value:7410.00
-[2023-05-09 13:55:26,194] Code: 2303, buy success, cash: 32396.50, holding value:8645.00
-[2023-05-09 13:55:26,198] Code: 2303, sell success, cash: 33636.50, holding value:7440.00
-[2023-05-09 13:55:26,202] Code: 2303, sell success, cash: 34881.50, holding value:6225.00
-[2023-05-09 13:55:26,231] Code: 2303, buy success, cash: 33636.50, holding value:7470.00
-[2023-05-09 13:55:26,233] Code: 2303, hold success, cash: 33636.50, holding value:7440.00
-[2023-05-09 13:55:26,236] Code: 2303, sell success, cash: 34876.50, holding value:6200.00
-[2023-05-09 13:55:26,239] Code: 2303, hold success, cash: 34876.50, holding value:6200.00
-[2023-05-09 13:55:26,240] Code: 2303, sell success, cash: 36121.50, holding value:4980.00
-[2023-05-09 13:55:26,241] Code: 2303, buy success, cash: 34876.50, holding value:6225.00
-[2023-05-09 13:55:26,243] Code: 2303, sell success, cash: 36121.50, holding value:4980.00
-[2023-05-09 13:55:26,245] Code: 2303, buy success, cash: 34886.50, holding value:6175.00
-[2023-05-09 13:55:26,247] Code: 2303, buy success, cash: 33661.50, holding value:7350.00
-[2023-05-09 13:55:26,248] Code: 2303, sell success, cash: 34876.50, holding value:6075.00
-[2023-05-09 13:55:26,251] Code: 2303, buy success, cash: 33656.50, holding value:7320.00
-[2023-05-09 13:55:26,253] Code: 2303, hold success, cash: 33656.50, holding value:7290.00
-[2023-05-09 13:55:26,255] Code: 2303, buy success, cash: 32436.50, holding value:8540.00
-[2023-05-09 13:55:26,257] Code: 2303, sell success, cash: 33656.50, holding value:7320.00
-[2023-05-09 13:55:26,260] Code: 2303, buy success, cash: 32431.50, holding value:8575.00
-[2023-05-09 13:55:26,262] Code: 2303, sell success, cash: 33661.50, holding value:7380.00
-[2023-05-09 13:55:26,264] Code: 2303, buy success, cash: 32421.50, holding value:8680.00
-[2023-05-09 13:55:26,268] Code: 2303, buy success, cash: 31181.50, holding value:9920.00
-[2023-05-09 13:55:26,270] Code: 2303, buy success, cash: 29901.50, holding value:11520.00
-[2023-05-09 13:55:26,272] Code: 2303, hold success, cash: 29901.50, holding value:11970.00
-[2023-05-09 13:55:26,276] Code: 2303, sell success, cash: 31216.50, holding value:10520.00
-[2023-05-09 13:55:26,278] Code: 2303, buy success, cash: 29771.50, holding value:13005.00
-[2023-05-09 13:55:26,279] Code: 2303, sell success, cash: 31246.50, holding value:11800.00
-[2023-05-09 13:55:26,281] Code: 2303, hold success, cash: 31246.50, holding value:11800.00
-[2023-05-09 13:55:26,282] Code: 2303, hold success, cash: 31246.50, holding value:11520.00
-[2023-05-09 13:55:26,284] Code: 2303, hold success, cash: 31246.50, holding value:11360.00
-[2023-05-09 13:55:26,290] Code: 2303, buy success, cash: 29806.50, holding value:12960.00
-[2023-05-09 13:55:26,291] Code: 2303, buy success, cash: 28361.50, holding value:14450.00
-[2023-05-09 13:55:26,293] Code: 2303, buy success, cash: 26926.50, holding value:15785.00
-[2023-05-09 13:55:26,294] Code: 2303, sell success, cash: 28356.50, holding value:14300.00
-[2023-05-09 13:55:26,295] Code: 2303, hold success, cash: 28356.50, holding value:14100.00
-[2023-05-09 13:55:26,297] Code: 2303, hold success, cash: 28356.50, holding value:14200.00
-[2023-05-09 13:55:26,299] Code: 2303, buy success, cash: 26871.50, holding value:16335.00
-[2023-05-09 13:55:26,300] Code: 2303, sell success, cash: 28326.50, holding value:14550.00
-[2023-05-09 13:55:26,304] Code: 2303, hold success, cash: 28326.50, holding value:14450.00
-[2023-05-09 13:55:26,305] Code: 2303, hold success, cash: 28326.50, holding value:14450.00
-[2023-05-09 13:55:26,306] Code: 2303, hold success, cash: 28326.50, holding value:14800.00
-[2023-05-09 13:55:26,307] Code: 2303, sell success, cash: 29831.50, holding value:13545.00
-[2023-05-09 13:55:26,307] Code: 2303, buy success, cash: 28356.50, holding value:14750.00
-[2023-05-09 13:55:26,312] Code: 2303, hold success, cash: 28356.50, holding value:14800.00
-[2023-05-09 13:55:26,314] Code: 2303, sell success, cash: 29846.50, holding value:13410.00
-[2023-05-09 13:55:26,315] Code: 2303, sell success, cash: 31386.50, holding value:12320.00
-[2023-05-09 13:55:26,319] Code: 2303, hold success, cash: 31386.50, holding value:11400.00
-[2023-05-09 13:55:26,321] Code: 2303, hold success, cash: 31386.50, holding value:11120.00
-[2023-05-09 13:55:26,324] Code: 2303, sell success, cash: 32776.50, holding value:9730.00
-[2023-05-09 13:55:26,329] Code: 2303, hold success, cash: 32776.50, holding value:9555.00
-[2023-05-09 13:55:26,330] Code: 2303, buy success, cash: 31411.50, holding value:10920.00
-[2023-05-09 13:55:26,332] Code: 2303, buy success, cash: 30071.50, holding value:12060.00
-[2023-05-09 13:55:26,337] Code: 2303, buy success, cash: 28686.50, holding value:13850.00
-[2023-05-09 13:55:26,340] Code: 2303, sell success, cash: 30076.50, holding value:12510.00
-[2023-05-09 13:55:26,341] Code: 2303, buy success, cash: 28676.50, holding value:14000.00
-[2023-05-09 13:55:26,343] Code: 2303, sell success, cash: 30066.50, holding value:12510.00
-[2023-05-09 13:55:26,344] Code: 2303, buy success, cash: 28666.50, holding value:14000.00
-[2023-05-09 13:55:26,346] Code: 2303, buy success, cash: 27261.50, holding value:15455.00
-[2023-05-09 13:55:26,348] Code: 2303, sell success, cash: 28666.50, holding value:14050.00
-[2023-05-09 13:55:26,349] Code: 2303, buy success, cash: 27256.50, holding value:15510.00
-[2023-05-09 13:55:26,354] Code: 2303, sell success, cash: 28661.50, holding value:14050.00
-[2023-05-09 13:55:26,356] Code: 2303, buy success, cash: 27246.50, holding value:15565.00
-[2023-05-09 13:55:26,357] Code: 2303, buy success, cash: 25836.50, holding value:16920.00
-[2023-05-09 13:55:26,364] Code: 2303, hold success, cash: 25836.50, holding value:16980.00
-[2023-05-09 13:55:26,366] Code: 2303, buy success, cash: 24406.50, holding value:18590.00
-[2023-05-09 13:55:26,369] Code: 2303, sell success, cash: 25826.50, holding value:17040.00
-[2023-05-09 13:55:26,373] Code: 2303, hold success, cash: 25826.50, holding value:17940.00
-[2023-05-09 13:55:26,376] Code: 2303, sell success, cash: 27316.50, holding value:16390.00
-[2023-05-09 13:55:26,379] Code: 2303, hold success, cash: 27316.50, holding value:16390.00
-[2023-05-09 13:55:26,381] Code: 2303, buy success, cash: 25826.50, holding value:17880.00
-[2023-05-09 13:55:26,383] Code: 2303, buy success, cash: 24341.50, holding value:19305.00
-[2023-05-09 13:55:26,386] Code: 2303, sell success, cash: 25846.50, holding value:18060.00
-[2023-05-09 13:55:26,390] Code: 2303, sell success, cash: 27451.50, holding value:17655.00
-[2023-05-09 13:55:26,392] Code: 2303, sell success, cash: 29101.50, holding value:16500.00
-[2023-05-09 13:55:26,393] Code: 2303, sell success, cash: 30751.50, holding value:14850.00
-[2023-05-09 13:55:26,395] Code: 2303, buy success, cash: 29146.50, holding value:16050.00
-[2023-05-09 13:55:26,397] Code: 2303, buy success, cash: 27516.50, holding value:17930.00
-[2023-05-09 13:55:26,398] Code: 2303, buy success, cash: 25891.50, holding value:19500.00
-[2023-05-09 13:55:26,400] Code: 2303, sell success, cash: 27496.50, holding value:17655.00
-[2023-05-09 13:55:26,403] Code: 2303, hold success, cash: 27496.50, holding value:17490.00
-[2023-05-09 13:55:26,406] Code: 2303, buy success, cash: 25926.50, holding value:18840.00
-[2023-05-09 13:55:26,409] Code: 2303, hold success, cash: 25926.50, holding value:19080.00
-[2023-05-09 13:55:26,411] Code: 2303, buy success, cash: 24371.50, holding value:20215.00
-[2023-05-09 13:55:26,412] Code: 2303, hold success, cash: 24371.50, holding value:20670.00
-[2023-05-09 13:55:26,414] Code: 2303, sell success, cash: 25971.50, holding value:19200.00
-[2023-05-09 13:55:26,416] Code: 2303, buy success, cash: 24406.50, holding value:20345.00
-[2023-05-09 13:55:26,419] Code: 2303, hold success, cash: 24406.50, holding value:20605.00
-[2023-05-09 13:55:26,424] Code: 2303, hold success, cash: 24406.50, holding value:20150.00
-[2023-05-09 13:55:26,425] Code: 2303, buy success, cash: 22886.50, holding value:21280.00
-[2023-05-09 13:55:26,428] Code: 2303, sell success, cash: 24411.50, holding value:19825.00
-[2023-05-09 13:55:26,430] Code: 2303, buy success, cash: 22886.50, holding value:21350.00
-[2023-05-09 13:55:26,432] Code: 2303, sell success, cash: 24431.50, holding value:20085.00
-[2023-05-09 13:55:26,434] Code: 2303, sell success, cash: 25946.50, holding value:18180.00
-[2023-05-09 13:55:26,440] Code: 2303, buy success, cash: 24446.50, holding value:19500.00
-[2023-05-09 13:55:26,442] Code: 2303, buy success, cash: 22931.50, holding value:21210.00
-[2023-05-09 13:55:26,444] Code: 2303, hold success, cash: 22931.50, holding value:22120.00
-[2023-05-09 13:55:26,447] Code: 2303, sell success, cash: 24501.50, holding value:20410.00
-[2023-05-09 13:55:26,452] Code: 2303, hold success, cash: 24501.50, holding value:20215.00
-[2023-05-09 13:55:26,456] Code: 2303, sell success, cash: 26081.50, holding value:18960.00
-[2023-05-09 13:55:26,459] Code: 2303, buy success, cash: 24491.50, holding value:20670.00
-[2023-05-09 13:55:26,462] Code: 2303, sell success, cash: 26086.50, holding value:19140.00
-[2023-05-09 13:55:26,464] Code: 2303, hold success, cash: 26086.50, holding value:19140.00
-[2023-05-09 13:55:26,472] Code: 2303, hold success, cash: 26086.50, holding value:19080.00
-[2023-05-09 13:55:26,475] Code: 2303, hold success, cash: 26086.50, holding value:19140.00
-[2023-05-09 13:55:26,478] Code: 2303, hold success, cash: 26086.50, holding value:18780.00
-[2023-05-09 13:55:26,480] Code: 2303, hold success, cash: 26086.50, holding value:18660.00
-[2023-05-09 13:55:26,487] Code: 2303, hold success, cash: 26086.50, holding value:18720.00
-[2023-05-09 13:55:26,491] Code: 2303, sell success, cash: 27641.50, holding value:17105.00
-[2023-05-09 13:55:26,493] Code: 2303, hold success, cash: 27641.50, holding value:17050.00
-[2023-05-09 13:55:26,496] Code: 2303, hold success, cash: 27641.50, holding value:17105.00
-[2023-05-09 13:55:26,499] Code: 2303, hold success, cash: 27641.50, holding value:16995.00
-[2023-05-09 13:55:26,505] Code: 2303, sell success, cash: 29221.50, holding value:15800.00
-[2023-05-09 13:55:26,509] Code: 2303, buy success, cash: 27671.50, holding value:17050.00
-[2023-05-09 13:55:26,511] Code: 2303, buy success, cash: 26121.50, holding value:18600.00
-[2023-05-09 13:55:26,514] Code: 2303, hold success, cash: 26121.50, holding value:18600.00
-[2023-05-09 13:55:26,519] Code: 2303, buy success, cash: 24576.50, holding value:20085.00
-[2023-05-09 13:55:26,525] Code: 2303, sell success, cash: 26101.50, holding value:18300.00
-[2023-05-09 13:55:26,528] Code: 2303, hold success, cash: 26101.50, holding value:18480.00
-[2023-05-09 13:55:26,529] Code: 2303, sell success, cash: 27636.50, holding value:16885.00
-[2023-05-09 13:55:26,531] Code: 2303, hold success, cash: 27636.50, holding value:17270.00
-[2023-05-09 13:55:26,539] Code: 2303, hold success, cash: 27636.50, holding value:17435.00
-[2023-05-09 13:55:26,541] Code: 2303, sell success, cash: 29201.50, holding value:15650.00
-[2023-05-09 13:55:26,543] Code: 2303, buy success, cash: 27626.50, holding value:17325.00
-[2023-05-09 13:55:26,544] Code: 2303, hold success, cash: 27626.50, holding value:17160.00
-[2023-05-09 13:55:26,546] Code: 2303, hold success, cash: 27626.50, holding value:17160.00
-[2023-05-09 13:55:26,547] Code: 2303, sell success, cash: 29191.50, holding value:15650.00
-[2023-05-09 13:55:26,550] Code: 2303, sell success, cash: 30781.50, holding value:14310.00
-[2023-05-09 13:55:26,556] Code: 2303, buy success, cash: 29166.50, holding value:16150.00
-[2023-05-09 13:55:26,558] Code: 2303, buy success, cash: 27556.50, holding value:17710.00
-[2023-05-09 13:55:26,559] Code: 2303, hold success, cash: 27556.50, holding value:17545.00
-[2023-05-09 13:55:26,561] Code: 2303, sell success, cash: 29151.50, holding value:15950.00
-[2023-05-09 13:55:26,562] Code: 2303, buy success, cash: 27571.50, holding value:17380.00
-[2023-05-09 13:55:26,564] Code: 2303, buy success, cash: 25986.50, holding value:19020.00
-[2023-05-09 13:55:26,568] Code: 2303, hold success, cash: 25986.50, holding value:18840.00
-[2023-05-09 13:55:26,573] Code: 2303, buy success, cash: 24456.50, holding value:19890.00
-[2023-05-09 13:55:26,575] Code: 2303, hold success, cash: 24456.50, holding value:19955.00
-[2023-05-09 13:55:26,577] Code: 2303, sell success, cash: 26026.50, holding value:18840.00
-[2023-05-09 13:55:26,578] Code: 2303, sell success, cash: 27581.50, holding value:17105.00
-[2023-05-09 13:55:26,580] Code: 2303, sell success, cash: 29081.50, holding value:15000.00
-[2023-05-09 13:55:26,582] Code: 2303, buy success, cash: 27616.50, holding value:16115.00
-[2023-05-09 13:55:26,588] Code: 2303, sell success, cash: 29081.50, holding value:14650.00
-[2023-05-09 13:55:26,591] Code: 2303, sell success, cash: 30596.50, holding value:13635.00
-[2023-05-09 13:55:26,593] Code: 2303, buy success, cash: 29101.50, holding value:14950.00
-[2023-05-09 13:55:26,595] Code: 2303, sell success, cash: 30581.50, holding value:13320.00
-[2023-05-09 13:55:26,597] Code: 2303, hold success, cash: 30581.50, holding value:13410.00
-[2023-05-09 13:55:26,599] Code: 2303, buy success, cash: 29116.50, holding value:14650.00
-[2023-05-09 13:55:26,604] Code: 2303, buy success, cash: 27666.50, holding value:15950.00
-[2023-05-09 13:55:26,607] Code: 2303, hold success, cash: 27666.50, holding value:16005.00
-[2023-05-09 13:55:26,610] Code: 2303, sell success, cash: 29126.50, holding value:14600.00
-[2023-05-09 13:55:26,611] Code: 2303, hold success, cash: 29126.50, holding value:14450.00
-[2023-05-09 13:55:26,613] Code: 2303, hold success, cash: 29126.50, holding value:14400.00
-[2023-05-09 13:55:26,615] Code: 2303, buy success, cash: 27681.50, holding value:15895.00
-[2023-05-09 13:55:26,617] Code: 2303, buy success, cash: 26276.50, holding value:16860.00
-[2023-05-09 13:55:26,623] Code: 2303, sell success, cash: 27696.50, holding value:15620.00
-[2023-05-09 13:55:26,625] Code: 2303, buy success, cash: 26266.50, holding value:17160.00
-[2023-05-09 13:55:26,626] Code: 2303, sell success, cash: 27686.50, holding value:15620.00
-[2023-05-09 13:55:26,627] Code: 2303, hold success, cash: 27686.50, holding value:12980.00
-[2023-05-09 13:55:26,629] Code: 2303, buy success, cash: 26511.50, holding value:14100.00
-[2023-05-09 13:55:26,630] Code: 2303, buy success, cash: 25336.50, holding value:15275.00
-[2023-05-09 13:55:26,631] Code: 2303, hold success, cash: 25336.50, holding value:14885.00
-[2023-05-09 13:55:26,635] Code: 2303, sell success, cash: 26476.50, holding value:13680.00
-[2023-05-09 13:55:26,639] Code: 2303, sell success, cash: 27581.50, holding value:12155.00
-[2023-05-09 13:55:26,641] Code: 2303, hold success, cash: 27581.50, holding value:12210.00
-[2023-05-09 13:55:26,642] Code: 2303, hold success, cash: 27581.50, holding value:12155.00
-[2023-05-09 13:55:26,643] Code: 2303, hold success, cash: 27581.50, holding value:12265.00
-[2023-05-09 13:55:26,644] Code: 2303, sell success, cash: 28706.50, holding value:11250.00
-[2023-05-09 13:55:26,646] Code: 2303, sell success, cash: 29821.50, holding value:10035.00
-[2023-05-09 13:55:26,647] Code: 2303, sell success, cash: 30936.50, holding value:8920.00
-[2023-05-09 13:55:26,648] Code: 2303, buy success, cash: 29826.50, holding value:9990.00
-[2023-05-09 13:55:26,652] Code: 2303, buy success, cash: 28716.50, holding value:11100.00
-[2023-05-09 13:55:26,656] Code: 2303, buy success, cash: 27591.50, holding value:12375.00
-[2023-05-09 13:55:26,657] Code: 2303, buy success, cash: 26446.50, holding value:13740.00
-[2023-05-09 13:55:26,659] Code: 2303, sell success, cash: 27616.50, holding value:12870.00
-[2023-05-09 13:55:26,660] Code: 2303, sell success, cash: 28786.50, holding value:11700.00
-[2023-05-09 13:55:26,661] Code: 2303, buy success, cash: 27511.50, holding value:14025.00
-[2023-05-09 13:55:26,662] Code: 2303, sell success, cash: 28796.50, holding value:12850.00
-[2023-05-09 13:55:26,664] Code: 2303, hold success, cash: 28796.50, holding value:12750.00
-[2023-05-09 13:55:26,665] Code: 2303, sell success, cash: 30086.50, holding value:11610.00
-[2023-05-09 13:55:26,670] Code: 2303, sell success, cash: 31396.50, holding value:10480.00
-[2023-05-09 13:55:26,672] Code: 2303, buy success, cash: 30106.50, holding value:11610.00
-[2023-05-09 13:55:26,674] Code: 2303, hold success, cash: 30106.50, holding value:11880.00
-[2023-05-09 13:55:26,675] Code: 2303, hold success, cash: 30106.50, holding value:11835.00
-[2023-05-09 13:55:26,676] Code: 2303, buy success, cash: 28781.50, holding value:13250.00
-[2023-05-09 13:55:26,678] Code: 2303, buy success, cash: 27441.50, holding value:14740.00
-[2023-05-09 13:55:26,734] Code: 2303, hold success, cash: 27441.50, holding value:14520.00
-[2023-05-09 13:55:26,765] Code: 2303, sell success, cash: 28761.50, holding value:13200.00
-[2023-05-09 13:55:26,773] Code: 2303, sell success, cash: 30081.50, holding value:11880.00
-[2023-05-09 13:55:26,774] Code: 2303, sell success, cash: 31401.50, holding value:10560.00
-[2023-05-09 13:55:26,776] Code: 2303, buy success, cash: 30076.50, holding value:11925.00
-[2023-05-09 13:55:26,777] Code: 2303, sell success, cash: 31411.50, holding value:10680.00
-[2023-05-09 13:55:26,779] Code: 2303, hold success, cash: 31411.50, holding value:10720.00
-[2023-05-09 13:55:26,780] Code: 2303, hold success, cash: 31411.50, holding value:10680.00
-[2023-05-09 13:55:26,782] Code: 2303, sell success, cash: 32756.50, holding value:9415.00
-[2023-05-09 13:55:26,789] Code: 2303, sell success, cash: 34096.50, holding value:8040.00
-[2023-05-09 13:55:26,791] Code: 2303, hold success, cash: 34096.50, holding value:8040.00
-[2023-05-09 13:55:26,792] Code: 2303, sell success, cash: 35416.50, holding value:6600.00
-[2023-05-09 13:55:26,793] Code: 2303, sell success, cash: 36706.50, holding value:5160.00
-[2023-05-09 13:55:26,795] Code: 2303, sell success, cash: 38021.50, holding value:3945.00
-[2023-05-09 13:55:26,797] Code: 2303, sell success, cash: 39346.50, holding value:2650.00
-[2023-05-09 13:55:26,799] Code: 2303, sell success, cash: 40686.50, holding value:1340.00
-[2023-05-09 13:55:26,802] Code: 2303, buy success, cash: 39361.50, holding value:2650.00
-[2023-05-09 13:55:26,843] Code: 2303, buy success, cash: 38036.50, holding value:3975.00
-[2023-05-09 13:55:26,854] Code: 2303, hold success, cash: 38036.50, holding value:3990.00
-[2023-05-09 13:55:26,860] Code: 2303, sell success, cash: 39366.50, holding value:2660.00
-[2023-05-09 13:55:26,862] Code: 2303, buy success, cash: 38031.50, holding value:4005.00
-[2023-05-09 13:55:26,868] Code: 2303, sell success, cash: 39361.50, holding value:2660.00
-[2023-05-09 13:55:26,871] Code: 2303, hold success, cash: 39361.50, holding value:2640.00
-[2023-05-09 13:55:26,878] Code: 2303, sell success, cash: 40686.50, holding value:1325.00
-[2023-05-09 13:55:26,881] Code: 2303, hold success, cash: 40686.50, holding value:1310.00
-[2023-05-09 13:55:26,883] Code: 2303, buy success, cash: 39376.50, holding value:2620.00
-[2023-05-09 13:55:26,884] Code: 2303, buy success, cash: 38086.50, holding value:3870.00
-[2023-05-09 13:55:26,894] Code: 2303, sell success, cash: 39411.50, holding value:2650.00
-[2023-05-09 13:55:26,897] Code: 2303, buy success, cash: 38081.50, holding value:3990.00
-[2023-05-09 13:55:26,899] Code: 2303, sell success, cash: 39396.50, holding value:2630.00
-[2023-05-09 13:55:26,900] Code: 2303, hold success, cash: 39396.50, holding value:2550.00
-[2023-05-09 13:55:26,902] Code: 2303, hold success, cash: 39396.50, holding value:2520.00
-[2023-05-09 13:55:26,914] Code: 2303, sell success, cash: 40671.50, holding value:1275.00
-[2023-05-09 13:55:26,932] Code: 2303, hold success, cash: 40671.50, holding value:1260.00
-[2023-05-09 13:55:26,942] Code: 2303, sell success, cash: 41961.50, holding value:0.00
-[2023-05-09 13:55:26,956] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:26,957] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:26,959] Code: 2303, buy success, cash: 40676.50, holding value:1285.00
-[2023-05-09 13:55:26,961] Code: 2303, sell success, cash: 41966.50, holding value:0.00
-[2023-05-09 13:55:26,963] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:26,964] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:26,966] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:26,982] Code: 2303, buy success, cash: 40696.50, holding value:1270.00
-[2023-05-09 13:55:26,988] Code: 2303, hold success, cash: 40696.50, holding value:1270.00
-[2023-05-09 13:55:26,990] Code: 2303, sell success, cash: 41966.50, holding value:0.00
-[2023-05-09 13:55:26,994] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:26,997] Code: 2303, not exists in Positions, sell failed.
-[2023-05-09 13:55:26,998] Code: 2303, not exists in Positions, hold failed.
-[2023-05-09 13:55:26,999] Code: 2303, buy success, cash: 40801.50, holding value:1165.00
-[2023-05-09 13:55:27,005] Code: 2303, buy success, cash: 39656.50, holding value:2290.00
-[2023-05-09 13:55:27,008] Code: 2303, buy success, cash: 38526.50, holding value:3390.00
-[2023-05-09 13:55:27,009] Code: 2303, buy success, cash: 37396.50, holding value:4520.00
-[2023-05-09 13:55:27,010] Code: 2303, buy success, cash: 36271.50, holding value:5625.00
-[2023-05-09 13:55:27,013] Code: 2303, buy success, cash: 35146.50, holding value:6750.00
-[2023-05-09 13:55:27,014] Code: 2303, hold success, cash: 35146.50, holding value:6750.00
-[2023-05-09 13:55:27,016] Code: 2303, sell success, cash: 36286.50, holding value:5700.00
-[2023-05-09 13:55:27,018] Code: 2303, buy success, cash: 35156.50, holding value:6780.00
-[2023-05-09 13:55:27,023] Code: 2303, sell success, cash: 36301.50, holding value:5725.00
-[2023-05-09 13:55:27,024] Code: 2303, hold success, cash: 36301.50, holding value:5775.00
-[2023-05-09 13:55:27,027] Code: 2303, hold success, cash: 36301.50, holding value:5775.00
-[2023-05-09 13:55:27,028] Code: 2303, sell success, cash: 37451.50, holding value:4600.00
-[2023-05-09 13:55:27,030] Code: 2303, buy success, cash: 36296.50, holding value:5775.00
-[2023-05-09 13:55:27,031] Code: 2303, hold success, cash: 36296.50, holding value:5900.00
-[2023-05-09 13:55:27,032] Code: 2303, hold success, cash: 36296.50, holding value:5900.00
-[2023-05-09 13:55:27,036] Code: 2303, hold success, cash: 36296.50, holding value:6000.00
-[2023-05-09 13:55:27,038] Code: 2303, buy success, cash: 35086.50, holding value:7260.00
-[2023-05-09 13:55:27,040] Code: 2303, buy success, cash: 33871.50, holding value:8505.00
-[2023-05-09 13:55:27,041] Code: 2303, sell success, cash: 35091.50, holding value:7320.00
-[2023-05-09 13:55:27,043] Code: 2303, buy success, cash: 33871.50, holding value:8540.00
-[2023-05-09 13:55:27,045] Code: 2303, sell success, cash: 35096.50, holding value:7350.00
-[2023-05-09 13:55:27,047] Code: 2303, buy success, cash: 33871.50, holding value:8575.00
-[2023-05-09 13:55:27,048] Code: 2303, hold success, cash: 33871.50, holding value:8680.00
-[2023-05-09 13:55:27,049] Code: 2303, hold success, cash: 33871.50, holding value:8645.00
-[2023-05-09 13:55:27,050] Code: 2303, hold success, cash: 33871.50, holding value:8680.00
-[2023-05-09 13:55:27,057] Code: 2303, buy success, cash: 32626.50, holding value:9960.00
-[2023-05-09 13:55:27,059] Code: 2303, buy success, cash: 31386.50, holding value:11160.00
-[2023-05-09 13:55:27,061] Code: 2303, hold success, cash: 31386.50, holding value:10980.00
-[2023-05-09 13:55:27,062] Code: 2303, sell success, cash: 32596.50, holding value:9680.00
-[2023-05-09 13:55:27,063] Code: 2303, buy success, cash: 31371.50, holding value:11025.00
-[2023-05-09 13:55:27,065] Code: 2303, sell success, cash: 32571.50, holding value:9600.00
-[2023-05-09 13:55:27,067] Code: 2303, hold success, cash: 32571.50, holding value:9720.00
-[2023-05-09 13:55:27,070] Code: 2303, hold success, cash: 32571.50, holding value:9960.00
-[2023-05-09 13:55:27,071] Code: 2303, sell success, cash: 33796.50, holding value:8575.00
-[2023-05-09 13:55:27,074] Code: 2303, sell success, cash: 35041.50, holding value:7470.00
-[2023-05-09 13:55:27,075] Code: 2303, sell success, cash: 36296.50, holding value:6275.00
-[2023-05-09 13:55:27,077] Code: 2303, sell success, cash: 37496.50, holding value:4800.00
-[2023-05-09 13:55:27,078] Code: 2303, hold success, cash: 37496.50, holding value:4980.00
-[2023-05-09 13:55:27,080] Code: 2303, hold success, cash: 37496.50, holding value:4920.00
-[2023-05-09 13:55:27,081] Code: 2303, buy success, cash: 36241.50, holding value:6275.00
-[2023-05-09 13:55:27,083] Code: 2303, sell success, cash: 37501.50, holding value:5040.00
-[2023-05-09 13:55:27,085] Code: 2303, hold success, cash: 37501.50, holding value:5020.00
-[2023-05-09 13:55:27,087] Code: 2303, sell success, cash: 38766.50, holding value:3795.00
-[2023-05-09 13:55:27,091] Code: 2303, buy success, cash: 37506.50, holding value:5040.00
-[2023-05-09 13:55:27,092] Code: 2303, hold success, cash: 37506.50, holding value:4940.00
-[2023-05-09 13:55:27,094] Code: 2303, hold success, cash: 37506.50, holding value:4960.00
-[2023-05-09 13:55:27,096] Code: 2303, buy success, cash: 36211.50, holding value:6475.00
-[2023-05-09 13:55:27,097] Code: 2303, buy success, cash: 34966.50, holding value:7470.00
-[2023-05-09 13:55:27,098] Code: 2303, buy success, cash: 33716.50, holding value:8750.00
-[2023-05-09 13:55:27,100] Code: 2303, sell success, cash: 34966.50, holding value:7500.00
-[2023-05-09 13:55:27,102] Code: 2303, buy success, cash: 33731.50, holding value:8645.00
-[2023-05-09 13:55:27,106] Code: 2303, hold success, cash: 33731.50, holding value:8750.00
-[2023-05-09 13:55:27,108] Code: 2303, sell success, cash: 34976.50, holding value:7470.00
-[2023-05-09 13:55:27,109] Code: 2303, buy success, cash: 33741.50, holding value:8645.00
-[2023-05-09 13:55:27,111] Code: 2303, hold success, cash: 33741.50, holding value:8750.00
-[2023-05-09 13:55:27,112] Code: 2303, hold success, cash: 33741.50, holding value:8610.00
-[2023-05-09 13:55:27,114] Code: 2303, sell success, cash: 34971.50, holding value:7380.00
-[2023-05-09 13:55:27,115] Code: 2303, buy success, cash: 33731.50, holding value:8680.00
diff --git a/logs/Random_policy-20230509150036-stock_market.log b/logs/Random_policy-20230509150036-stock_market.log
deleted file mode 100644
index e69de29..0000000
diff --git a/logs/forex-v0/gpt/azure/args.json b/logs/forex-v0/gpt/azure/args.json
deleted file mode 100644
index fa1989c..0000000
--- a/logs/forex-v0/gpt/azure/args.json
+++ /dev/null
@@ -1,65 +0,0 @@
-{
-    "N": 20,
-    "action_weight": 5,
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoNoaUUpQu"
-    },
-    "attn_pdrop": 0.1,
-    "batch_size": 256,
-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-    "config": "config.offline",
-    "dataset": "forex-v0",
-    "device": "cuda",
-    "discount": 0.99,
-    "discretizer": "QuantileDiscretizer",
-    "embd_pdrop": 0.1,
-    "exp_name": "gpt/azure",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoMYaUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoE4aUUpQu"
-    },
-    "learning_rate": 0.0006,
-    "logbase": "logs/",
-    "lr_decay": true,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoLIaUUpQu"
-    },
-    "n_embd": 32,
-    "n_epochs_ref": 50,
-    "n_head": 4,
-    "n_layer": 4,
-    "n_saves": 3,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoHoaUUpQu"
-    },
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-        "time": "Sat May 13 23:04:00 2023"
-    },
-    "resid_pdrop": 0.1,
-    "reward_weight": 1,
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoOYaUUpQu"
-    },
-    "savepath": "logs/forex-v0/gpt/azure",
-    "seed": 42,
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVGQMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCGRpc2NvdW50lEc/764UeuFHrowGbl9oZWFklEsEjAduX3NhdmVzlEsDjAx2YWx1ZV93ZWlnaHSUSwGMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwHbl9sYXllcpRLBIwHZGF0YXNldJSMCGZvcmV4LXYwlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMCmdldF9jb21taXSUaAJoBmgThpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBHN0ZXCUSwGMCHNhdmVwYXRolIwXbG9ncy9mb3JleC12MC9ncHQvYXp1cmWUjAZjb21taXSUjC0yMDVmNmI2MWVjZWE2MmE4OTliZDQ5NGZhYWIxNDU5YTYyZWE1NTI1IG1haW6UjAZkZXZpY2WUjARjdWRhlIwLcmVhZF9jb25maWeUaAJoBmgehpRSlIwKYXR0bl9wZHJvcJRHP7mZmZmZmZqME3Rlcm1pbmF0aW9uX3BlbmFsdHmUSpz///+MDXJld2FyZF93ZWlnaHSUSwGMBHNlZWSUSyqMDG5fZXBvY2hzX3JlZpRLMowLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhleHBfbmFtZZSMCWdwdC9henVyZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMCGxyX2RlY2F5lIiMBW1rZGlylGgCaAZoLIaUUpSMCmJhdGNoX3NpemWUTQABjAFOlEsUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaDGGlFKUjAZuX2VtYmSUSyCMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAphZGRfZXh0cmFzlGgCaAZoNoaUUpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjAtkaXNjcmV0aXplcpSME1F1YW50aWxlRGlzY3JldGl6ZXKUjAhzZXRfc2VlZJRoAmgGaD6GlFKUdWJoPoaUUpQu"
-    },
-    "step": 1,
-    "subsampled_sequence_length": 10,
-    "termination_penalty": -100,
-    "value_weight": 1
-}
\ No newline at end of file
diff --git a/logs/forex-v0/gpt/azure/data_config.pkl b/logs/forex-v0/gpt/azure/data_config.pkl
deleted file mode 100644
index 19e5dfe..0000000
Binary files a/logs/forex-v0/gpt/azure/data_config.pkl and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/diff.txt b/logs/forex-v0/gpt/azure/diff.txt
deleted file mode 100644
index fd45683..0000000
--- a/logs/forex-v0/gpt/azure/diff.txt
+++ /dev/null
@@ -1,165 +0,0 @@
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 1dd7eb6..98c4875 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -17,7 +17,7 @@ args_to_watch = [
- base = {
- 
-     'train': {
--        'N': 100,
-+        'N': 20,
-         'discount': 0.99,
-         'n_layer': 4,
-         'n_head': 4,
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index 881688c..335869f 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -3,6 +3,7 @@ import pdb
- from os.path import join
- import gym
- import gym_anytrading
-+import numpy as np
- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
- import trajectory.utils as utils
-@@ -90,7 +91,7 @@ for t in range(T):
-     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
- 
-     ## execute action in environment
--    next_observation, reward, terminal, _ = env.step(action)
-+    next_observation, reward, terminal, _ = env.step(np.argmax(action))
- 
-     ## update return
-     total_reward += reward
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index ddcda7a..913d790 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -2,11 +2,17 @@ import os
- import numpy as np
- import torch
- import pdb
-+import sys
-+
-+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
-+sys.path.insert(0, parent_dir)
- 
- import trajectory.utils as utils
- import trajectory.datasets as datasets
- from trajectory.models.transformers import GPT
- 
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
-     dataset: str = 'forex-v0'
-@@ -31,7 +37,7 @@ dataset_config = utils.Config(
-     savepath=(args.savepath, 'data_config.pkl'),
-     env=args.dataset,
-     N=args.N,
--    penalty=args.termination_penalty,
-+    penalty=None,
-     sequence_length=sequence_length,
-     step=args.step,
-     discount=args.discount,
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
-deleted file mode 100644
-index fa97c75..0000000
-Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index 71bfb7e..bbd08e4 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
- action_dim = env.action_space.n
- 
- episode = 10
--
-+T = 0
- episode_data = {}
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = []
-@@ -25,13 +25,12 @@ for _ in range(episode):
-         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
-         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
-         episode_data['actions'].append(action)
--        episode_data['rewards'].append(np.array(reward).astype('float32'))
-+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
-         episode_data['terminals'].append(done)
-         if done:
-             break
- 
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = np.stack(episode_data[k])
--
--with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
-+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
-     pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
-index 69ee58d..d1062c5 100644
---- a/Trajectory_Transformer/trajectory/datasets/__init__.py
-+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
-@@ -1,3 +1,3 @@
--from .d4rl import load_environment
-+#from .d4rl import load_environment
- from .sequence import *
- from .preprocessing import get_preprocess_fn
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index c23b4f3..4525194 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
-         self.device = device
-         
-         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
--        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
-+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
-             dataset = pickle.load(f)
-         print('✓')
- 
-@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
-         terminals = dataset['terminals']
-         realterminals = [False]*len(dataset['terminals'])
- 
--        #observations = np.reshape(observations, (100, 7000))
-         self.observations_raw = observations
-         self.actions_raw = actions
-         self.next_observations_raw = next_observations
-diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
-index 7c596c3..7529384 100644
---- a/Trajectory_Transformer/trajectory/utils/__init__.py
-+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
-@@ -2,7 +2,7 @@ from .setup import Parser, watch
- from .arrays import *
- from .serialization import *
- from .progress import Progress, Silent
--from .rendering import make_renderer
-+#from .rendering import make_renderer
- # from .video import *
- from .config import Config
- from .training import Trainer
-diff --git a/requirements.txt b/requirements.txt
-index ece16ed..a579177 100644
---- a/requirements.txt
-+++ b/requirements.txt
-@@ -1,14 +1,16 @@
- numpy
- gym
- numpy
--torch
-+pytorch==1.12.1
-+torchvision==0.13.1 
-+torchaudio==0.12.1
- transformers==4.5.1
- wandb==0.9.1
- tensorboard
- pyprind
- tensorflow
- gin-config
--gym
-+gym==0.21.0
- tqdm
- blosc
- git+https://github.com/google/dopamine.git
\ No newline at end of file
diff --git a/logs/forex-v0/gpt/azure/model_config.pkl b/logs/forex-v0/gpt/azure/model_config.pkl
deleted file mode 100644
index db868c9..0000000
Binary files a/logs/forex-v0/gpt/azure/model_config.pkl and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/state_0.pt b/logs/forex-v0/gpt/azure/state_0.pt
deleted file mode 100644
index 15f43e4..0000000
Binary files a/logs/forex-v0/gpt/azure/state_0.pt and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/state_166.pt b/logs/forex-v0/gpt/azure/state_166.pt
deleted file mode 100644
index e4313e6..0000000
Binary files a/logs/forex-v0/gpt/azure/state_166.pt and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/state_332.pt b/logs/forex-v0/gpt/azure/state_332.pt
deleted file mode 100644
index 19b2a25..0000000
Binary files a/logs/forex-v0/gpt/azure/state_332.pt and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/state_498.pt b/logs/forex-v0/gpt/azure/state_498.pt
deleted file mode 100644
index 7947174..0000000
Binary files a/logs/forex-v0/gpt/azure/state_498.pt and /dev/null differ
diff --git a/logs/forex-v0/gpt/azure/trainer_config.pkl b/logs/forex-v0/gpt/azure/trainer_config.pkl
deleted file mode 100644
index cb42344..0000000
Binary files a/logs/forex-v0/gpt/azure/trainer_config.pkl and /dev/null differ
diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
deleted file mode 100644
index 0e84897..0000000
--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-    "config": "config.offline",
-    "dataset": "forex-v0",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H15_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 15,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-        "time": "Tue May 16 00:22:08 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-    },
-    "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
deleted file mode 100644
index c30ee70..0000000
--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
+++ /dev/null
@@ -1,71 +0,0 @@
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
\ No newline at end of file
diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/rollout.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/rollout.json
deleted file mode 100644
index da1f841..0000000
--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/rollout.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-  "gpt_epoch": 498,
-  "return": 104.49999999999403,
-  "step": 48,
-  "term": true
-}
\ No newline at end of file
diff --git a/logs/stock_2330/gpt/azure/args.json b/logs/stock_2330/gpt/azure/args.json
deleted file mode 100644
index b46697b..0000000
--- a/logs/stock_2330/gpt/azure/args.json
+++ /dev/null
@@ -1,65 +0,0 @@
-{
-    "N": 20,
-    "action_weight": 5,
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoEYaUUpQu"
-    },
-    "attn_pdrop": 0.1,
-    "batch_size": 64,
-    "commit": "4bd920d3f1555913907e37871fa2384aec68e214 main",
-    "config": "config.offline",
-    "dataset": "stock_2330",
-    "device": "cuda",
-    "discount": 0.99,
-    "discretizer": "QuantileDiscretizer",
-    "embd_pdrop": 0.1,
-    "exp_name": "gpt/azure",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoHIaUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoJoaUUpQu"
-    },
-    "learning_rate": 0.0006,
-    "logbase": "logs/",
-    "lr_decay": true,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoDoaUUpQu"
-    },
-    "n_embd": 32,
-    "n_epochs_ref": 50,
-    "n_head": 4,
-    "n_layer": 4,
-    "n_saves": 3,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoI4aUUpQu"
-    },
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/4bd920d3f1555913907e37871fa2384aec68e214",
-        "time": "Tue May 23 21:54:57 2023"
-    },
-    "resid_pdrop": 0.1,
-    "reward_weight": 1,
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoOYaUUpQu"
-    },
-    "savepath": "logs/stock_2330/gpt/azure",
-    "seed": 42,
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoKYaUUpQu"
-    },
-    "step": 1,
-    "subsampled_sequence_length": 10,
-    "termination_penalty": -100,
-    "value_weight": 1
-}
\ No newline at end of file
diff --git a/logs/stock_2330/gpt/azure/data_config.pkl b/logs/stock_2330/gpt/azure/data_config.pkl
deleted file mode 100644
index cac53e8..0000000
Binary files a/logs/stock_2330/gpt/azure/data_config.pkl and /dev/null differ
diff --git a/logs/stock_2330/gpt/azure/diff.txt b/logs/stock_2330/gpt/azure/diff.txt
deleted file mode 100644
index 74dbf40..0000000
--- a/logs/stock_2330/gpt/azure/diff.txt
+++ /dev/null
@@ -1,1309 +0,0 @@
-diff --git a/PG_test.py b/PG_test.py
-index 1b9f5f9..8335923 100644
---- a/PG_test.py
-+++ b/PG_test.py
-@@ -33,7 +33,7 @@ class Policy(nn.Module):
-         # Extract the dimensionality of state and action spaces
-         self.discrete = isinstance(env.action_space, gym.spaces.Discrete)     
-         self.action_dim = env.action_space.n if self.discrete else env.action_space.shape[0]
--        self.hidden_size = 4096
-+        self.hidden_size = 500
-         self.double()
- 
-         self.observation_dim = 1
-@@ -86,7 +86,11 @@ class Policy(nn.Module):
-         """
-         
-         ########## YOUR CODE HERE (3~5 lines) ##########
--        state = torch.Tensor(state)
-+        tempstate = state.reshape(-1)
-+        for i in range(12):
-+            for j in range(4):
-+                tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-+        state = torch.Tensor(tempstate)
-         state = state.cuda()
-         action, state_value= self.forward(state)
-         m = Categorical(logits=action)
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index bd75e78..3c3bb2b 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
-         self.device = device
-         
-         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
--        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
-+        with open('Trajectory_Transformer/trajectory/datasets/Medium/'+env+'.pkl', 'rb') as f:
-             dataset = pickle.load(f)
-         print('✓')
- 
-diff --git a/decision-transformer/gym/conda_env.yml b/decision-transformer/gym/conda_env.yml
-index 655ea94..333b26c 100644
---- a/decision-transformer/gym/conda_env.yml
-+++ b/decision-transformer/gym/conda_env.yml
-@@ -9,7 +9,6 @@ dependencies:
- - pip
- - pip:
-   - gym==0.18.3
--  - mujoco-py==2.0.2.13
-   - numpy==1.20.3
-   - torch==1.8.1
-   - transformers==4.5.1
-diff --git a/decision-transformer/gym/data/stock_random_2330.pkl b/decision-transformer/gym/data/stock_random_2330.pkl
-deleted file mode 100644
-index 460a4f1..0000000
-Binary files a/decision-transformer/gym/data/stock_random_2330.pkl and /dev/null differ
-diff --git a/decision-transformer/gym/experiment.py b/decision-transformer/gym/experiment.py
-index a2e6006..ccafaa5 100644
---- a/decision-transformer/gym/experiment.py
-+++ b/decision-transformer/gym/experiment.py
-@@ -36,17 +36,17 @@ def experiment(
-     exp_prefix = f'{group_name}-{random.randint(int(1e5), int(1e6) - 1)}'
- 
-     if env_name == 'hopper':
--        env = gym.make('Hopper-v3')
-+        #env = gym.make('Hopper-v3')
-         max_ep_len = 1000
-         env_targets = [3600, 1800]  # evaluation conditioning targets
-         scale = 1000.  # normalization for rewards/returns
-     elif env_name == 'halfcheetah':
--        env = gym.make('HalfCheetah-v3')
-+        #env = gym.make('HalfCheetah-v3')
-         max_ep_len = 1000
-         env_targets = [12000, 6000]
-         scale = 1000.
-     elif env_name == 'walker2d':
--        env = gym.make('Walker2d-v3')
-+        #env = gym.make('Walker2d-v3')
-         max_ep_len = 1000
-         env_targets = [5000, 2500]
-         scale = 1000.
-@@ -67,11 +67,11 @@ def experiment(
-     if model_type == 'bc':
-         env_targets = env_targets[:1]  # since BC ignores target, no need for different evaluations
- 
--    state_dim = env.observation_space.shape[0]
--    act_dim = env.action_space.shape[0]
-+    state_dim = env.reset().reshape(-1).shape[0]
-+    act_dim = env.action_space.n
- 
-     # load dataset
--    dataset_path = f'data/{env_name}-{dataset}-v2.pkl'
-+    dataset_path = f'data/{env_name}-{dataset}.pkl'
-     with open(dataset_path, 'rb') as f:
-         trajectories = pickle.load(f)
- 
-@@ -287,8 +287,8 @@ def experiment(
- 
- if __name__ == '__main__':
-     parser = argparse.ArgumentParser()
--    parser.add_argument('--env', type=str, default='hopper')
--    parser.add_argument('--dataset', type=str, default='medium')  # medium, medium-replay, medium-expert, expert
-+    parser.add_argument('--env', type=str, default='stock')
-+    parser.add_argument('--dataset', type=str, default='random-2330')  # medium, medium-replay, medium-expert, expert
-     parser.add_argument('--mode', type=str, default='normal')  # normal for standard setting, delayed for sparse
-     parser.add_argument('--K', type=int, default=20)
-     parser.add_argument('--pct_traj', type=float, default=1.)
-diff --git a/logs/stock_2330/gpt/azure/args.json b/logs/stock_2330/gpt/azure/args.json
-index c13bf1c..b46697b 100644
---- a/logs/stock_2330/gpt/azure/args.json
-+++ b/logs/stock_2330/gpt/azure/args.json
-@@ -3,11 +3,11 @@
-     "action_weight": 5,
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoC4aUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoEYaUUpQu"
-     },
-     "attn_pdrop": 0.1,
-     "batch_size": 64,
--    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-+    "commit": "4bd920d3f1555913907e37871fa2384aec68e214 main",
-     "config": "config.offline",
-     "dataset": "stock_2330",
-     "device": "cuda",
-@@ -17,18 +17,18 @@
-     "exp_name": "gpt/azure",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoDoaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoHIaUUpQu"
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoMYaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoJoaUUpQu"
-     },
-     "learning_rate": 0.0006,
-     "logbase": "logs/",
-     "lr_decay": true,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoLIaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoDoaUUpQu"
-     },
-     "n_embd": 32,
-     "n_epochs_ref": 50,
-@@ -37,26 +37,26 @@
-     "n_saves": 3,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoOYaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoI4aUUpQu"
-     },
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
--        "time": "Tue May 16 18:48:00 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/4bd920d3f1555913907e37871fa2384aec68e214",
-+        "time": "Tue May 23 21:54:57 2023"
-     },
-     "resid_pdrop": 0.1,
-     "reward_weight": 1,
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoGoaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoOYaUUpQu"
-     },
-     "savepath": "logs/stock_2330/gpt/azure",
-     "seed": 42,
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoIYaUUpQu"
-+        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMC3Jlc2lkX3Bkcm9wlEc/uZmZmZmZmowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wHbG9nYmFzZZSMBWxvZ3MvlIwFbWtkaXKUaAJoBmgOhpRSlIwKYWRkX2V4dHJhc5RoAmgGaBGGlFKUjAx2YWx1ZV93ZWlnaHSUSwGMGnN1YnNhbXBsZWRfc2VxdWVuY2VfbGVuZ3RolEsKjAduX2xheWVylEsEjAxuX2Vwb2Noc19yZWaUSzKMCGxyX2RlY2F5lIiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwBTpRLFIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgchpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAhkaXNjb3VudJRHP++uFHrhR66MBHN0ZXCUSwGMC3JlYWRfY29uZmlnlGgCaAZoI4aUUpSMCmdldF9jb21taXSUaAJoBmgmhpRSlIwIc2V0X3NlZWSUaAJoBmgphpRSlIwKYmF0Y2hfc2l6ZZRLQIwGbl9oZWFklEsEjAZkZXZpY2WUjARjdWRhlIwKZW1iZF9wZHJvcJRHP7mZmZmZmZqMC2Rpc2NyZXRpemVylIwTUXVhbnRpbGVEaXNjcmV0aXplcpSMCmF0dG5fcGRyb3CURz+5mZmZmZmajAduX3NhdmVzlEsDjAhleHBfbmFtZZSMCWdwdC9henVyZZSMBmNvbW1pdJSMLTRiZDkyMGQzZjE1NTU5MTM5MDdlMzc4NzFmYTIzODRhZWM2OGUyMTQgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaDmGlFKUjA1hY3Rpb25fd2VpZ2h0lEsFjA1sZWFybmluZ19yYXRllEc/Q6kqMFUyYYwNcmV3YXJkX3dlaWdodJRLAYwGbl9lbWJklEsgjARzZWVklEsqdWJoKYaUUpQu"
-     },
-     "step": 1,
-     "subsampled_sequence_length": 10,
-diff --git a/logs/stock_2330/gpt/azure/diff.txt b/logs/stock_2330/gpt/azure/diff.txt
-index c8fb551..2f1a49a 100644
---- a/logs/stock_2330/gpt/azure/diff.txt
-+++ b/logs/stock_2330/gpt/azure/diff.txt
-@@ -1,978 +1,178 @@
--diff --git a/DDPG.py b/DDPG.py
--index d682b97..c69f550 100644
----- a/DDPG.py
--+++ b/DDPG.py
--@@ -1,6 +1,3 @@
---from env.market import Market
---from helper.args_parser import model_launcher_parser
---from helper.data_logger import generate_algorithm_logger, generate_market_logger
-- import sys
-- import gym
-- import numpy as np
--@@ -15,12 +12,15 @@ from torch.autograd import Variable
-- import torch.optim.lr_scheduler as Scheduler
-- import torch.nn.functional as F
-- from torch.utils.tensorboard import SummaryWriter
--+from buildEnv import createEnv, MyStocksEnv
--+from torch.distributions import Categorical
-- import logging
-- #from skopt.space import Real, Integer
-- #from skopt import gp_minimize
-- logging.basicConfig(filename='train.log', level=logging.DEBUG)
-- 
---
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- def soft_update(target, source, tau):
--     for target_param, param in zip(target.parameters(), source.parameters()):
--         target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
--@@ -153,46 +153,16 @@ class DDPG(object):
--         hard_update(self.actor_target, self.actor) 
--         hard_update(self.critic_target, self.critic)
-- 
---    def get_stock_code_and_action(self, a, use_greedy=False, use_prob=False):
---        # Reshape a.
---        if not use_greedy:
---            a = a.reshape((-1,))
---            # Calculate action index depends on prob.
---            if use_prob:
---                # Generate indices.
---                a_indices = np.arange(a.shape[0])
---                # Get action index.
---                action_index = np.random.choice(a_indices, p=a)
---            else:
---                # Get action index.
---                action_index = np.argmax(a)
---        else:
---            if use_prob:
---                # Calculate action index
---                if np.random.uniform() < self.epsilon:
---                    action_index = np.floor(a).astype(int)
---                else:
---                    action_index = np.random.randint(0, self.action_space)
---            else:
---                # Calculate action index
---                action_index = np.floor(a).astype(int)
---
---        # Get action
---        action = action_index % 3
---        # Get stock index
---        stock_index = np.floor(action_index / 3).astype(np.int)
---        # Get stock code.
---        stock_code = self.env.codes[stock_index]
---
---        return stock_code, action, action_index
---
---    def select_action(self, state, action_noise=None):
--+
--+    def select_action(self, state, epsilon=0.0):
--         self.actor.eval()
---        mu = self.actor((Variable(state)))
---        mu = mu.data
---        noise = [0.0] if action_noise is None else action_noise.noise()
---        noise = torch.FloatTensor(noise)
---        return torch.clamp(mu + noise, min=0, max=1.0)
--+        probs = self.actor((Variable(state)))
--+        probs = probs.detach()
--+        m = Categorical(logits= probs)
--+        action = m.sample().item()
--+        if random.random() > epsilon:
--+            return self.env.action_space.sample()
--+        return action
-- 
--     def update_parameters(self, batch):
--         state_batch = Variable(torch.cat([b.state for b in batch]))
--@@ -201,7 +171,6 @@ class DDPG(object):
--         mask_batch = Variable(torch.cat([b.mask for b in batch]))
--         next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
--         
---        ########## YOUR CODE HERE (10~20 lines) ##########
--         # Calculate policy loss and value loss
--         # Update the actor and the critic
--         q_v = self.critic(state_batch, action_batch)
--@@ -219,7 +188,6 @@ class DDPG(object):
--         self.actor_optim.zero_grad()
--         policy_loss.backward()
--         self.actor_optim.step()
---        ########## END OF YOUR CODE ########## 
-- 
--         soft_update(self.actor_target, self.actor, self.tau)
--         soft_update(self.critic_target, self.critic, self.tau)
--@@ -248,9 +216,9 @@ class DDPG(object):
--         if critic_path is not None: 
--             self.critic.load_state_dict(torch.load(critic_path))
-- 
---def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
--+def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
--     # Define a tensorboard writer
---    writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
--+    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-- 
--     logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
--         lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
--@@ -276,9 +244,8 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--     total_numsteps = 0
--     updates = 0
-- 
---    
---    agent = DDPG(num_inputs = env.data_dim,
---                 action_space = env.trader.action_space, 
--+    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
--+                 action_space = env.action_space.n, 
--                  env = env, 
--                  epsilon= epsilon,
--                  gamma = gamma, 
--@@ -288,15 +255,15 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--                 lr_c= lr_c, 
--                 lr_a_decay= lr_a_decay, 
--                 lr_c_decay = lr_c_decay)
---    ounoise = OUNoise(env.trader.action_space)
--+    #ounoise = OUNoise(env.action_space)
--     memory = ReplayMemory(replay_size)
--     
--     for i_episode in range(num_episodes):
--         
---        ounoise.scale = noise_scale
---        ounoise.reset()
--+        #ounoise.scale = noise_scale
--+        #ounoise.reset()
--         
---        state = torch.Tensor([env.reset()])
--+        state = torch.Tensor([env.reset().reshape(-1)])
-- 
--         episode_reward = 0
--         val_loss = []
--@@ -308,10 +275,9 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--             # 2. Push the sample to the replay buffer
--             # 3. Update the actor and the critic
--             total_numsteps+=1
---            action = agent.select_action(state, ounoise)
---            code, action, a_index= agent.get_stock_code_and_action(action, use_greedy=False, use_prob=True)
---            next_state, reward, done, _ = env.forward(code, action)
---            next_state = torch.Tensor([next_state])
--+            action = agent.select_action(state, epsilon)
--+            next_state, reward, done, info = env.step(action)
--+            next_state = torch.Tensor([next_state.reshape(-1)])
--             memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
--             if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
--                 batch = memory.sample(batch_size)
--@@ -320,7 +286,7 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--                 act_loss.append(a_loss)
--             episode_reward += reward
--             state = next_state
---            if done == env.Done:
--+            if done:
--                 break
--             ########## END OF YOUR CODE ########## 
-+diff --git a/PG_test.py b/PG_test.py
-+index 1b9f5f9..8335923 100644
-+--- a/PG_test.py
-++++ b/PG_test.py
-+@@ -33,7 +33,7 @@ class Policy(nn.Module):
-+         # Extract the dimensionality of state and action spaces
-+         self.discrete = isinstance(env.action_space, gym.spaces.Discrete)     
-+         self.action_dim = env.action_space.n if self.discrete else env.action_space.shape[0]
-+-        self.hidden_size = 4096
-++        self.hidden_size = 500
-+         self.double()
-+ 
-+         self.observation_dim = 1
-+@@ -86,7 +86,11 @@ class Policy(nn.Module):
-+         """
-          
--@@ -330,23 +296,24 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--         critic_loss = np.mean(val_loss)
--         t = 0
--         
---        state = torch.Tensor([env.reset()])
--+        state = torch.Tensor([env.reset().reshape(-1)])
--         episode_reward = 0
--         while True:
--             action = agent.select_action(state)
-- 
---            next_state, reward, done, _ = env.step(action.numpy()[0])
--+            next_state, reward, done, info = env.step(action)
--             
--             #env.render()
--             
--             episode_reward += reward
-- 
---            next_state = torch.Tensor([next_state])
--+            next_state = torch.Tensor([next_state.reshape(-1)])
-- 
--             state = next_state
--             
--             t += 1
--             if done:
--+                print(info)
--                 break
-- 
--         rewards.append(episode_reward)
--@@ -358,36 +325,22 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
--             logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
-- 
--         #Logging
---        writer.add_scalar('Reward', episode_reward, i_episode)
---        writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
---        writer.add_scalar('Critic loss', critic_loss, i_episode)
---        writer.add_scalar('Actor loss', actor_loss, i_episode)
---
---        if ewma_reward >= 120:
---            agent.save_model(env_name, '.pth')
---            logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
---            #break
---            return (ewma_reward+500)/(i_episode+1) #For tuning
--+        #writer.add_scalar('Reward', episode_reward, i_episode)
--+        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
--+        #writer.add_scalar('Critic loss', critic_loss, i_episode)
--+        #writer.add_scalar('Actor loss', actor_loss, i_episode)
--+
--+        #if ewma_reward >= 120:
--+        #    agent.save_model(env_name, '.pth')
--+        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--+        #    #break
--+        #    return (ewma_reward+500)/(i_episode+1) #For tuning
--     
--     agent.save_model(env_name, '.pth')  
--     logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--     return (ewma_reward+500)/(i_episode+1) #For tuning
-- 
-- def main():
---    """
---    Market environment args 
---    """
---    #mode = args.mode
---    mode = 'test'
---    # codes = args.codes
---    codes = ["2303"]
---    # market = args.market
---    market = 'stock'
---    # episode = args.episode
---    episode = 1000
---    training_data_ratio = 0.95
---    # training_data_ratio = args.training_data_ratio
---
--     """
--     Training args
--     """
--@@ -398,14 +351,8 @@ def main():
--     noise_scale_ = 0.3
--     batch_size_ = 64
-- 
---    model_name = os.path.basename(__file__).split('.')[0]
-- 
---    env = Market(codes, start_date="2012-01-01", end_date="2018-01-01", **{
---        "market": market,
---        "mix_index_state": False,
---        "logger": generate_market_logger(model_name),
---        "training_data_ratio": training_data_ratio,
---    })
--+    env = createEnv(2330)
-- 
--     train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
-- if __name__ == '__main__':
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 9a7a974..73c5b28 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -57,7 +57,7 @@ base = {
--         'renderer': 'Renderer',
-- 
--         'plan_freq': 1,
---        'horizon': 15,
--+        'horizon': 10,
--         'beam_width': 128,
--         'n_expand': 2,
-- 
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index f06654a..8979c32 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -12,15 +12,19 @@ parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
-- sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
--+from trajectory.datasets.Random.buildEnv import createEnv
-- from trajectory.search import (
--     beam_plan,
--     make_prefix,
--     extract_actions,
--     update_context,
-- )
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '3'
-- 
--+code = '2330'
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stock_'+code
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -43,7 +47,8 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- ####### dataset #######
-- #######################
-- 
---env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
--+
--+env = createEnv(code)
-- #renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
--@@ -68,7 +73,7 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = 1000000
--+T = 1187
-- for t in range(T):
-- 
--     #observation = preprocess_fn(observation)
--@@ -105,11 +110,11 @@ for t in range(T):
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
---
--     print(
--         f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
--+    print(info, action)
-- 
--     ## visualization
--     #if t % args.vis_freq == 0 or terminal or t == T:
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 6ef5569..bb35461 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'stocks-v0_r'
--+    dataset: str = 'stock_2330'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 5000
--+n_epochs = 10000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 659bd84..122adaf 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -5,9 +5,12 @@ from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
-- import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
--+import os
--+import sys
--+from buildEnv import createEnv
-- 
---quat_type = "stocks-v0"
---env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = 2330
--+env = createEnv(2330)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
--@@ -20,11 +23,12 @@ for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals'
-- for _ in range(episode):
--     observation = env.reset()
--     while True:
---        action = np.random.rand(action_dim)
---        next_observation, reward, done, _ = env.step(np.argmax(action))
--+        probs = np.random.rand(action_dim)
--+        action = np.random.choice(2, p=probs/np.sum(probs))
--+        next_observation, reward, done, _ = env.step(action)
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
---        episode_data['actions'].append(action)
--+        episode_data['actions'].append(probs)
--         episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--@@ -32,5 +36,5 @@ for _ in range(episode):
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
-+         ########## YOUR CODE HERE (3~5 lines) ##########
-+-        state = torch.Tensor(state)
-++        tempstate = state.reshape(-1)
-++        for i in range(12):
-++            for j in range(4):
-++                tempstate[i*4+j] = (state[44+j] - state[i*4+j])/state[44+j]
-++        state = torch.Tensor(tempstate)
-+         state = state.cuda()
-+         action, state_value= self.forward(state)
-+         m = Categorical(logits=action)
- diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index 4525194..bd75e78 100644
-+index bd75e78..3c3bb2b 100644
- --- a/Trajectory_Transformer/trajectory/datasets/sequence.py
- +++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -44,7 +44,7 @@ def segment(observations, terminals, max_path_length):
-- 
-- class SequenceDataset(torch.utils.data.Dataset):
-+@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
-+         self.device = device
-+         
-+         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
-+-        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
-++        with open('Trajectory_Transformer/trajectory/datasets/Medium/'+env+'.pkl', 'rb') as f:
-+             dataset = pickle.load(f)
-+         print('✓')
-+ 
-+diff --git a/decision-transformer/gym/conda_env.yml b/decision-transformer/gym/conda_env.yml
-+index 655ea94..333b26c 100644
-+--- a/decision-transformer/gym/conda_env.yml
-++++ b/decision-transformer/gym/conda_env.yml
-+@@ -9,7 +9,6 @@ dependencies:
-+ - pip
-+ - pip:
-+   - gym==0.18.3
-+-  - mujoco-py==2.0.2.13
-+   - numpy==1.20.3
-+   - torch==1.8.1
-+   - transformers==4.5.1
-+diff --git a/decision-transformer/gym/data/stock_random_2330.pkl b/decision-transformer/gym/data/stock_random_2330.pkl
-+deleted file mode 100644
-+index 460a4f1..0000000
-+Binary files a/decision-transformer/gym/data/stock_random_2330.pkl and /dev/null differ
-+diff --git a/decision-transformer/gym/experiment.py b/decision-transformer/gym/experiment.py
-+index a2e6006..ccafaa5 100644
-+--- a/decision-transformer/gym/experiment.py
-++++ b/decision-transformer/gym/experiment.py
-+@@ -36,17 +36,17 @@ def experiment(
-+     exp_prefix = f'{group_name}-{random.randint(int(1e5), int(1e6) - 1)}'
-+ 
-+     if env_name == 'hopper':
-+-        env = gym.make('Hopper-v3')
-++        #env = gym.make('Hopper-v3')
-+         max_ep_len = 1000
-+         env_targets = [3600, 1800]  # evaluation conditioning targets
-+         scale = 1000.  # normalization for rewards/returns
-+     elif env_name == 'halfcheetah':
-+-        env = gym.make('HalfCheetah-v3')
-++        #env = gym.make('HalfCheetah-v3')
-+         max_ep_len = 1000
-+         env_targets = [12000, 6000]
-+         scale = 1000.
-+     elif env_name == 'walker2d':
-+-        env = gym.make('Walker2d-v3')
-++        #env = gym.make('Walker2d-v3')
-+         max_ep_len = 1000
-+         env_targets = [5000, 2500]
-+         scale = 1000.
-+@@ -67,11 +67,11 @@ def experiment(
-+     if model_type == 'bc':
-+         env_targets = env_targets[:1]  # since BC ignores target, no need for different evaluations
-+ 
-+-    state_dim = env.observation_space.shape[0]
-+-    act_dim = env.action_space.shape[0]
-++    state_dim = env.reset().reshape(-1).shape[0]
-++    act_dim = env.action_space.n
-+ 
-+     # load dataset
-+-    dataset_path = f'data/{env_name}-{dataset}-v2.pkl'
-++    dataset_path = f'data/{env_name}-{dataset}.pkl'
-+     with open(dataset_path, 'rb') as f:
-+         trajectories = pickle.load(f)
-+ 
-+@@ -287,8 +287,8 @@ def experiment(
-  
---    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=1000, penalty=None, device='cuda:0'):
--+    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=2000, penalty=None, device='cuda:0'):
--         print(f'[ datasets/sequence ] Sequence length: {sequence_length} | Step: {step} | Max path length: {max_path_length}')
--         #self.env = env = load_environment(env) if type(env) is str else env
--         self.sequence_length = sequence_length
--diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--index f42cef8..0e84897 100644
----- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--@@ -1,23 +1,23 @@
-- {
-+ if __name__ == '__main__':
-+     parser = argparse.ArgumentParser()
-+-    parser.add_argument('--env', type=str, default='hopper')
-+-    parser.add_argument('--dataset', type=str, default='medium')  # medium, medium-replay, medium-expert, expert
-++    parser.add_argument('--env', type=str, default='stock')
-++    parser.add_argument('--dataset', type=str, default='random-2330')  # medium, medium-replay, medium-expert, expert
-+     parser.add_argument('--mode', type=str, default='normal')  # normal for standard setting, delayed for sparse
-+     parser.add_argument('--K', type=int, default=20)
-+     parser.add_argument('--pct_traj', type=float, default=1.)
-+diff --git a/logs/stock_2330/gpt/azure/args.json b/logs/stock_2330/gpt/azure/args.json
-+index c13bf1c..17acae4 100644
-+--- a/logs/stock_2330/gpt/azure/args.json
-++++ b/logs/stock_2330/gpt/azure/args.json
-+@@ -3,11 +3,11 @@
-+     "action_weight": 5,
-      "add_extras": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoC4aUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoFIaUUpQu"
-      },
--     "beam_width": 128,
--     "cdf_act": 0.6,
--     "cdf_obs": null,
---    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
--+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "attn_pdrop": 0.1,
-+     "batch_size": 64,
-+-    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-++    "commit": "4bd920d3f1555913907e37871fa2384aec68e214 main",
-      "config": "config.offline",
--     "dataset": "forex-v0",
-+     "dataset": "stock_2330",
-      "device": "cuda",
--     "exp_name": "plans/defaults/freq1_H15_beam128",
-+@@ -17,18 +17,18 @@
-+     "exp_name": "gpt/azure",
-      "generate_exp_name": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoDoaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoKYaUUpQu"
-      },
-      "get_commit": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoMYaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoIYaUUpQu"
-      },
--     "gpt_epoch": "latest",
--     "gpt_loadpath": "gpt/azure",
--@@ -28,7 +28,7 @@
--     "max_context_transitions": 5,
-+     "learning_rate": 0.0006,
-+     "logbase": "logs/",
-+     "lr_decay": true,
-      "mkdir": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoLIaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoLYaUUpQu"
-      },
--     "n_expand": 2,
--     "percentile": "mean",
--@@ -37,24 +37,24 @@
--     "prefix_context": true,
-+     "n_embd": 32,
-+     "n_epochs_ref": 50,
-+@@ -37,26 +37,26 @@
-+     "n_saves": 3,
-      "read_config": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoOYaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoOoaUUpQu"
-      },
--     "renderer": "Renderer",
-      "reproducibility": {
--         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
-          "git_has_uncommitted_changes": true,
-          "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
---        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
---        "time": "Sun May 14 00:30:59 2023"
--+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
--+        "time": "Tue May 16 00:22:08 2023"
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
-+-        "time": "Tue May 16 18:48:00 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/4bd920d3f1555913907e37871fa2384aec68e214",
-++        "time": "Tue May 23 21:53:51 2023"
-      },
-+     "resid_pdrop": 0.1,
-+     "reward_weight": 1,
-      "save_diff": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoGoaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoDIaUUpQu"
-      },
--     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "savepath": "logs/stock_2330/gpt/azure",
-+     "seed": 42,
-      "set_seed": {
-          "_type": "python_object (type = method)",
---        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
--+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+-        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAphZGRfZXh0cmFzlGgCaAZoC4aUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoDoaUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNcmV3YXJkX3dlaWdodJRLAYwBTpRLFIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwIZGlzY291bnSURz/vrhR64UeujAlzYXZlX2RpZmaUaAJoBmgahpRSlIwHbl9zYXZlc5RLA4wac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMBmRldmljZZSMBGN1ZGGUjAhzZXRfc2VlZJRoAmgGaCGGlFKUjAdsb2diYXNllIwFbG9ncy+UjAtyZXNpZF9wZHJvcJRHP7mZmZmZmZqMB25fbGF5ZXKUSwSMDG5fZXBvY2hzX3JlZpRLMowMdmFsdWVfd2VpZ2h0lEsBjAhscl9kZWNheZSIjAZuX2hlYWSUSwSMBW1rZGlylGgCaAZoLIaUUpSMBmNvbW1pdJSMLTA3YmE3M2ZhYmYwZGJlNmQyMzAyMDZlODhkYWIxZDNmODdhZjgxYjIgbWFpbpSMCmdldF9jb21taXSUaAJoBmgxhpRSlIwNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMBm5fZW1iZJRLIIwEc2VlZJRLKowKYXR0bl9wZHJvcJRHP7mZmZmZmZqMDWFjdGlvbl93ZWlnaHSUSwWMC3JlYWRfY29uZmlnlGgCaAZoOYaUUpSMCmJhdGNoX3NpemWUS0CMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwHZGF0YXNldJSMCnN0b2NrXzIzMzCUdWJoIYaUUpQu"
-++        "_value": "gASVHAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDG5fZXBvY2hzX3JlZpRLMowHbl9zYXZlc5RLA4wGY29tbWl0lIwtNGJkOTIwZDNmMTU1NTkxMzkwN2UzNzg3MWZhMjM4NGFlYzY4ZTIxNCBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoDIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAduX2xheWVylEsEjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMBm5faGVhZJRLBIwKYWRkX2V4dHJhc5RoAmgGaBSGlFKUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMCHNhdmVwYXRolIwZbG9ncy9zdG9ja18yMzMwL2dwdC9henVyZZSMCGV4cF9uYW1llIwJZ3B0L2F6dXJllIwEc3RlcJRLAYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwac3Vic2FtcGxlZF9zZXF1ZW5jZV9sZW5ndGiUSwqMCmdldF9jb21taXSUaAJoBmghhpRSlIwNcmV3YXJkX3dlaWdodJRLAYwEc2VlZJRLKowTdGVybWluYXRpb25fcGVuYWx0eZRKnP///4wNbGVhcm5pbmdfcmF0ZZRHP0OpKjBVMmGMCGRpc2NvdW50lEc/764UeuFHrowRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgphpRSlIwIbHJfZGVjYXmUiIwFbWtkaXKUaAJoBmgthpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwGZGV2aWNllIwEY3VkYZSMDHZhbHVlX3dlaWdodJRLAYwNYWN0aW9uX3dlaWdodJRLBYwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAhzZXRfc2VlZJRoAmgGaDeGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDqGlFKUjAFOlEsUjAphdHRuX3Bkcm9wlEc/uZmZmZmZmowKYmF0Y2hfc2l6ZZRLQIwGbl9lbWJklEsgdWJoN4aUUpQu"
-      },
--     "suffix": "0",
--     "verbose": true,
--diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
--index 6c69f6b..c30ee70 100644
----- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
--+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
--@@ -1,244 +1,71 @@
---diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
---index 1dd7eb6..98c4875 100644
------ a/Trajectory_Transformer/config/offline.py
---+++ b/Trajectory_Transformer/config/offline.py
---@@ -17,7 +17,7 @@ args_to_watch = [
--- base = {
--- 
---     'train': {
----        'N': 100,
---+        'N': 20,
---         'discount': 0.99,
---         'n_layer': 4,
---         'n_head': 4,
---diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
---index 881688c..f06654a 100644
------ a/Trajectory_Transformer/scripts/plan.py
---+++ b/Trajectory_Transformer/scripts/plan.py
---@@ -1,10 +1,15 @@
--- import json
--- import pdb
---+import os
---+import sys
--- from os.path import join
--- import gym
--- import gym_anytrading
---+import numpy as np
--- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
--- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
---+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
---+sys.path.insert(0, parent_dir)
--- import trajectory.utils as utils
--- import trajectory.datasets as datasets
--- from trajectory.search import (
---@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
--- #######################
--- 
--- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
----renderer = utils.make_renderer(args)
---+#renderer = utils.make_renderer(args)
--- timer = utils.timer.Timer()
--- 
--- discretizer = dataset.discretizer
---@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
--- action_dim = dataset.action_dim
--- 
--- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
----preprocess_fn = datasets.get_preprocess_fn(env.name)
---+#preprocess_fn = datasets.get_preprocess_fn(env.name)
--- 
--- #######################
--- ###### main loop ######
---@@ -63,10 +68,11 @@ rollout = [observation.copy()]
--- ## previous (tokenized) transitions for conditioning transformer
--- context = []
--- 
----T = env.max_episode_steps
---+T = 1000000
--- for t in range(T):
--- 
----    observation = preprocess_fn(observation)
---+    #observation = preprocess_fn(observation)
---+    observation = observation.reshape(-1)
--- 
---     if t % args.plan_freq == 0:
---         ## concatenate previous transitions and current observations to input to model
---@@ -90,18 +96,18 @@ for t in range(T):
---     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
--- 
---     ## execute action in environment
----    next_observation, reward, terminal, _ = env.step(action)
---+    next_observation, reward, terminal, info = env.step(np.argmax(action))
--- 
---     ## update return
---     total_reward += reward
----    score = env.get_normalized_score(total_reward)
---+    #score = env.get_normalized_score(total_reward)
--- 
---     ## update rollout observations and context transitions
---     rollout.append(next_observation.copy())
---     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
--- 
---     print(
----        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
---+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
---         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
---     )
--- 
---@@ -114,11 +120,13 @@ for t in range(T):
---     #    ## save rollout thus far
---     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
--- 
----    if terminal: break
---+    if terminal: 
---+        print(info)
---+        break
--- 
---     observation = next_observation
--- 
--- ## save result as a json file
--- json_path = join(args.savepath, 'rollout.json')
----json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
---+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
---diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
---index ddcda7a..9a2273b 100644
------ a/Trajectory_Transformer/scripts/train.py
---+++ b/Trajectory_Transformer/scripts/train.py
---@@ -2,11 +2,17 @@ import os
--- import numpy as np
--- import torch
--- import pdb
---+import sys
---+
---+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
---+sys.path.insert(0, parent_dir)
--- 
--- import trajectory.utils as utils
--- import trajectory.datasets as datasets
--- from trajectory.models.transformers import GPT
--- 
---+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
---+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
--- 
--- class Parser(utils.Parser):
---     dataset: str = 'forex-v0'
---@@ -31,7 +37,7 @@ dataset_config = utils.Config(
---     savepath=(args.savepath, 'data_config.pkl'),
---     env=args.dataset,
---     N=args.N,
----    penalty=args.termination_penalty,
---+    penalty=None,
---     sequence_length=sequence_length,
---     step=args.step,
---     discount=args.discount,
---@@ -104,7 +110,8 @@ trainer = trainer_config()
--- #######################
--- 
--- ## scale number of epochs to keep number of updates constant
----n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---+n_epochs = 3000
--- save_freq = int(n_epochs // args.n_saves)
--- 
--- for epoch in range(n_epochs):
---diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
---deleted file mode 100644
---index fa97c75..0000000
---Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
---diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---index 71bfb7e..bbd08e4 100644
------ a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--- action_dim = env.action_space.n
--- 
--- episode = 10
----
---+T = 0
--- episode_data = {}
--- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
---     episode_data[k] = []
---@@ -25,13 +25,12 @@ for _ in range(episode):
---         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
---         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
---         episode_data['actions'].append(action)
----        episode_data['rewards'].append(np.array(reward).astype('float32'))
---+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
---         episode_data['terminals'].append(done)
---         if done:
---             break
--- 
--- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
---     episode_data[k] = np.stack(episode_data[k])
----
----with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
---+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
---     pickle.dump(episode_data, f)
---\ No newline at end of file
---diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
---index 69ee58d..d1062c5 100644
------ a/Trajectory_Transformer/trajectory/datasets/__init__.py
---+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
---@@ -1,3 +1,3 @@
----from .d4rl import load_environment
---+#from .d4rl import load_environment
--- from .sequence import *
--- from .preprocessing import get_preprocess_fn
---diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
---index c23b4f3..4525194 100644
------ a/Trajectory_Transformer/trajectory/datasets/sequence.py
---+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
---@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
---         self.device = device
---         
---         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
----        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
---+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
---             dataset = pickle.load(f)
---         print('✓')
--- 
---@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
---         terminals = dataset['terminals']
---         realterminals = [False]*len(dataset['terminals'])
--- 
----        #observations = np.reshape(observations, (100, 7000))
---         self.observations_raw = observations
---         self.actions_raw = actions
---         self.next_observations_raw = next_observations
---diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
---index 7c596c3..7529384 100644
------ a/Trajectory_Transformer/trajectory/utils/__init__.py
---+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
---@@ -2,7 +2,7 @@ from .setup import Parser, watch
--- from .arrays import *
--- from .serialization import *
--- from .progress import Progress, Silent
----from .rendering import make_renderer
---+#from .rendering import make_renderer
--- # from .video import *
--- from .config import Config
--- from .training import Trainer
---diff --git a/requirements.txt b/requirements.txt
---index ece16ed..a579177 100644
------ a/requirements.txt
---+++ b/requirements.txt
---@@ -1,14 +1,16 @@
--- numpy
--- gym
--- numpy
----torch
---+pytorch==1.12.1
---+torchvision==0.13.1 
---+torchaudio==0.12.1
--- transformers==4.5.1
--- wandb==0.9.1
--- tensorboard
--- pyprind
--- tensorflow
--- gin-config
----gym
---+gym==0.21.0
--- tqdm
--- blosc
--- git+https://github.com/google/dopamine.git
--\ No newline at end of file
--+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--+index f42cef8..0e84897 100644
--+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
--+@@ -1,23 +1,23 @@
--+ {
--+     "add_extras": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
--+     },
--+     "beam_width": 128,
--+     "cdf_act": 0.6,
--+     "cdf_obs": null,
--+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
--++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
--+     "config": "config.offline",
--+     "dataset": "forex-v0",
--+     "device": "cuda",
--+     "exp_name": "plans/defaults/freq1_H15_beam128",
--+     "generate_exp_name": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
--+     },
--+     "get_commit": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
--+     },
--+     "gpt_epoch": "latest",
--+     "gpt_loadpath": "gpt/azure",
--+@@ -28,7 +28,7 @@
--+     "max_context_transitions": 5,
--+     "mkdir": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
--+     },
--+     "n_expand": 2,
--+     "percentile": "mean",
--+@@ -37,24 +37,24 @@
--+     "prefix_context": true,
--+     "read_config": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
--+     },
--+     "renderer": "Renderer",
--+     "reproducibility": {
--+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
--+         "git_has_uncommitted_changes": true,
--+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--+-        "time": "Sun May 14 00:30:59 2023"
--++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
--++        "time": "Tue May 16 00:22:08 2023"
--+     },
--+     "save_diff": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
--+     },
--+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
--+     "set_seed": {
--+         "_type": "python_object (type = method)",
--+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
--++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
--+     },
--+     "suffix": "0",
--+     "verbose": true,
--\ No newline at end of file
--diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
--deleted file mode 100644
--index 59fc81f..0000000
----- a/logs/stocks-v0_r/gpt/azure/args.json
--+++ /dev/null
--@@ -1,65 +0,0 @@
---{
---    "N": 20,
---    "action_weight": 5,
---    "add_extras": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
---    },
---    "attn_pdrop": 0.1,
---    "batch_size": 64,
---    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
---    "config": "config.offline",
---    "dataset": "stocks-v0_r",
---    "device": "cuda",
---    "discount": 0.99,
---    "discretizer": "QuantileDiscretizer",
---    "embd_pdrop": 0.1,
---    "exp_name": "gpt/azure",
---    "generate_exp_name": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
---    },
---    "get_commit": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
---    },
---    "learning_rate": 0.0006,
---    "logbase": "logs/",
---    "lr_decay": true,
---    "mkdir": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
---    },
---    "n_embd": 32,
---    "n_epochs_ref": 50,
---    "n_head": 4,
---    "n_layer": 4,
---    "n_saves": 3,
---    "read_config": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
---    },
---    "reproducibility": {
---        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
---        "git_has_uncommitted_changes": true,
---        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
---        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
---        "time": "Mon May 15 17:39:32 2023"
---    },
---    "resid_pdrop": 0.1,
---    "reward_weight": 1,
---    "save_diff": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
---    },
---    "savepath": "logs/stocks-v0_r/gpt/azure",
---    "seed": 42,
---    "set_seed": {
---        "_type": "python_object (type = method)",
---        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
---    },
---    "step": 1,
---    "subsampled_sequence_length": 10,
---    "termination_penalty": -100,
---    "value_weight": 1
---}
--\ No newline at end of file
--diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
--deleted file mode 100644
--index f2b7eea..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
--deleted file mode 100644
--index 7d861b1..0000000
----- a/logs/stocks-v0_r/gpt/azure/diff.txt
--+++ /dev/null
--@@ -1,59 +0,0 @@
---diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
---index 98c4875..9a7a974 100644
------ a/Trajectory_Transformer/config/offline.py
---+++ b/Trajectory_Transformer/config/offline.py
---@@ -29,7 +29,7 @@ base = {
---         'device': 'cuda',
--- 
---         'n_embd': 32,
----        'batch_size': 256,
---+        'batch_size': 64,
---         'learning_rate': 6e-4,
---         'lr_decay': True,
---         'seed': 42,
---diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
---index 9a2273b..6ef5569 100644
------ a/Trajectory_Transformer/scripts/train.py
---+++ b/Trajectory_Transformer/scripts/train.py
---@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
--- 
--- class Parser(utils.Parser):
----    dataset: str = 'forex-v0'
---+    dataset: str = 'stocks-v0_r'
---     config: str = 'config.offline'
--- 
--- #######################
---@@ -111,7 +111,7 @@ trainer = trainer_config()
--- 
--- ## scale number of epochs to keep number of updates constant
--- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
----n_epochs = 3000
---+n_epochs = 5000
--- save_freq = int(n_epochs // args.n_saves)
--- 
--- for epoch in range(n_epochs):
---diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
---index 506330f..e08063c 100644
---Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
---diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---index bbd08e4..659bd84 100644
------ a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
---@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
--- import numpy as np
--- import pickle
--- 
----quat_type = "forex-v0"
----env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
---+quat_type = "stocks-v0"
---+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
--- 
--- action_dim = env.action_space.n
--- 
----episode = 10
---+episode = 100
--- T = 0
--- episode_data = {}
--- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--\ No newline at end of file
--diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
--deleted file mode 100644
--index db868c9..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
--deleted file mode 100644
--index aaacded..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
--deleted file mode 100644
--index c3fe2b4..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
--deleted file mode 100644
--index f13edba..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
--deleted file mode 100644
--index 5531c7d..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
--diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
--deleted file mode 100644
--index 090ede9..0000000
--Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
--diff --git a/old_env/trader.py b/old_env/trader.py
--index 7937f12..6b2f29c 100644
----- a/old_env/trader.py
--+++ b/old_env/trader.py
--@@ -4,7 +4,7 @@ import math
-- 
-- from time import time
-- from enum import Enum
---from env.position import Position
--+from position import Position
-- 
-- 
-- class ActionCode(Enum):
-\ No newline at end of file
-+     "step": 1,
-+     "subsampled_sequence_length": 10,
-\ No newline at end of file
\ No newline at end of file
diff --git a/logs/stock_2330/gpt/azure/model_config.pkl b/logs/stock_2330/gpt/azure/model_config.pkl
deleted file mode 100644
index 033b29b..0000000
Binary files a/logs/stock_2330/gpt/azure/model_config.pkl and /dev/null differ
diff --git a/logs/stock_2330/gpt/azure/state_0.pt b/logs/stock_2330/gpt/azure/state_0.pt
deleted file mode 100644
index 2008ae4..0000000
Binary files a/logs/stock_2330/gpt/azure/state_0.pt and /dev/null differ
diff --git a/logs/stock_2330/gpt/azure/trainer_config.pkl b/logs/stock_2330/gpt/azure/trainer_config.pkl
deleted file mode 100644
index d323415..0000000
Binary files a/logs/stock_2330/gpt/azure/trainer_config.pkl and /dev/null differ
diff --git a/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/args.json b/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/args.json
deleted file mode 100644
index 1b192a0..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgrhpRSlC4="
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-    "config": "config.offline",
-    "dataset": "stock_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H10_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmhAhpRSlC4="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgJhpRSlC4="
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 10,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1Ymg9hpRSlC4="
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgwhpRSlC4="
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
-        "time": "Tue May 16 18:33:05 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgQhpRSlC4="
-    },
-    "savepath": "logs/stock_2330/plans/defaults/freq1_H10_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaAmGlFKUjAVrX2FjdJROjApiZWFtX3dpZHRolEuAjAhleHBfbmFtZZSMIHBsYW5zL2RlZmF1bHRzL2ZyZXExX0gxMF9iZWFtMTI4lIwJc2F2ZV9kaWZmlGgCaAZoEIaUUpSMCHZpc19mcmVxlEsyjAZjb21taXSUjC0wN2JhNzNmYWJmMGRiZTZkMjMwMjA2ZTg4ZGFiMWQzZjg3YWY4MWIyIG1haW6UjAdob3Jpem9ulEsKjAlncHRfZXBvY2iUjAZsYXRlc3SUjAd2ZXJib3NllIiMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwFa19vYnOUSwGMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMB2NkZl9hY3SURz/jMzMzMzMzjAlwbGFuX2ZyZXGUSwGMCG5fZXhwYW5klEsCjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwGc3VmZml4lIwBMJSMCHNldF9zZWVklGgCaAZoKIaUUpSMCmFkZF9leHRyYXOUaAJoBmgrhpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAtyZWFkX2NvbmZpZ5RoAmgGaDCGlFKUjAdsb2diYXNllIwFbG9ncy+UjA5wcmVmaXhfY29udGV4dJSIjAZkZXZpY2WUjARjdWRhlIwIc2F2ZXBhdGiUjDJsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDEwX2JlYW0xMjgvMJSMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBW1rZGlylGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgohpRSlC4="
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/diff.txt b/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/diff.txt
deleted file mode 100644
index 1a5816f..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H10_beam128/0/diff.txt
+++ /dev/null
@@ -1,977 +0,0 @@
-diff --git a/DDPG.py b/DDPG.py
-index d682b97..c69f550 100644
---- a/DDPG.py
-+++ b/DDPG.py
-@@ -1,6 +1,3 @@
--from env.market import Market
--from helper.args_parser import model_launcher_parser
--from helper.data_logger import generate_algorithm_logger, generate_market_logger
- import sys
- import gym
- import numpy as np
-@@ -15,12 +12,15 @@ from torch.autograd import Variable
- import torch.optim.lr_scheduler as Scheduler
- import torch.nn.functional as F
- from torch.utils.tensorboard import SummaryWriter
-+from buildEnv import createEnv, MyStocksEnv
-+from torch.distributions import Categorical
- import logging
- #from skopt.space import Real, Integer
- #from skopt import gp_minimize
- logging.basicConfig(filename='train.log', level=logging.DEBUG)
- 
--
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- def soft_update(target, source, tau):
-     for target_param, param in zip(target.parameters(), source.parameters()):
-         target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
-@@ -153,46 +153,16 @@ class DDPG(object):
-         hard_update(self.actor_target, self.actor) 
-         hard_update(self.critic_target, self.critic)
- 
--    def get_stock_code_and_action(self, a, use_greedy=False, use_prob=False):
--        # Reshape a.
--        if not use_greedy:
--            a = a.reshape((-1,))
--            # Calculate action index depends on prob.
--            if use_prob:
--                # Generate indices.
--                a_indices = np.arange(a.shape[0])
--                # Get action index.
--                action_index = np.random.choice(a_indices, p=a)
--            else:
--                # Get action index.
--                action_index = np.argmax(a)
--        else:
--            if use_prob:
--                # Calculate action index
--                if np.random.uniform() < self.epsilon:
--                    action_index = np.floor(a).astype(int)
--                else:
--                    action_index = np.random.randint(0, self.action_space)
--            else:
--                # Calculate action index
--                action_index = np.floor(a).astype(int)
--
--        # Get action
--        action = action_index % 3
--        # Get stock index
--        stock_index = np.floor(action_index / 3).astype(np.int)
--        # Get stock code.
--        stock_code = self.env.codes[stock_index]
--
--        return stock_code, action, action_index
--
--    def select_action(self, state, action_noise=None):
-+
-+    def select_action(self, state, epsilon=0.0):
-         self.actor.eval()
--        mu = self.actor((Variable(state)))
--        mu = mu.data
--        noise = [0.0] if action_noise is None else action_noise.noise()
--        noise = torch.FloatTensor(noise)
--        return torch.clamp(mu + noise, min=0, max=1.0)
-+        probs = self.actor((Variable(state)))
-+        probs = probs.detach()
-+        m = Categorical(logits= probs)
-+        action = m.sample().item()
-+        if random.random() > epsilon:
-+            return self.env.action_space.sample()
-+        return action
- 
-     def update_parameters(self, batch):
-         state_batch = Variable(torch.cat([b.state for b in batch]))
-@@ -201,7 +171,6 @@ class DDPG(object):
-         mask_batch = Variable(torch.cat([b.mask for b in batch]))
-         next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
-         
--        ########## YOUR CODE HERE (10~20 lines) ##########
-         # Calculate policy loss and value loss
-         # Update the actor and the critic
-         q_v = self.critic(state_batch, action_batch)
-@@ -219,7 +188,6 @@ class DDPG(object):
-         self.actor_optim.zero_grad()
-         policy_loss.backward()
-         self.actor_optim.step()
--        ########## END OF YOUR CODE ########## 
- 
-         soft_update(self.actor_target, self.actor, self.tau)
-         soft_update(self.critic_target, self.critic, self.tau)
-@@ -248,9 +216,9 @@ class DDPG(object):
-         if critic_path is not None: 
-             self.critic.load_state_dict(torch.load(critic_path))
- 
--def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-+def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-     # Define a tensorboard writer
--    writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-+    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
- 
-     logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
-         lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
-@@ -276,9 +244,8 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-     total_numsteps = 0
-     updates = 0
- 
--    
--    agent = DDPG(num_inputs = env.data_dim,
--                 action_space = env.trader.action_space, 
-+    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
-+                 action_space = env.action_space.n, 
-                  env = env, 
-                  epsilon= epsilon,
-                  gamma = gamma, 
-@@ -288,15 +255,15 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 lr_c= lr_c, 
-                 lr_a_decay= lr_a_decay, 
-                 lr_c_decay = lr_c_decay)
--    ounoise = OUNoise(env.trader.action_space)
-+    #ounoise = OUNoise(env.action_space)
-     memory = ReplayMemory(replay_size)
-     
-     for i_episode in range(num_episodes):
-         
--        ounoise.scale = noise_scale
--        ounoise.reset()
-+        #ounoise.scale = noise_scale
-+        #ounoise.reset()
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
- 
-         episode_reward = 0
-         val_loss = []
-@@ -308,10 +275,9 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             # 2. Push the sample to the replay buffer
-             # 3. Update the actor and the critic
-             total_numsteps+=1
--            action = agent.select_action(state, ounoise)
--            code, action, a_index= agent.get_stock_code_and_action(action, use_greedy=False, use_prob=True)
--            next_state, reward, done, _ = env.forward(code, action)
--            next_state = torch.Tensor([next_state])
-+            action = agent.select_action(state, epsilon)
-+            next_state, reward, done, info = env.step(action)
-+            next_state = torch.Tensor([next_state.reshape(-1)])
-             memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
-             if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
-                 batch = memory.sample(batch_size)
-@@ -320,7 +286,7 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 act_loss.append(a_loss)
-             episode_reward += reward
-             state = next_state
--            if done == env.Done:
-+            if done:
-                 break
-             ########## END OF YOUR CODE ########## 
-         
-@@ -330,23 +296,24 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-         critic_loss = np.mean(val_loss)
-         t = 0
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
-         episode_reward = 0
-         while True:
-             action = agent.select_action(state)
- 
--            next_state, reward, done, _ = env.step(action.numpy()[0])
-+            next_state, reward, done, info = env.step(action)
-             
-             #env.render()
-             
-             episode_reward += reward
- 
--            next_state = torch.Tensor([next_state])
-+            next_state = torch.Tensor([next_state.reshape(-1)])
- 
-             state = next_state
-             
-             t += 1
-             if done:
-+                print(info)
-                 break
- 
-         rewards.append(episode_reward)
-@@ -358,36 +325,22 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
- 
-         #Logging
--        writer.add_scalar('Reward', episode_reward, i_episode)
--        writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
--        writer.add_scalar('Critic loss', critic_loss, i_episode)
--        writer.add_scalar('Actor loss', actor_loss, i_episode)
--
--        if ewma_reward >= 120:
--            agent.save_model(env_name, '.pth')
--            logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--            #break
--            return (ewma_reward+500)/(i_episode+1) #For tuning
-+        #writer.add_scalar('Reward', episode_reward, i_episode)
-+        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
-+        #writer.add_scalar('Critic loss', critic_loss, i_episode)
-+        #writer.add_scalar('Actor loss', actor_loss, i_episode)
-+
-+        #if ewma_reward >= 120:
-+        #    agent.save_model(env_name, '.pth')
-+        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-+        #    #break
-+        #    return (ewma_reward+500)/(i_episode+1) #For tuning
-     
-     agent.save_model(env_name, '.pth')  
-     logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-     return (ewma_reward+500)/(i_episode+1) #For tuning
- 
- def main():
--    """
--    Market environment args 
--    """
--    #mode = args.mode
--    mode = 'test'
--    # codes = args.codes
--    codes = ["2303"]
--    # market = args.market
--    market = 'stock'
--    # episode = args.episode
--    episode = 1000
--    training_data_ratio = 0.95
--    # training_data_ratio = args.training_data_ratio
--
-     """
-     Training args
-     """
-@@ -398,14 +351,8 @@ def main():
-     noise_scale_ = 0.3
-     batch_size_ = 64
- 
--    model_name = os.path.basename(__file__).split('.')[0]
- 
--    env = Market(codes, start_date="2012-01-01", end_date="2018-01-01", **{
--        "market": market,
--        "mix_index_state": False,
--        "logger": generate_market_logger(model_name),
--        "training_data_ratio": training_data_ratio,
--    })
-+    env = createEnv(2330)
- 
-     train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
- if __name__ == '__main__':
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 9a7a974..73c5b28 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -57,7 +57,7 @@ base = {
-         'renderer': 'Renderer',
- 
-         'plan_freq': 1,
--        'horizon': 15,
-+        'horizon': 10,
-         'beam_width': 128,
-         'n_expand': 2,
- 
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index f06654a..8979c32 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -12,15 +12,19 @@ parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
- sys.path.insert(0, parent_dir)
- import trajectory.utils as utils
- import trajectory.datasets as datasets
-+from trajectory.datasets.Random.buildEnv import createEnv
- from trajectory.search import (
-     beam_plan,
-     make_prefix,
-     extract_actions,
-     update_context,
- )
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '3'
- 
-+code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stock_'+code
-     config: str = 'config.offline'
- 
- #######################
-@@ -43,7 +47,8 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
- ####### dataset #######
- #######################
- 
--env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
-+
-+env = createEnv(code)
- #renderer = utils.make_renderer(args)
- timer = utils.timer.Timer()
- 
-@@ -68,7 +73,7 @@ rollout = [observation.copy()]
- ## previous (tokenized) transitions for conditioning transformer
- context = []
- 
--T = 1000000
-+T = 1187
- for t in range(T):
- 
-     #observation = preprocess_fn(observation)
-@@ -105,11 +110,11 @@ for t in range(T):
-     ## update rollout observations and context transitions
-     rollout.append(next_observation.copy())
-     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
--
-     print(
-         f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
-         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
-     )
-+    print(info, action)
- 
-     ## visualization
-     #if t % args.vis_freq == 0 or terminal or t == T:
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index 6ef5569..bb35461 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stocks-v0_r'
-+    dataset: str = 'stock_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 5000
-+n_epochs = 10000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index 659bd84..28c9f58 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -5,9 +5,12 @@ from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
- import matplotlib.pyplot as plt
- import numpy as np
- import pickle
-+import os
-+import sys
-+from buildEnv import createEnv
- 
--quat_type = "stocks-v0"
--env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-+quat_type = 2330
-+env = createEnv(2330)
- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- 
- action_dim = env.action_space.n
-@@ -20,11 +23,11 @@ for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals'
- for _ in range(episode):
-     observation = env.reset()
-     while True:
--        action = np.random.rand(action_dim)
--        next_observation, reward, done, _ = env.step(np.argmax(action))
-+        action = env.action_space.sample()
-+        next_observation, reward, done, _ = env.step(action)
-         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
-         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--        episode_data['actions'].append(action)
-+        episode_data['actions'].append(np.array([action]))
-         episode_data['rewards'].append(np.array([reward]).astype('float32'))
-         episode_data['terminals'].append(done)
-         if done:
-@@ -32,5 +35,5 @@ for _ in range(episode):
- 
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
-+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
-     pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 4525194..bd75e78 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -44,7 +44,7 @@ def segment(observations, terminals, max_path_length):
- 
- class SequenceDataset(torch.utils.data.Dataset):
- 
--    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=1000, penalty=None, device='cuda:0'):
-+    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=2000, penalty=None, device='cuda:0'):
-         print(f'[ datasets/sequence ] Sequence length: {sequence_length} | Step: {step} | Max path length: {max_path_length}')
-         #self.env = env = load_environment(env) if type(env) is str else env
-         self.sequence_length = sequence_length
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-index 6c69f6b..c30ee70 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-@@ -1,244 +1,71 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 1dd7eb6..98c4875 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -17,7 +17,7 @@ args_to_watch = [
-- base = {
-- 
--     'train': {
---        'N': 100,
--+        'N': 20,
--         'discount': 0.99,
--         'n_layer': 4,
--         'n_head': 4,
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index 881688c..f06654a 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -1,10 +1,15 @@
-- import json
-- import pdb
--+import os
--+import sys
-- from os.path import join
-- import gym
-- import gym_anytrading
--+import numpy as np
-- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
-- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.search import (
--@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- #######################
-- 
-- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
---renderer = utils.make_renderer(args)
--+#renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
-- discretizer = dataset.discretizer
--@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
-- action_dim = dataset.action_dim
-- 
-- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
---preprocess_fn = datasets.get_preprocess_fn(env.name)
--+#preprocess_fn = datasets.get_preprocess_fn(env.name)
-- 
-- #######################
-- ###### main loop ######
--@@ -63,10 +68,11 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = env.max_episode_steps
--+T = 1000000
-- for t in range(T):
-- 
---    observation = preprocess_fn(observation)
--+    #observation = preprocess_fn(observation)
--+    observation = observation.reshape(-1)
-- 
--     if t % args.plan_freq == 0:
--         ## concatenate previous transitions and current observations to input to model
--@@ -90,18 +96,18 @@ for t in range(T):
--     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
-- 
--     ## execute action in environment
---    next_observation, reward, terminal, _ = env.step(action)
--+    next_observation, reward, terminal, info = env.step(np.argmax(action))
-- 
--     ## update return
--     total_reward += reward
---    score = env.get_normalized_score(total_reward)
--+    #score = env.get_normalized_score(total_reward)
-- 
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-- 
--     print(
---        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
--+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
-- 
--@@ -114,11 +120,13 @@ for t in range(T):
--     #    ## save rollout thus far
--     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
-- 
---    if terminal: break
--+    if terminal: 
--+        print(info)
--+        break
-- 
--     observation = next_observation
-- 
-- ## save result as a json file
-- json_path = join(args.savepath, 'rollout.json')
---json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
-- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index ddcda7a..9a2273b 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -2,11 +2,17 @@ import os
-- import numpy as np
-- import torch
-- import pdb
--+import sys
--+
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- 
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.models.transformers import GPT
-- 
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
--     dataset: str = 'forex-v0'
--@@ -31,7 +37,7 @@ dataset_config = utils.Config(
--     savepath=(args.savepath, 'data_config.pkl'),
--     env=args.dataset,
--     N=args.N,
---    penalty=args.termination_penalty,
--+    penalty=None,
--     sequence_length=sequence_length,
--     step=args.step,
--     discount=args.discount,
--@@ -104,7 +110,8 @@ trainer = trainer_config()
-- #######################
-- 
-- ## scale number of epochs to keep number of updates constant
---n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+n_epochs = 3000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
--deleted file mode 100644
--index fa97c75..0000000
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 71bfb7e..bbd08e4 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-- action_dim = env.action_space.n
-- 
-- episode = 10
---
--+T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = []
--@@ -25,13 +25,12 @@ for _ in range(episode):
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--         episode_data['actions'].append(action)
---        episode_data['rewards'].append(np.array(reward).astype('float32'))
--+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--             break
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---
---with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
--diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
--index 69ee58d..d1062c5 100644
----- a/Trajectory_Transformer/trajectory/datasets/__init__.py
--+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
--@@ -1,3 +1,3 @@
---from .d4rl import load_environment
--+#from .d4rl import load_environment
-- from .sequence import *
-- from .preprocessing import get_preprocess_fn
--diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index c23b4f3..4525194 100644
----- a/Trajectory_Transformer/trajectory/datasets/sequence.py
--+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
--         self.device = device
--         
--         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
---        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
--+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
--             dataset = pickle.load(f)
--         print('✓')
-- 
--@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
--         terminals = dataset['terminals']
--         realterminals = [False]*len(dataset['terminals'])
-- 
---        #observations = np.reshape(observations, (100, 7000))
--         self.observations_raw = observations
--         self.actions_raw = actions
--         self.next_observations_raw = next_observations
--diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
--index 7c596c3..7529384 100644
----- a/Trajectory_Transformer/trajectory/utils/__init__.py
--+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
--@@ -2,7 +2,7 @@ from .setup import Parser, watch
-- from .arrays import *
-- from .serialization import *
-- from .progress import Progress, Silent
---from .rendering import make_renderer
--+#from .rendering import make_renderer
-- # from .video import *
-- from .config import Config
-- from .training import Trainer
--diff --git a/requirements.txt b/requirements.txt
--index ece16ed..a579177 100644
----- a/requirements.txt
--+++ b/requirements.txt
--@@ -1,14 +1,16 @@
-- numpy
-- gym
-- numpy
---torch
--+pytorch==1.12.1
--+torchvision==0.13.1 
--+torchaudio==0.12.1
-- transformers==4.5.1
-- wandb==0.9.1
-- tensorboard
-- pyprind
-- tensorflow
-- gin-config
---gym
--+gym==0.21.0
-- tqdm
-- blosc
-- git+https://github.com/google/dopamine.git
-\ No newline at end of file
-+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+index f42cef8..0e84897 100644
-+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+@@ -1,23 +1,23 @@
-+ {
-+     "add_extras": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+     },
-+     "beam_width": 128,
-+     "cdf_act": 0.6,
-+     "cdf_obs": null,
-+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "config": "config.offline",
-+     "dataset": "forex-v0",
-+     "device": "cuda",
-+     "exp_name": "plans/defaults/freq1_H15_beam128",
-+     "generate_exp_name": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+     },
-+     "get_commit": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+     },
-+     "gpt_epoch": "latest",
-+     "gpt_loadpath": "gpt/azure",
-+@@ -28,7 +28,7 @@
-+     "max_context_transitions": 5,
-+     "mkdir": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+     },
-+     "n_expand": 2,
-+     "percentile": "mean",
-+@@ -37,24 +37,24 @@
-+     "prefix_context": true,
-+     "read_config": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+     },
-+     "renderer": "Renderer",
-+     "reproducibility": {
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "git_has_uncommitted_changes": true,
-+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-+-        "time": "Sun May 14 00:30:59 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-++        "time": "Tue May 16 00:22:08 2023"
-+     },
-+     "save_diff": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+     },
-+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "set_seed": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+     },
-+     "suffix": "0",
-+     "verbose": true,
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
-deleted file mode 100644
-index 59fc81f..0000000
---- a/logs/stocks-v0_r/gpt/azure/args.json
-+++ /dev/null
-@@ -1,65 +0,0 @@
--{
--    "N": 20,
--    "action_weight": 5,
--    "add_extras": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
--    },
--    "attn_pdrop": 0.1,
--    "batch_size": 64,
--    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
--    "config": "config.offline",
--    "dataset": "stocks-v0_r",
--    "device": "cuda",
--    "discount": 0.99,
--    "discretizer": "QuantileDiscretizer",
--    "embd_pdrop": 0.1,
--    "exp_name": "gpt/azure",
--    "generate_exp_name": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
--    },
--    "get_commit": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
--    },
--    "learning_rate": 0.0006,
--    "logbase": "logs/",
--    "lr_decay": true,
--    "mkdir": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
--    },
--    "n_embd": 32,
--    "n_epochs_ref": 50,
--    "n_head": 4,
--    "n_layer": 4,
--    "n_saves": 3,
--    "read_config": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
--    },
--    "reproducibility": {
--        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
--        "git_has_uncommitted_changes": true,
--        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
--        "time": "Mon May 15 17:39:32 2023"
--    },
--    "resid_pdrop": 0.1,
--    "reward_weight": 1,
--    "save_diff": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
--    },
--    "savepath": "logs/stocks-v0_r/gpt/azure",
--    "seed": 42,
--    "set_seed": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
--    },
--    "step": 1,
--    "subsampled_sequence_length": 10,
--    "termination_penalty": -100,
--    "value_weight": 1
--}
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
-deleted file mode 100644
-index f2b7eea..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
-deleted file mode 100644
-index 7d861b1..0000000
---- a/logs/stocks-v0_r/gpt/azure/diff.txt
-+++ /dev/null
-@@ -1,59 +0,0 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 98c4875..9a7a974 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -29,7 +29,7 @@ base = {
--         'device': 'cuda',
-- 
--         'n_embd': 32,
---        'batch_size': 256,
--+        'batch_size': 64,
--         'learning_rate': 6e-4,
--         'lr_decay': True,
--         'seed': 42,
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 9a2273b..6ef5569 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stocks-v0_r'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 3000
--+n_epochs = 5000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
--index 506330f..e08063c 100644
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index bbd08e4..659bd84 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
-- 
---quat_type = "forex-v0"
---env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = "stocks-v0"
--+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
-- 
---episode = 10
--+episode = 100
-- T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
-deleted file mode 100644
-index db868c9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
-deleted file mode 100644
-index aaacded..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
-deleted file mode 100644
-index c3fe2b4..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
-deleted file mode 100644
-index f13edba..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
-deleted file mode 100644
-index 5531c7d..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
-deleted file mode 100644
-index 090ede9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
-diff --git a/old_env/trader.py b/old_env/trader.py
-index 7937f12..6b2f29c 100644
---- a/old_env/trader.py
-+++ b/old_env/trader.py
-@@ -4,7 +4,7 @@ import math
- 
- from time import time
- from enum import Enum
--from env.position import Position
-+from position import Position
- 
- 
- class ActionCode(Enum):
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/args.json b/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/args.json
deleted file mode 100644
index 6df8217..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgihpRSlC4="
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-    "config": "config.offline",
-    "dataset": "stock_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H15_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmhAhpRSlC4="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1Ymg9hpRSlC4="
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 15,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgthpRSlC4="
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgahpRSlC4="
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
-        "time": "Tue May 16 15:35:46 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1YmgXhpRSlC4="
-    },
-    "savepath": "logs/stock_2330/plans/defaults/freq1_H15_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2RhdGFzZXSUjApzdG9ja18yMzMwlIwGc3VmZml4lIwBMJSMB2NkZl9vYnOUTowIbl9leHBhbmSUSwKMB3ZlcmJvc2WUiIwXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMCXBsYW5fZnJlcZRLAYwFa19vYnOUSwGMDnByZWZpeF9jb250ZXh0lIiMCWdwdF9lcG9jaJSMBmxhdGVzdJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAlzYXZlX2RpZmaUaAJoBmgXhpRSlIwLcmVhZF9jb25maWeUaAJoBmgahpRSlIwHY2RmX2FjdJRHP+MzMzMzMzOMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCmFkZF9leHRyYXOUaAJoBmgihpRSlIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjAdob3Jpem9ulEsPjAZkZXZpY2WUjARjdWRhlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwIdmlzX2ZyZXGUSzKMBW1rZGlylGgCaAZoLYaUUpSMCHJlbmRlcmVylIwIUmVuZGVyZXKUjApiZWFtX3dpZHRolEuAjAVrX2FjdJROjAhzZXRfc2VlZJRoAmgGaDSGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCHNhdmVwYXRolIwybG9ncy9zdG9ja18yMzMwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAdsb2diYXNllIwFbG9ncy+UjApnZXRfY29tbWl0lGgCaAZoPYaUUpSMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoQIaUUpR1Ymg0hpRSlC4="
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/diff.txt
deleted file mode 100644
index 9cb3bac..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H15_beam128/0/diff.txt
+++ /dev/null
@@ -1,942 +0,0 @@
-diff --git a/DDPG.py b/DDPG.py
-index d682b97..c69f550 100644
---- a/DDPG.py
-+++ b/DDPG.py
-@@ -1,6 +1,3 @@
--from env.market import Market
--from helper.args_parser import model_launcher_parser
--from helper.data_logger import generate_algorithm_logger, generate_market_logger
- import sys
- import gym
- import numpy as np
-@@ -15,12 +12,15 @@ from torch.autograd import Variable
- import torch.optim.lr_scheduler as Scheduler
- import torch.nn.functional as F
- from torch.utils.tensorboard import SummaryWriter
-+from buildEnv import createEnv, MyStocksEnv
-+from torch.distributions import Categorical
- import logging
- #from skopt.space import Real, Integer
- #from skopt import gp_minimize
- logging.basicConfig(filename='train.log', level=logging.DEBUG)
- 
--
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- def soft_update(target, source, tau):
-     for target_param, param in zip(target.parameters(), source.parameters()):
-         target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
-@@ -153,46 +153,16 @@ class DDPG(object):
-         hard_update(self.actor_target, self.actor) 
-         hard_update(self.critic_target, self.critic)
- 
--    def get_stock_code_and_action(self, a, use_greedy=False, use_prob=False):
--        # Reshape a.
--        if not use_greedy:
--            a = a.reshape((-1,))
--            # Calculate action index depends on prob.
--            if use_prob:
--                # Generate indices.
--                a_indices = np.arange(a.shape[0])
--                # Get action index.
--                action_index = np.random.choice(a_indices, p=a)
--            else:
--                # Get action index.
--                action_index = np.argmax(a)
--        else:
--            if use_prob:
--                # Calculate action index
--                if np.random.uniform() < self.epsilon:
--                    action_index = np.floor(a).astype(int)
--                else:
--                    action_index = np.random.randint(0, self.action_space)
--            else:
--                # Calculate action index
--                action_index = np.floor(a).astype(int)
--
--        # Get action
--        action = action_index % 3
--        # Get stock index
--        stock_index = np.floor(action_index / 3).astype(np.int)
--        # Get stock code.
--        stock_code = self.env.codes[stock_index]
--
--        return stock_code, action, action_index
--
--    def select_action(self, state, action_noise=None):
-+
-+    def select_action(self, state, epsilon=0.0):
-         self.actor.eval()
--        mu = self.actor((Variable(state)))
--        mu = mu.data
--        noise = [0.0] if action_noise is None else action_noise.noise()
--        noise = torch.FloatTensor(noise)
--        return torch.clamp(mu + noise, min=0, max=1.0)
-+        probs = self.actor((Variable(state)))
-+        probs = probs.detach()
-+        m = Categorical(logits= probs)
-+        action = m.sample().item()
-+        if random.random() > epsilon:
-+            return self.env.action_space.sample()
-+        return action
- 
-     def update_parameters(self, batch):
-         state_batch = Variable(torch.cat([b.state for b in batch]))
-@@ -201,7 +171,6 @@ class DDPG(object):
-         mask_batch = Variable(torch.cat([b.mask for b in batch]))
-         next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
-         
--        ########## YOUR CODE HERE (10~20 lines) ##########
-         # Calculate policy loss and value loss
-         # Update the actor and the critic
-         q_v = self.critic(state_batch, action_batch)
-@@ -219,7 +188,6 @@ class DDPG(object):
-         self.actor_optim.zero_grad()
-         policy_loss.backward()
-         self.actor_optim.step()
--        ########## END OF YOUR CODE ########## 
- 
-         soft_update(self.actor_target, self.actor, self.tau)
-         soft_update(self.critic_target, self.critic, self.tau)
-@@ -248,9 +216,9 @@ class DDPG(object):
-         if critic_path is not None: 
-             self.critic.load_state_dict(torch.load(critic_path))
- 
--def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-+def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-     # Define a tensorboard writer
--    writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-+    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
- 
-     logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
-         lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
-@@ -276,9 +244,8 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-     total_numsteps = 0
-     updates = 0
- 
--    
--    agent = DDPG(num_inputs = env.data_dim,
--                 action_space = env.trader.action_space, 
-+    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
-+                 action_space = env.action_space.n, 
-                  env = env, 
-                  epsilon= epsilon,
-                  gamma = gamma, 
-@@ -288,15 +255,15 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 lr_c= lr_c, 
-                 lr_a_decay= lr_a_decay, 
-                 lr_c_decay = lr_c_decay)
--    ounoise = OUNoise(env.trader.action_space)
-+    #ounoise = OUNoise(env.action_space)
-     memory = ReplayMemory(replay_size)
-     
-     for i_episode in range(num_episodes):
-         
--        ounoise.scale = noise_scale
--        ounoise.reset()
-+        #ounoise.scale = noise_scale
-+        #ounoise.reset()
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
- 
-         episode_reward = 0
-         val_loss = []
-@@ -308,10 +275,9 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             # 2. Push the sample to the replay buffer
-             # 3. Update the actor and the critic
-             total_numsteps+=1
--            action = agent.select_action(state, ounoise)
--            code, action, a_index= agent.get_stock_code_and_action(action, use_greedy=False, use_prob=True)
--            next_state, reward, done, _ = env.forward(code, action)
--            next_state = torch.Tensor([next_state])
-+            action = agent.select_action(state, epsilon)
-+            next_state, reward, done, info = env.step(action)
-+            next_state = torch.Tensor([next_state.reshape(-1)])
-             memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
-             if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
-                 batch = memory.sample(batch_size)
-@@ -320,7 +286,7 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 act_loss.append(a_loss)
-             episode_reward += reward
-             state = next_state
--            if done == env.Done:
-+            if done:
-                 break
-             ########## END OF YOUR CODE ########## 
-         
-@@ -330,23 +296,24 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-         critic_loss = np.mean(val_loss)
-         t = 0
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
-         episode_reward = 0
-         while True:
-             action = agent.select_action(state)
- 
--            next_state, reward, done, _ = env.step(action.numpy()[0])
-+            next_state, reward, done, info = env.step(action)
-             
-             #env.render()
-             
-             episode_reward += reward
- 
--            next_state = torch.Tensor([next_state])
-+            next_state = torch.Tensor([next_state.reshape(-1)])
- 
-             state = next_state
-             
-             t += 1
-             if done:
-+                print(info)
-                 break
- 
-         rewards.append(episode_reward)
-@@ -358,36 +325,22 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
- 
-         #Logging
--        writer.add_scalar('Reward', episode_reward, i_episode)
--        writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
--        writer.add_scalar('Critic loss', critic_loss, i_episode)
--        writer.add_scalar('Actor loss', actor_loss, i_episode)
--
--        if ewma_reward >= 120:
--            agent.save_model(env_name, '.pth')
--            logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--            #break
--            return (ewma_reward+500)/(i_episode+1) #For tuning
-+        #writer.add_scalar('Reward', episode_reward, i_episode)
-+        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
-+        #writer.add_scalar('Critic loss', critic_loss, i_episode)
-+        #writer.add_scalar('Actor loss', actor_loss, i_episode)
-+
-+        #if ewma_reward >= 120:
-+        #    agent.save_model(env_name, '.pth')
-+        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-+        #    #break
-+        #    return (ewma_reward+500)/(i_episode+1) #For tuning
-     
-     agent.save_model(env_name, '.pth')  
-     logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-     return (ewma_reward+500)/(i_episode+1) #For tuning
- 
- def main():
--    """
--    Market environment args 
--    """
--    #mode = args.mode
--    mode = 'test'
--    # codes = args.codes
--    codes = ["2303"]
--    # market = args.market
--    market = 'stock'
--    # episode = args.episode
--    episode = 1000
--    training_data_ratio = 0.95
--    # training_data_ratio = args.training_data_ratio
--
-     """
-     Training args
-     """
-@@ -398,14 +351,8 @@ def main():
-     noise_scale_ = 0.3
-     batch_size_ = 64
- 
--    model_name = os.path.basename(__file__).split('.')[0]
- 
--    env = Market(codes, start_date="2012-01-01", end_date="2018-01-01", **{
--        "market": market,
--        "mix_index_state": False,
--        "logger": generate_market_logger(model_name),
--        "training_data_ratio": training_data_ratio,
--    })
-+    env = createEnv(2330)
- 
-     train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
- if __name__ == '__main__':
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index f06654a..235e6e8 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -12,15 +12,19 @@ parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
- sys.path.insert(0, parent_dir)
- import trajectory.utils as utils
- import trajectory.datasets as datasets
-+from trajectory.datasets.Random.buildEnv import createEnv
- from trajectory.search import (
-     beam_plan,
-     make_prefix,
-     extract_actions,
-     update_context,
- )
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '3'
- 
-+code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stock_'+code
-     config: str = 'config.offline'
- 
- #######################
-@@ -43,7 +47,8 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
- ####### dataset #######
- #######################
- 
--env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
-+
-+env = createEnv(code)
- #renderer = utils.make_renderer(args)
- timer = utils.timer.Timer()
- 
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index 6ef5569..bb35461 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stocks-v0_r'
-+    dataset: str = 'stock_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 5000
-+n_epochs = 10000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index 659bd84..28c9f58 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -5,9 +5,12 @@ from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
- import matplotlib.pyplot as plt
- import numpy as np
- import pickle
-+import os
-+import sys
-+from buildEnv import createEnv
- 
--quat_type = "stocks-v0"
--env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-+quat_type = 2330
-+env = createEnv(2330)
- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- 
- action_dim = env.action_space.n
-@@ -20,11 +23,11 @@ for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals'
- for _ in range(episode):
-     observation = env.reset()
-     while True:
--        action = np.random.rand(action_dim)
--        next_observation, reward, done, _ = env.step(np.argmax(action))
-+        action = env.action_space.sample()
-+        next_observation, reward, done, _ = env.step(action)
-         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
-         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--        episode_data['actions'].append(action)
-+        episode_data['actions'].append(np.array([action]))
-         episode_data['rewards'].append(np.array([reward]).astype('float32'))
-         episode_data['terminals'].append(done)
-         if done:
-@@ -32,5 +35,5 @@ for _ in range(episode):
- 
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
-+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
-     pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 4525194..bd75e78 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -44,7 +44,7 @@ def segment(observations, terminals, max_path_length):
- 
- class SequenceDataset(torch.utils.data.Dataset):
- 
--    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=1000, penalty=None, device='cuda:0'):
-+    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=2000, penalty=None, device='cuda:0'):
-         print(f'[ datasets/sequence ] Sequence length: {sequence_length} | Step: {step} | Max path length: {max_path_length}')
-         #self.env = env = load_environment(env) if type(env) is str else env
-         self.sequence_length = sequence_length
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-index 6c69f6b..c30ee70 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-@@ -1,244 +1,71 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 1dd7eb6..98c4875 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -17,7 +17,7 @@ args_to_watch = [
-- base = {
-- 
--     'train': {
---        'N': 100,
--+        'N': 20,
--         'discount': 0.99,
--         'n_layer': 4,
--         'n_head': 4,
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index 881688c..f06654a 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -1,10 +1,15 @@
-- import json
-- import pdb
--+import os
--+import sys
-- from os.path import join
-- import gym
-- import gym_anytrading
--+import numpy as np
-- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
-- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.search import (
--@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- #######################
-- 
-- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
---renderer = utils.make_renderer(args)
--+#renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
-- discretizer = dataset.discretizer
--@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
-- action_dim = dataset.action_dim
-- 
-- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
---preprocess_fn = datasets.get_preprocess_fn(env.name)
--+#preprocess_fn = datasets.get_preprocess_fn(env.name)
-- 
-- #######################
-- ###### main loop ######
--@@ -63,10 +68,11 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = env.max_episode_steps
--+T = 1000000
-- for t in range(T):
-- 
---    observation = preprocess_fn(observation)
--+    #observation = preprocess_fn(observation)
--+    observation = observation.reshape(-1)
-- 
--     if t % args.plan_freq == 0:
--         ## concatenate previous transitions and current observations to input to model
--@@ -90,18 +96,18 @@ for t in range(T):
--     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
-- 
--     ## execute action in environment
---    next_observation, reward, terminal, _ = env.step(action)
--+    next_observation, reward, terminal, info = env.step(np.argmax(action))
-- 
--     ## update return
--     total_reward += reward
---    score = env.get_normalized_score(total_reward)
--+    #score = env.get_normalized_score(total_reward)
-- 
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-- 
--     print(
---        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
--+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
-- 
--@@ -114,11 +120,13 @@ for t in range(T):
--     #    ## save rollout thus far
--     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
-- 
---    if terminal: break
--+    if terminal: 
--+        print(info)
--+        break
-- 
--     observation = next_observation
-- 
-- ## save result as a json file
-- json_path = join(args.savepath, 'rollout.json')
---json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
-- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index ddcda7a..9a2273b 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -2,11 +2,17 @@ import os
-- import numpy as np
-- import torch
-- import pdb
--+import sys
--+
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- 
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.models.transformers import GPT
-- 
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
--     dataset: str = 'forex-v0'
--@@ -31,7 +37,7 @@ dataset_config = utils.Config(
--     savepath=(args.savepath, 'data_config.pkl'),
--     env=args.dataset,
--     N=args.N,
---    penalty=args.termination_penalty,
--+    penalty=None,
--     sequence_length=sequence_length,
--     step=args.step,
--     discount=args.discount,
--@@ -104,7 +110,8 @@ trainer = trainer_config()
-- #######################
-- 
-- ## scale number of epochs to keep number of updates constant
---n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+n_epochs = 3000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
--deleted file mode 100644
--index fa97c75..0000000
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 71bfb7e..bbd08e4 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-- action_dim = env.action_space.n
-- 
-- episode = 10
---
--+T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = []
--@@ -25,13 +25,12 @@ for _ in range(episode):
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--         episode_data['actions'].append(action)
---        episode_data['rewards'].append(np.array(reward).astype('float32'))
--+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--             break
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---
---with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
--diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
--index 69ee58d..d1062c5 100644
----- a/Trajectory_Transformer/trajectory/datasets/__init__.py
--+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
--@@ -1,3 +1,3 @@
---from .d4rl import load_environment
--+#from .d4rl import load_environment
-- from .sequence import *
-- from .preprocessing import get_preprocess_fn
--diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index c23b4f3..4525194 100644
----- a/Trajectory_Transformer/trajectory/datasets/sequence.py
--+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
--         self.device = device
--         
--         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
---        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
--+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
--             dataset = pickle.load(f)
--         print('✓')
-- 
--@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
--         terminals = dataset['terminals']
--         realterminals = [False]*len(dataset['terminals'])
-- 
---        #observations = np.reshape(observations, (100, 7000))
--         self.observations_raw = observations
--         self.actions_raw = actions
--         self.next_observations_raw = next_observations
--diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
--index 7c596c3..7529384 100644
----- a/Trajectory_Transformer/trajectory/utils/__init__.py
--+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
--@@ -2,7 +2,7 @@ from .setup import Parser, watch
-- from .arrays import *
-- from .serialization import *
-- from .progress import Progress, Silent
---from .rendering import make_renderer
--+#from .rendering import make_renderer
-- # from .video import *
-- from .config import Config
-- from .training import Trainer
--diff --git a/requirements.txt b/requirements.txt
--index ece16ed..a579177 100644
----- a/requirements.txt
--+++ b/requirements.txt
--@@ -1,14 +1,16 @@
-- numpy
-- gym
-- numpy
---torch
--+pytorch==1.12.1
--+torchvision==0.13.1 
--+torchaudio==0.12.1
-- transformers==4.5.1
-- wandb==0.9.1
-- tensorboard
-- pyprind
-- tensorflow
-- gin-config
---gym
--+gym==0.21.0
-- tqdm
-- blosc
-- git+https://github.com/google/dopamine.git
-\ No newline at end of file
-+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+index f42cef8..0e84897 100644
-+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+@@ -1,23 +1,23 @@
-+ {
-+     "add_extras": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+     },
-+     "beam_width": 128,
-+     "cdf_act": 0.6,
-+     "cdf_obs": null,
-+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "config": "config.offline",
-+     "dataset": "forex-v0",
-+     "device": "cuda",
-+     "exp_name": "plans/defaults/freq1_H15_beam128",
-+     "generate_exp_name": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+     },
-+     "get_commit": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+     },
-+     "gpt_epoch": "latest",
-+     "gpt_loadpath": "gpt/azure",
-+@@ -28,7 +28,7 @@
-+     "max_context_transitions": 5,
-+     "mkdir": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+     },
-+     "n_expand": 2,
-+     "percentile": "mean",
-+@@ -37,24 +37,24 @@
-+     "prefix_context": true,
-+     "read_config": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+     },
-+     "renderer": "Renderer",
-+     "reproducibility": {
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "git_has_uncommitted_changes": true,
-+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-+-        "time": "Sun May 14 00:30:59 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-++        "time": "Tue May 16 00:22:08 2023"
-+     },
-+     "save_diff": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+     },
-+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "set_seed": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+     },
-+     "suffix": "0",
-+     "verbose": true,
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
-deleted file mode 100644
-index 59fc81f..0000000
---- a/logs/stocks-v0_r/gpt/azure/args.json
-+++ /dev/null
-@@ -1,65 +0,0 @@
--{
--    "N": 20,
--    "action_weight": 5,
--    "add_extras": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
--    },
--    "attn_pdrop": 0.1,
--    "batch_size": 64,
--    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
--    "config": "config.offline",
--    "dataset": "stocks-v0_r",
--    "device": "cuda",
--    "discount": 0.99,
--    "discretizer": "QuantileDiscretizer",
--    "embd_pdrop": 0.1,
--    "exp_name": "gpt/azure",
--    "generate_exp_name": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
--    },
--    "get_commit": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
--    },
--    "learning_rate": 0.0006,
--    "logbase": "logs/",
--    "lr_decay": true,
--    "mkdir": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
--    },
--    "n_embd": 32,
--    "n_epochs_ref": 50,
--    "n_head": 4,
--    "n_layer": 4,
--    "n_saves": 3,
--    "read_config": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
--    },
--    "reproducibility": {
--        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
--        "git_has_uncommitted_changes": true,
--        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
--        "time": "Mon May 15 17:39:32 2023"
--    },
--    "resid_pdrop": 0.1,
--    "reward_weight": 1,
--    "save_diff": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
--    },
--    "savepath": "logs/stocks-v0_r/gpt/azure",
--    "seed": 42,
--    "set_seed": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
--    },
--    "step": 1,
--    "subsampled_sequence_length": 10,
--    "termination_penalty": -100,
--    "value_weight": 1
--}
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
-deleted file mode 100644
-index f2b7eea..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
-deleted file mode 100644
-index 7d861b1..0000000
---- a/logs/stocks-v0_r/gpt/azure/diff.txt
-+++ /dev/null
-@@ -1,59 +0,0 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 98c4875..9a7a974 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -29,7 +29,7 @@ base = {
--         'device': 'cuda',
-- 
--         'n_embd': 32,
---        'batch_size': 256,
--+        'batch_size': 64,
--         'learning_rate': 6e-4,
--         'lr_decay': True,
--         'seed': 42,
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 9a2273b..6ef5569 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stocks-v0_r'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 3000
--+n_epochs = 5000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
--index 506330f..e08063c 100644
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index bbd08e4..659bd84 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
-- 
---quat_type = "forex-v0"
---env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = "stocks-v0"
--+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
-- 
---episode = 10
--+episode = 100
-- T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
-deleted file mode 100644
-index db868c9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
-deleted file mode 100644
-index aaacded..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
-deleted file mode 100644
-index c3fe2b4..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
-deleted file mode 100644
-index f13edba..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
-deleted file mode 100644
-index 5531c7d..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
-deleted file mode 100644
-index 090ede9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
-diff --git a/old_env/trader.py b/old_env/trader.py
-index 7937f12..6b2f29c 100644
---- a/old_env/trader.py
-+++ b/old_env/trader.py
-@@ -4,7 +4,7 @@ import math
- 
- from time import time
- from enum import Enum
--from env.position import Position
-+from position import Position
- 
- 
- class ActionCode(Enum):
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json b/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json
deleted file mode 100644
index fb2a49c..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoOoaUUpQu"
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "07ba73fabf0dbe6d230206e88dab1d3f87af81b2 main",
-    "config": "config.offline",
-    "dataset": "stock_2330",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H4_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoKoaUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoD4aUUpQu"
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 4,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoJ4aUUpQu"
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoNIaUUpQu"
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/07ba73fabf0dbe6d230206e88dab1d3f87af81b2",
-        "time": "Tue May 16 17:21:43 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoGoaUUpQu"
-    },
-    "savepath": "logs/stock_2330/plans/defaults/freq1_H4_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBWtfb2JzlEsBjAhleHBfbmFtZZSMH3BsYW5zL2RlZmF1bHRzL2ZyZXExX0g0X2JlYW0xMjiUjAdkYXRhc2V0lIwKc3RvY2tfMjMzMJSMDnByZWZpeF9jb250ZXh0lIiMB3ZlcmJvc2WUiIwKZ2V0X2NvbW1pdJRoAmgGaA+GlFKUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwJcGxhbl9mcmVxlEsBjAVrX2FjdJROjAZzdWZmaXiUjAEwlIwGY29tbWl0lIwtMDdiYTczZmFiZjBkYmU2ZDIzMDIwNmU4OGRhYjFkM2Y4N2FmODFiMiBtYWlulIwJc2F2ZV9kaWZmlGgCaAZoGoaUUpSMB2NkZl9vYnOUTowIc2F2ZXBhdGiUjDFsb2dzL3N0b2NrXzIzMzAvcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDRfYmVhbTEyOC8wlIwHY2RmX2FjdJRHP+MzMzMzMzOMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAdob3Jpem9ulEsEjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwFbWtkaXKUaAJoBmgnhpRSlIwRZ2VuZXJhdGVfZXhwX25hbWWUaAJoBmgqhpRSlIwJZ3B0X2Vwb2NolIwGbGF0ZXN0lIwGY29uZmlnlIwOY29uZmlnLm9mZmxpbmWUjApwZXJjZW50aWxllIwEbWVhbpSMCHZpc19mcmVxlEsyjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwKYWRkX2V4dHJhc5RoAmgGaDqGlFKUjApiZWFtX3dpZHRolEuAjAdsb2diYXNllIwFbG9ncy+UjAhzZXRfc2VlZJRoAmgGaECGlFKUdWJoQIaUUpQu"
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt b/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt
deleted file mode 100644
index 3528290..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/diff.txt
+++ /dev/null
@@ -1,955 +0,0 @@
-diff --git a/DDPG.py b/DDPG.py
-index d682b97..c69f550 100644
---- a/DDPG.py
-+++ b/DDPG.py
-@@ -1,6 +1,3 @@
--from env.market import Market
--from helper.args_parser import model_launcher_parser
--from helper.data_logger import generate_algorithm_logger, generate_market_logger
- import sys
- import gym
- import numpy as np
-@@ -15,12 +12,15 @@ from torch.autograd import Variable
- import torch.optim.lr_scheduler as Scheduler
- import torch.nn.functional as F
- from torch.utils.tensorboard import SummaryWriter
-+from buildEnv import createEnv, MyStocksEnv
-+from torch.distributions import Categorical
- import logging
- #from skopt.space import Real, Integer
- #from skopt import gp_minimize
- logging.basicConfig(filename='train.log', level=logging.DEBUG)
- 
--
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- def soft_update(target, source, tau):
-     for target_param, param in zip(target.parameters(), source.parameters()):
-         target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)
-@@ -153,46 +153,16 @@ class DDPG(object):
-         hard_update(self.actor_target, self.actor) 
-         hard_update(self.critic_target, self.critic)
- 
--    def get_stock_code_and_action(self, a, use_greedy=False, use_prob=False):
--        # Reshape a.
--        if not use_greedy:
--            a = a.reshape((-1,))
--            # Calculate action index depends on prob.
--            if use_prob:
--                # Generate indices.
--                a_indices = np.arange(a.shape[0])
--                # Get action index.
--                action_index = np.random.choice(a_indices, p=a)
--            else:
--                # Get action index.
--                action_index = np.argmax(a)
--        else:
--            if use_prob:
--                # Calculate action index
--                if np.random.uniform() < self.epsilon:
--                    action_index = np.floor(a).astype(int)
--                else:
--                    action_index = np.random.randint(0, self.action_space)
--            else:
--                # Calculate action index
--                action_index = np.floor(a).astype(int)
--
--        # Get action
--        action = action_index % 3
--        # Get stock index
--        stock_index = np.floor(action_index / 3).astype(np.int)
--        # Get stock code.
--        stock_code = self.env.codes[stock_index]
--
--        return stock_code, action, action_index
--
--    def select_action(self, state, action_noise=None):
-+
-+    def select_action(self, state, epsilon=0.0):
-         self.actor.eval()
--        mu = self.actor((Variable(state)))
--        mu = mu.data
--        noise = [0.0] if action_noise is None else action_noise.noise()
--        noise = torch.FloatTensor(noise)
--        return torch.clamp(mu + noise, min=0, max=1.0)
-+        probs = self.actor((Variable(state)))
-+        probs = probs.detach()
-+        m = Categorical(logits= probs)
-+        action = m.sample().item()
-+        if random.random() > epsilon:
-+            return self.env.action_space.sample()
-+        return action
- 
-     def update_parameters(self, batch):
-         state_batch = Variable(torch.cat([b.state for b in batch]))
-@@ -201,7 +171,6 @@ class DDPG(object):
-         mask_batch = Variable(torch.cat([b.mask for b in batch]))
-         next_state_batch = Variable(torch.cat([b.next_state for b in batch]))
-         
--        ########## YOUR CODE HERE (10~20 lines) ##########
-         # Calculate policy loss and value loss
-         # Update the actor and the critic
-         q_v = self.critic(state_batch, action_batch)
-@@ -219,7 +188,6 @@ class DDPG(object):
-         self.actor_optim.zero_grad()
-         policy_loss.backward()
-         self.actor_optim.step()
--        ########## END OF YOUR CODE ########## 
- 
-         soft_update(self.actor_target, self.actor, self.tau)
-         soft_update(self.critic_target, self.critic, self.tau)
-@@ -248,9 +216,9 @@ class DDPG(object):
-         if critic_path is not None: 
-             self.critic.load_state_dict(torch.load(critic_path))
- 
--def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-+def train(env:MyStocksEnv, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_ , env_name = 'Stock_Market'):   
-     # Define a tensorboard writer
--    writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
-+    #writer = SummaryWriter("./tb_record_3/DDPG/train-{}-{}".format(lr_a_, lr_c_))
- 
-     logging.info('lr_a = {}, lr_c = {} , lr_a_decay={} , lr_c_decay={}, noise_scale = {} , batch_size = {}'.format(
-         lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_))
-@@ -276,9 +244,8 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-     total_numsteps = 0
-     updates = 0
- 
--    
--    agent = DDPG(num_inputs = env.data_dim,
--                 action_space = env.trader.action_space, 
-+    agent = DDPG(num_inputs = env.reset().reshape(-1).shape[0],
-+                 action_space = env.action_space.n, 
-                  env = env, 
-                  epsilon= epsilon,
-                  gamma = gamma, 
-@@ -288,15 +255,15 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 lr_c= lr_c, 
-                 lr_a_decay= lr_a_decay, 
-                 lr_c_decay = lr_c_decay)
--    ounoise = OUNoise(env.trader.action_space)
-+    #ounoise = OUNoise(env.action_space)
-     memory = ReplayMemory(replay_size)
-     
-     for i_episode in range(num_episodes):
-         
--        ounoise.scale = noise_scale
--        ounoise.reset()
-+        #ounoise.scale = noise_scale
-+        #ounoise.reset()
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
- 
-         episode_reward = 0
-         val_loss = []
-@@ -308,10 +275,9 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             # 2. Push the sample to the replay buffer
-             # 3. Update the actor and the critic
-             total_numsteps+=1
--            action = agent.select_action(state, ounoise)
--            code, action, a_index= agent.get_stock_code_and_action(action, use_greedy=False, use_prob=True)
--            next_state, reward, done, _ = env.forward(code, action)
--            next_state = torch.Tensor([next_state])
-+            action = agent.select_action(state, epsilon)
-+            next_state, reward, done, info = env.step(action)
-+            next_state = torch.Tensor([next_state.reshape(-1)])
-             memory.push(state, action, torch.Tensor([done]), next_state, torch.Tensor([reward]))
-             if len(memory) >= batch_size and total_numsteps%updates_per_step == 0:
-                 batch = memory.sample(batch_size)
-@@ -320,7 +286,7 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-                 act_loss.append(a_loss)
-             episode_reward += reward
-             state = next_state
--            if done == env.Done:
-+            if done:
-                 break
-             ########## END OF YOUR CODE ########## 
-         
-@@ -330,23 +296,24 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-         critic_loss = np.mean(val_loss)
-         t = 0
-         
--        state = torch.Tensor([env.reset()])
-+        state = torch.Tensor([env.reset().reshape(-1)])
-         episode_reward = 0
-         while True:
-             action = agent.select_action(state)
- 
--            next_state, reward, done, _ = env.step(action.numpy()[0])
-+            next_state, reward, done, info = env.step(action)
-             
-             #env.render()
-             
-             episode_reward += reward
- 
--            next_state = torch.Tensor([next_state])
-+            next_state = torch.Tensor([next_state.reshape(-1)])
- 
-             state = next_state
-             
-             t += 1
-             if done:
-+                print(info)
-                 break
- 
-         rewards.append(episode_reward)
-@@ -358,36 +325,22 @@ def train(env: Market, lr_a_, lr_c_, lr_a_decay_, lr_c_decay_, noise_scale_, bat
-             logging.info("Episode: {}, length: {}, reward: {:.2f}, ewma reward: {:.2f}, val loss: {:.2f}, act loss: {:.2f}".format(i_episode, t, rewards[-1], ewma_reward, critic_loss, actor_loss))
- 
-         #Logging
--        writer.add_scalar('Reward', episode_reward, i_episode)
--        writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
--        writer.add_scalar('Critic loss', critic_loss, i_episode)
--        writer.add_scalar('Actor loss', actor_loss, i_episode)
--
--        if ewma_reward >= 120:
--            agent.save_model(env_name, '.pth')
--            logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
--            #break
--            return (ewma_reward+500)/(i_episode+1) #For tuning
-+        #writer.add_scalar('Reward', episode_reward, i_episode)
-+        #writer.add_scalar('EWMA Reward', ewma_reward, i_episode)
-+        #writer.add_scalar('Critic loss', critic_loss, i_episode)
-+        #writer.add_scalar('Actor loss', actor_loss, i_episode)
-+
-+        #if ewma_reward >= 120:
-+        #    agent.save_model(env_name, '.pth')
-+        #    logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-+        #    #break
-+        #    return (ewma_reward+500)/(i_episode+1) #For tuning
-     
-     agent.save_model(env_name, '.pth')  
-     logging.info("Running reward is now {} and the total episode is {}.".format(ewma_reward, i_episode))
-     return (ewma_reward+500)/(i_episode+1) #For tuning
- 
- def main():
--    """
--    Market environment args 
--    """
--    #mode = args.mode
--    mode = 'test'
--    # codes = args.codes
--    codes = ["2303"]
--    # market = args.market
--    market = 'stock'
--    # episode = args.episode
--    episode = 1000
--    training_data_ratio = 0.95
--    # training_data_ratio = args.training_data_ratio
--
-     """
-     Training args
-     """
-@@ -398,14 +351,8 @@ def main():
-     noise_scale_ = 0.3
-     batch_size_ = 64
- 
--    model_name = os.path.basename(__file__).split('.')[0]
- 
--    env = Market(codes, start_date="2012-01-01", end_date="2018-01-01", **{
--        "market": market,
--        "mix_index_state": False,
--        "logger": generate_market_logger(model_name),
--        "training_data_ratio": training_data_ratio,
--    })
-+    env = createEnv(2330)
- 
-     train(env, lr_a, lr_c, lr_a_decay_, lr_c_decay_, noise_scale_, batch_size_)
- if __name__ == '__main__':
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 9a7a974..f6720ba 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -57,7 +57,7 @@ base = {
-         'renderer': 'Renderer',
- 
-         'plan_freq': 1,
--        'horizon': 15,
-+        'horizon': 4,
-         'beam_width': 128,
-         'n_expand': 2,
- 
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index f06654a..657b490 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -12,15 +12,19 @@ parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
- sys.path.insert(0, parent_dir)
- import trajectory.utils as utils
- import trajectory.datasets as datasets
-+from trajectory.datasets.Random.buildEnv import createEnv
- from trajectory.search import (
-     beam_plan,
-     make_prefix,
-     extract_actions,
-     update_context,
- )
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '1'
- 
-+code = '2330'
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stock_'+code
-     config: str = 'config.offline'
- 
- #######################
-@@ -43,7 +47,8 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
- ####### dataset #######
- #######################
- 
--env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
-+
-+env = createEnv(code)
- #renderer = utils.make_renderer(args)
- timer = utils.timer.Timer()
- 
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index 6ef5569..bb35461 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'stocks-v0_r'
-+    dataset: str = 'stock_2330'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 5000
-+n_epochs = 10000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index 659bd84..28c9f58 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -5,9 +5,12 @@ from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
- import matplotlib.pyplot as plt
- import numpy as np
- import pickle
-+import os
-+import sys
-+from buildEnv import createEnv
- 
--quat_type = "stocks-v0"
--env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-+quat_type = 2330
-+env = createEnv(2330)
- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- 
- action_dim = env.action_space.n
-@@ -20,11 +23,11 @@ for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals'
- for _ in range(episode):
-     observation = env.reset()
-     while True:
--        action = np.random.rand(action_dim)
--        next_observation, reward, done, _ = env.step(np.argmax(action))
-+        action = env.action_space.sample()
-+        next_observation, reward, done, _ = env.step(action)
-         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
-         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--        episode_data['actions'].append(action)
-+        episode_data['actions'].append(np.array([action]))
-         episode_data['rewards'].append(np.array([reward]).astype('float32'))
-         episode_data['terminals'].append(done)
-         if done:
-@@ -32,5 +35,5 @@ for _ in range(episode):
- 
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-     episode_data[k] = np.stack(episode_data[k])
--with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
-+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/stock_{}'.format(quat_type) + '.pkl', 'wb') as f:
-     pickle.dump(episode_data, f)
-\ No newline at end of file
-diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
-index 4525194..bd75e78 100644
---- a/Trajectory_Transformer/trajectory/datasets/sequence.py
-+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
-@@ -44,7 +44,7 @@ def segment(observations, terminals, max_path_length):
- 
- class SequenceDataset(torch.utils.data.Dataset):
- 
--    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=1000, penalty=None, device='cuda:0'):
-+    def __init__(self, env, sequence_length=250, step=10, discount=0.99, max_path_length=2000, penalty=None, device='cuda:0'):
-         print(f'[ datasets/sequence ] Sequence length: {sequence_length} | Step: {step} | Max path length: {max_path_length}')
-         #self.env = env = load_environment(env) if type(env) is str else env
-         self.sequence_length = sequence_length
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-index 6c69f6b..c30ee70 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-@@ -1,244 +1,71 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 1dd7eb6..98c4875 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -17,7 +17,7 @@ args_to_watch = [
-- base = {
-- 
--     'train': {
---        'N': 100,
--+        'N': 20,
--         'discount': 0.99,
--         'n_layer': 4,
--         'n_head': 4,
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index 881688c..f06654a 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -1,10 +1,15 @@
-- import json
-- import pdb
--+import os
--+import sys
-- from os.path import join
-- import gym
-- import gym_anytrading
--+import numpy as np
-- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
-- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.search import (
--@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- #######################
-- 
-- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
---renderer = utils.make_renderer(args)
--+#renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
-- discretizer = dataset.discretizer
--@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
-- action_dim = dataset.action_dim
-- 
-- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
---preprocess_fn = datasets.get_preprocess_fn(env.name)
--+#preprocess_fn = datasets.get_preprocess_fn(env.name)
-- 
-- #######################
-- ###### main loop ######
--@@ -63,10 +68,11 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = env.max_episode_steps
--+T = 1000000
-- for t in range(T):
-- 
---    observation = preprocess_fn(observation)
--+    #observation = preprocess_fn(observation)
--+    observation = observation.reshape(-1)
-- 
--     if t % args.plan_freq == 0:
--         ## concatenate previous transitions and current observations to input to model
--@@ -90,18 +96,18 @@ for t in range(T):
--     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
-- 
--     ## execute action in environment
---    next_observation, reward, terminal, _ = env.step(action)
--+    next_observation, reward, terminal, info = env.step(np.argmax(action))
-- 
--     ## update return
--     total_reward += reward
---    score = env.get_normalized_score(total_reward)
--+    #score = env.get_normalized_score(total_reward)
-- 
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-- 
--     print(
---        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
--+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
-- 
--@@ -114,11 +120,13 @@ for t in range(T):
--     #    ## save rollout thus far
--     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
-- 
---    if terminal: break
--+    if terminal: 
--+        print(info)
--+        break
-- 
--     observation = next_observation
-- 
-- ## save result as a json file
-- json_path = join(args.savepath, 'rollout.json')
---json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
-- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index ddcda7a..9a2273b 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -2,11 +2,17 @@ import os
-- import numpy as np
-- import torch
-- import pdb
--+import sys
--+
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- 
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.models.transformers import GPT
-- 
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
--     dataset: str = 'forex-v0'
--@@ -31,7 +37,7 @@ dataset_config = utils.Config(
--     savepath=(args.savepath, 'data_config.pkl'),
--     env=args.dataset,
--     N=args.N,
---    penalty=args.termination_penalty,
--+    penalty=None,
--     sequence_length=sequence_length,
--     step=args.step,
--     discount=args.discount,
--@@ -104,7 +110,8 @@ trainer = trainer_config()
-- #######################
-- 
-- ## scale number of epochs to keep number of updates constant
---n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+n_epochs = 3000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
--deleted file mode 100644
--index fa97c75..0000000
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 71bfb7e..bbd08e4 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-- action_dim = env.action_space.n
-- 
-- episode = 10
---
--+T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = []
--@@ -25,13 +25,12 @@ for _ in range(episode):
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--         episode_data['actions'].append(action)
---        episode_data['rewards'].append(np.array(reward).astype('float32'))
--+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--             break
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---
---with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
--diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
--index 69ee58d..d1062c5 100644
----- a/Trajectory_Transformer/trajectory/datasets/__init__.py
--+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
--@@ -1,3 +1,3 @@
---from .d4rl import load_environment
--+#from .d4rl import load_environment
-- from .sequence import *
-- from .preprocessing import get_preprocess_fn
--diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index c23b4f3..4525194 100644
----- a/Trajectory_Transformer/trajectory/datasets/sequence.py
--+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
--         self.device = device
--         
--         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
---        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
--+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
--             dataset = pickle.load(f)
--         print('✓')
-- 
--@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
--         terminals = dataset['terminals']
--         realterminals = [False]*len(dataset['terminals'])
-- 
---        #observations = np.reshape(observations, (100, 7000))
--         self.observations_raw = observations
--         self.actions_raw = actions
--         self.next_observations_raw = next_observations
--diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
--index 7c596c3..7529384 100644
----- a/Trajectory_Transformer/trajectory/utils/__init__.py
--+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
--@@ -2,7 +2,7 @@ from .setup import Parser, watch
-- from .arrays import *
-- from .serialization import *
-- from .progress import Progress, Silent
---from .rendering import make_renderer
--+#from .rendering import make_renderer
-- # from .video import *
-- from .config import Config
-- from .training import Trainer
--diff --git a/requirements.txt b/requirements.txt
--index ece16ed..a579177 100644
----- a/requirements.txt
--+++ b/requirements.txt
--@@ -1,14 +1,16 @@
-- numpy
-- gym
-- numpy
---torch
--+pytorch==1.12.1
--+torchvision==0.13.1 
--+torchaudio==0.12.1
-- transformers==4.5.1
-- wandb==0.9.1
-- tensorboard
-- pyprind
-- tensorflow
-- gin-config
---gym
--+gym==0.21.0
-- tqdm
-- blosc
-- git+https://github.com/google/dopamine.git
-\ No newline at end of file
-+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+index f42cef8..0e84897 100644
-+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+@@ -1,23 +1,23 @@
-+ {
-+     "add_extras": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+     },
-+     "beam_width": 128,
-+     "cdf_act": 0.6,
-+     "cdf_obs": null,
-+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "config": "config.offline",
-+     "dataset": "forex-v0",
-+     "device": "cuda",
-+     "exp_name": "plans/defaults/freq1_H15_beam128",
-+     "generate_exp_name": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+     },
-+     "get_commit": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+     },
-+     "gpt_epoch": "latest",
-+     "gpt_loadpath": "gpt/azure",
-+@@ -28,7 +28,7 @@
-+     "max_context_transitions": 5,
-+     "mkdir": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+     },
-+     "n_expand": 2,
-+     "percentile": "mean",
-+@@ -37,24 +37,24 @@
-+     "prefix_context": true,
-+     "read_config": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+     },
-+     "renderer": "Renderer",
-+     "reproducibility": {
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "git_has_uncommitted_changes": true,
-+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-+-        "time": "Sun May 14 00:30:59 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-++        "time": "Tue May 16 00:22:08 2023"
-+     },
-+     "save_diff": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+     },
-+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "set_seed": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+     },
-+     "suffix": "0",
-+     "verbose": true,
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
-deleted file mode 100644
-index 59fc81f..0000000
---- a/logs/stocks-v0_r/gpt/azure/args.json
-+++ /dev/null
-@@ -1,65 +0,0 @@
--{
--    "N": 20,
--    "action_weight": 5,
--    "add_extras": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
--    },
--    "attn_pdrop": 0.1,
--    "batch_size": 64,
--    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
--    "config": "config.offline",
--    "dataset": "stocks-v0_r",
--    "device": "cuda",
--    "discount": 0.99,
--    "discretizer": "QuantileDiscretizer",
--    "embd_pdrop": 0.1,
--    "exp_name": "gpt/azure",
--    "generate_exp_name": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
--    },
--    "get_commit": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
--    },
--    "learning_rate": 0.0006,
--    "logbase": "logs/",
--    "lr_decay": true,
--    "mkdir": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
--    },
--    "n_embd": 32,
--    "n_epochs_ref": 50,
--    "n_head": 4,
--    "n_layer": 4,
--    "n_saves": 3,
--    "read_config": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
--    },
--    "reproducibility": {
--        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
--        "git_has_uncommitted_changes": true,
--        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
--        "time": "Mon May 15 17:39:32 2023"
--    },
--    "resid_pdrop": 0.1,
--    "reward_weight": 1,
--    "save_diff": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
--    },
--    "savepath": "logs/stocks-v0_r/gpt/azure",
--    "seed": 42,
--    "set_seed": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
--    },
--    "step": 1,
--    "subsampled_sequence_length": 10,
--    "termination_penalty": -100,
--    "value_weight": 1
--}
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
-deleted file mode 100644
-index f2b7eea..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
-deleted file mode 100644
-index 7d861b1..0000000
---- a/logs/stocks-v0_r/gpt/azure/diff.txt
-+++ /dev/null
-@@ -1,59 +0,0 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 98c4875..9a7a974 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -29,7 +29,7 @@ base = {
--         'device': 'cuda',
-- 
--         'n_embd': 32,
---        'batch_size': 256,
--+        'batch_size': 64,
--         'learning_rate': 6e-4,
--         'lr_decay': True,
--         'seed': 42,
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 9a2273b..6ef5569 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stocks-v0_r'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 3000
--+n_epochs = 5000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
--index 506330f..e08063c 100644
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index bbd08e4..659bd84 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
-- 
---quat_type = "forex-v0"
---env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = "stocks-v0"
--+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
-- 
---episode = 10
--+episode = 100
-- T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
-deleted file mode 100644
-index db868c9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
-deleted file mode 100644
-index aaacded..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
-deleted file mode 100644
-index c3fe2b4..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
-deleted file mode 100644
-index f13edba..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
-deleted file mode 100644
-index 5531c7d..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
-deleted file mode 100644
-index 090ede9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
-diff --git a/old_env/trader.py b/old_env/trader.py
-index 7937f12..6b2f29c 100644
---- a/old_env/trader.py
-+++ b/old_env/trader.py
-@@ -4,7 +4,7 @@ import math
- 
- from time import time
- from enum import Enum
--from env.position import Position
-+from position import Position
- 
- 
- class ActionCode(Enum):
\ No newline at end of file
diff --git a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/rollout.json b/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/rollout.json
deleted file mode 100644
index 31c07a8..0000000
--- a/logs/stock_2330/plans/defaults/freq1_H4_beam128/0/rollout.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-  "gpt_epoch": 0,
-  "return": -149.0,
-  "step": 1186,
-  "term": true
-}
\ No newline at end of file
diff --git a/logs/stocks-v0/gpt/azure/args.json b/logs/stocks-v0/gpt/azure/args.json
deleted file mode 100644
index 59fc81f..0000000
--- a/logs/stocks-v0/gpt/azure/args.json
+++ /dev/null
@@ -1,65 +0,0 @@
-{
-    "N": 20,
-    "action_weight": 5,
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
-    },
-    "attn_pdrop": 0.1,
-    "batch_size": 64,
-    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
-    "config": "config.offline",
-    "dataset": "stocks-v0_r",
-    "device": "cuda",
-    "discount": 0.99,
-    "discretizer": "QuantileDiscretizer",
-    "embd_pdrop": 0.1,
-    "exp_name": "gpt/azure",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
-    },
-    "learning_rate": 0.0006,
-    "logbase": "logs/",
-    "lr_decay": true,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
-    },
-    "n_embd": 32,
-    "n_epochs_ref": 50,
-    "n_head": 4,
-    "n_layer": 4,
-    "n_saves": 3,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
-    },
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
-        "time": "Mon May 15 17:39:32 2023"
-    },
-    "resid_pdrop": 0.1,
-    "reward_weight": 1,
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
-    },
-    "savepath": "logs/stocks-v0_r/gpt/azure",
-    "seed": 42,
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
-    },
-    "step": 1,
-    "subsampled_sequence_length": 10,
-    "termination_penalty": -100,
-    "value_weight": 1
-}
\ No newline at end of file
diff --git a/logs/stocks-v0/gpt/azure/data_config.pkl b/logs/stocks-v0/gpt/azure/data_config.pkl
deleted file mode 100644
index f2b7eea..0000000
Binary files a/logs/stocks-v0/gpt/azure/data_config.pkl and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/diff.txt b/logs/stocks-v0/gpt/azure/diff.txt
deleted file mode 100644
index 7d861b1..0000000
--- a/logs/stocks-v0/gpt/azure/diff.txt
+++ /dev/null
@@ -1,59 +0,0 @@
-diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
-index 98c4875..9a7a974 100644
---- a/Trajectory_Transformer/config/offline.py
-+++ b/Trajectory_Transformer/config/offline.py
-@@ -29,7 +29,7 @@ base = {
-         'device': 'cuda',
- 
-         'n_embd': 32,
--        'batch_size': 256,
-+        'batch_size': 64,
-         'learning_rate': 6e-4,
-         'lr_decay': True,
-         'seed': 42,
-diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
-index 9a2273b..6ef5569 100644
---- a/Trajectory_Transformer/scripts/train.py
-+++ b/Trajectory_Transformer/scripts/train.py
-@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stocks-v0_r'
-     config: str = 'config.offline'
- 
- #######################
-@@ -111,7 +111,7 @@ trainer = trainer_config()
- 
- ## scale number of epochs to keep number of updates constant
- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--n_epochs = 3000
-+n_epochs = 5000
- save_freq = int(n_epochs // args.n_saves)
- 
- for epoch in range(n_epochs):
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
-index 506330f..e08063c 100644
-Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
-diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-index bbd08e4..659bd84 100644
---- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
-@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
- import numpy as np
- import pickle
- 
--quat_type = "forex-v0"
--env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-+quat_type = "stocks-v0"
-+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
- 
- action_dim = env.action_space.n
- 
--episode = 10
-+episode = 100
- T = 0
- episode_data = {}
- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
\ No newline at end of file
diff --git a/logs/stocks-v0/gpt/azure/model_config.pkl b/logs/stocks-v0/gpt/azure/model_config.pkl
deleted file mode 100644
index db868c9..0000000
Binary files a/logs/stocks-v0/gpt/azure/model_config.pkl and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/state_0.pt b/logs/stocks-v0/gpt/azure/state_0.pt
deleted file mode 100644
index aaacded..0000000
Binary files a/logs/stocks-v0/gpt/azure/state_0.pt and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/state_1666.pt b/logs/stocks-v0/gpt/azure/state_1666.pt
deleted file mode 100644
index c3fe2b4..0000000
Binary files a/logs/stocks-v0/gpt/azure/state_1666.pt and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/state_3332.pt b/logs/stocks-v0/gpt/azure/state_3332.pt
deleted file mode 100644
index f13edba..0000000
Binary files a/logs/stocks-v0/gpt/azure/state_3332.pt and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/state_4998.pt b/logs/stocks-v0/gpt/azure/state_4998.pt
deleted file mode 100644
index 5531c7d..0000000
Binary files a/logs/stocks-v0/gpt/azure/state_4998.pt and /dev/null differ
diff --git a/logs/stocks-v0/gpt/azure/trainer_config.pkl b/logs/stocks-v0/gpt/azure/trainer_config.pkl
deleted file mode 100644
index 090ede9..0000000
Binary files a/logs/stocks-v0/gpt/azure/trainer_config.pkl and /dev/null differ
diff --git a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/args.json
deleted file mode 100644
index d9b1c2e..0000000
--- a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/args.json
+++ /dev/null
@@ -1,62 +0,0 @@
-{
-    "add_extras": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoJ4aUUpQu"
-    },
-    "beam_width": 128,
-    "cdf_act": 0.6,
-    "cdf_obs": null,
-    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-    "config": "config.offline",
-    "dataset": "stocks-v0",
-    "device": "cuda",
-    "exp_name": "plans/defaults/freq1_H15_beam128",
-    "generate_exp_name": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoIoaUUpQu"
-    },
-    "get_commit": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoFYaUUpQu"
-    },
-    "gpt_epoch": "latest",
-    "gpt_loadpath": "gpt/azure",
-    "horizon": 15,
-    "k_act": null,
-    "k_obs": 1,
-    "logbase": "logs/",
-    "max_context_transitions": 5,
-    "mkdir": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoH4aUUpQu"
-    },
-    "n_expand": 2,
-    "percentile": "mean",
-    "plan_freq": 1,
-    "prefix": "plans/defaults/",
-    "prefix_context": true,
-    "read_config": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoGYaUUpQu"
-    },
-    "renderer": "Renderer",
-    "reproducibility": {
-        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-        "git_has_uncommitted_changes": true,
-        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-        "time": "Tue May 16 00:23:35 2023"
-    },
-    "save_diff": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoN4aUUpQu"
-    },
-    "savepath": "logs/stocks-v0/plans/defaults/freq1_H15_beam128/0",
-    "set_seed": {
-        "_type": "python_object (type = method)",
-        "_value": "gASVBAMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjAhzYXZlcGF0aJSMMWxvZ3Mvc3RvY2tzLXYwL3BsYW5zL2RlZmF1bHRzL2ZyZXExX0gxNV9iZWFtMTI4LzCUjAlncHRfZXBvY2iUjAZsYXRlc3SUjAxncHRfbG9hZHBhdGiUjAlncHQvYXp1cmWUjAhyZW5kZXJlcpSMCFJlbmRlcmVylIwHbG9nYmFzZZSMBWxvZ3MvlIwIbl9leHBhbmSUSwKMB2NkZl9vYnOUTowKZ2V0X2NvbW1pdJRoAmgGaBWGlFKUjAVrX2FjdJROjAtyZWFkX2NvbmZpZ5RoAmgGaBmGlFKUjAlwbGFuX2ZyZXGUSwGMBnN1ZmZpeJSMATCUjAVta2RpcpRoAmgGaB+GlFKUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCKGlFKUjApwZXJjZW50aWxllIwEbWVhbpSMCmFkZF9leHRyYXOUaAJoBmgnhpRSlIwKYmVhbV93aWR0aJRLgIwHaG9yaXpvbpRLD4wHZGF0YXNldJSMCXN0b2Nrcy12MJSMB2NkZl9hY3SURz/jMzMzMzMzjAd2ZXJib3NllIiMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwGY29tbWl0lIwtMTZmMjEyZjAxMDU5ZWQ2OGVlMzM3MzE4ZWNmYzRhNTdkMzFiZGNhNCBtYWlulIwIc2V0X3NlZWSUaAJoBmg0hpRSlIwJc2F2ZV9kaWZmlGgCaAZoN4aUUpSMBWtfb2JzlEsBjAZkZXZpY2WUjARjdWRhlIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMDnByZWZpeF9jb250ZXh0lIiMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHZpc19mcmVxlEsydWJoNIaUUpQu"
-    },
-    "suffix": "0",
-    "verbose": true,
-    "vis_freq": 50
-}
\ No newline at end of file
diff --git a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
deleted file mode 100644
index 10463ec..0000000
--- a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
+++ /dev/null
@@ -1,576 +0,0 @@
-diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
-index f06654a..04a6f48 100644
---- a/Trajectory_Transformer/scripts/plan.py
-+++ b/Trajectory_Transformer/scripts/plan.py
-@@ -18,9 +18,11 @@ from trajectory.search import (
-     extract_actions,
-     update_context,
- )
-+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
- 
- class Parser(utils.Parser):
--    dataset: str = 'forex-v0'
-+    dataset: str = 'stocks-v0'
-     config: str = 'config.offline'
- 
- #######################
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-index f42cef8..0e84897 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-@@ -1,23 +1,23 @@
- {
-     "add_extras": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-     },
-     "beam_width": 128,
-     "cdf_act": 0.6,
-     "cdf_obs": null,
--    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-+    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-     "config": "config.offline",
-     "dataset": "forex-v0",
-     "device": "cuda",
-     "exp_name": "plans/defaults/freq1_H15_beam128",
-     "generate_exp_name": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-     },
-     "get_commit": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-     },
-     "gpt_epoch": "latest",
-     "gpt_loadpath": "gpt/azure",
-@@ -28,7 +28,7 @@
-     "max_context_transitions": 5,
-     "mkdir": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-     },
-     "n_expand": 2,
-     "percentile": "mean",
-@@ -37,24 +37,24 @@
-     "prefix_context": true,
-     "read_config": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-     },
-     "renderer": "Renderer",
-     "reproducibility": {
-         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-         "git_has_uncommitted_changes": true,
-         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
--        "time": "Sun May 14 00:30:59 2023"
-+        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-+        "time": "Tue May 16 00:22:08 2023"
-     },
-     "save_diff": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-     },
-     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-     "set_seed": {
-         "_type": "python_object (type = method)",
--        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-+        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-     },
-     "suffix": "0",
-     "verbose": true,
-diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-index 6c69f6b..c30ee70 100644
---- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-+++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/diff.txt
-@@ -1,244 +1,71 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 1dd7eb6..98c4875 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -17,7 +17,7 @@ args_to_watch = [
-- base = {
-- 
--     'train': {
---        'N': 100,
--+        'N': 20,
--         'discount': 0.99,
--         'n_layer': 4,
--         'n_head': 4,
--diff --git a/Trajectory_Transformer/scripts/plan.py b/Trajectory_Transformer/scripts/plan.py
--index 881688c..f06654a 100644
----- a/Trajectory_Transformer/scripts/plan.py
--+++ b/Trajectory_Transformer/scripts/plan.py
--@@ -1,10 +1,15 @@
-- import json
-- import pdb
--+import os
--+import sys
-- from os.path import join
-- import gym
-- import gym_anytrading
--+import numpy as np
-- from gym_anytrading.envs import TradingEnv, ForexEnv, StocksEnv, Actions, Positions 
-- from gym_anytrading.datasets import FOREX_EURUSD_1H_ASK, STOCKS_GOOGL
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.search import (
--@@ -39,7 +44,7 @@ gpt, gpt_epoch = utils.load_model(args.logbase, args.dataset, args.gpt_loadpath,
-- #######################
-- 
-- env = gym.make(args.dataset, frame_bound=(50, 100), window_size=10)
---renderer = utils.make_renderer(args)
--+#renderer = utils.make_renderer(args)
-- timer = utils.timer.Timer()
-- 
-- discretizer = dataset.discretizer
--@@ -48,7 +53,7 @@ observation_dim = dataset.observation_dim
-- action_dim = dataset.action_dim
-- 
-- value_fn = lambda x: discretizer.value_fn(x, args.percentile)
---preprocess_fn = datasets.get_preprocess_fn(env.name)
--+#preprocess_fn = datasets.get_preprocess_fn(env.name)
-- 
-- #######################
-- ###### main loop ######
--@@ -63,10 +68,11 @@ rollout = [observation.copy()]
-- ## previous (tokenized) transitions for conditioning transformer
-- context = []
-- 
---T = env.max_episode_steps
--+T = 1000000
-- for t in range(T):
-- 
---    observation = preprocess_fn(observation)
--+    #observation = preprocess_fn(observation)
--+    observation = observation.reshape(-1)
-- 
--     if t % args.plan_freq == 0:
--         ## concatenate previous transitions and current observations to input to model
--@@ -90,18 +96,18 @@ for t in range(T):
--     action = extract_actions(sequence_recon, observation_dim, action_dim, t=0)
-- 
--     ## execute action in environment
---    next_observation, reward, terminal, _ = env.step(action)
--+    next_observation, reward, terminal, info = env.step(np.argmax(action))
-- 
--     ## update return
--     total_reward += reward
---    score = env.get_normalized_score(total_reward)
--+    #score = env.get_normalized_score(total_reward)
-- 
--     ## update rollout observations and context transitions
--     rollout.append(next_observation.copy())
--     context = update_context(context, discretizer, observation, action, reward, args.max_context_transitions)
-- 
--     print(
---        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} | score: {score:.4f} | '
--+        f'[ plan ] t: {t} / {T} | r: {reward:.2f} | R: {total_reward:.2f} '
--         f'time: {timer():.2f} | {args.dataset} | {args.exp_name} | {args.suffix}\n'
--     )
-- 
--@@ -114,11 +120,13 @@ for t in range(T):
--     #    ## save rollout thus far
--     #    renderer.render_rollout(join(args.savepath, f'rollout.mp4'), rollout, fps=80)
-- 
---    if terminal: break
--+    if terminal: 
--+        print(info)
--+        break
-- 
--     observation = next_observation
-- 
-- ## save result as a json file
-- json_path = join(args.savepath, 'rollout.json')
---json_data = {'score': score, 'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
--+json_data = {'step': t, 'return': total_reward, 'term': terminal, 'gpt_epoch': gpt_epoch}
-- json.dump(json_data, open(json_path, 'w'), indent=2, sort_keys=True)
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index ddcda7a..9a2273b 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -2,11 +2,17 @@ import os
-- import numpy as np
-- import torch
-- import pdb
--+import sys
--+
--+parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
--+sys.path.insert(0, parent_dir)
-- 
-- import trajectory.utils as utils
-- import trajectory.datasets as datasets
-- from trajectory.models.transformers import GPT
-- 
--+os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
--+os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
--     dataset: str = 'forex-v0'
--@@ -31,7 +37,7 @@ dataset_config = utils.Config(
--     savepath=(args.savepath, 'data_config.pkl'),
--     env=args.dataset,
--     N=args.N,
---    penalty=args.termination_penalty,
--+    penalty=None,
--     sequence_length=sequence_length,
--     step=args.step,
--     discount=args.discount,
--@@ -104,7 +110,8 @@ trainer = trainer_config()
-- #######################
-- 
-- ## scale number of epochs to keep number of updates constant
---n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+#n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
--+n_epochs = 3000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl
--deleted file mode 100644
--index fa97c75..0000000
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_random.pkl and /dev/null differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index 71bfb7e..bbd08e4 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -13,7 +13,7 @@ env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
-- action_dim = env.action_space.n
-- 
-- episode = 10
---
--+T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = []
--@@ -25,13 +25,12 @@ for _ in range(episode):
--         episode_data['observations'].append(observation.reshape(-1).astype('float32'))
--         episode_data['next_observations'].append(next_observation.reshape(-1).astype('float32'))
--         episode_data['actions'].append(action)
---        episode_data['rewards'].append(np.array(reward).astype('float32'))
--+        episode_data['rewards'].append(np.array([reward]).astype('float32'))
--         episode_data['terminals'].append(done)
--         if done:
--             break
-- 
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
--     episode_data[k] = np.stack(episode_data[k])
---
---with open('trajectory-transformer/trajectory/datasets/Random/{}_'.format(quat_type) + '_random.pkl', 'wb') as f:
--+with open('/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/trajectory/datasets/Random/{}_r'.format(quat_type) + '.pkl', 'wb') as f:
--     pickle.dump(episode_data, f)
--\ No newline at end of file
--diff --git a/Trajectory_Transformer/trajectory/datasets/__init__.py b/Trajectory_Transformer/trajectory/datasets/__init__.py
--index 69ee58d..d1062c5 100644
----- a/Trajectory_Transformer/trajectory/datasets/__init__.py
--+++ b/Trajectory_Transformer/trajectory/datasets/__init__.py
--@@ -1,3 +1,3 @@
---from .d4rl import load_environment
--+#from .d4rl import load_environment
-- from .sequence import *
-- from .preprocessing import get_preprocess_fn
--diff --git a/Trajectory_Transformer/trajectory/datasets/sequence.py b/Trajectory_Transformer/trajectory/datasets/sequence.py
--index c23b4f3..4525194 100644
----- a/Trajectory_Transformer/trajectory/datasets/sequence.py
--+++ b/Trajectory_Transformer/trajectory/datasets/sequence.py
--@@ -53,7 +53,7 @@ class SequenceDataset(torch.utils.data.Dataset):
--         self.device = device
--         
--         print(f'[ datasets/sequence ] Loading...', end=' ', flush=True)
---        with open('trajectory-transformer/trajectory/datasets/Random'+env+'.pkl', 'rb') as f:
--+        with open('Trajectory_Transformer/trajectory/datasets/Random/'+env+'.pkl', 'rb') as f:
--             dataset = pickle.load(f)
--         print('✓')
-- 
--@@ -69,7 +69,6 @@ class SequenceDataset(torch.utils.data.Dataset):
--         terminals = dataset['terminals']
--         realterminals = [False]*len(dataset['terminals'])
-- 
---        #observations = np.reshape(observations, (100, 7000))
--         self.observations_raw = observations
--         self.actions_raw = actions
--         self.next_observations_raw = next_observations
--diff --git a/Trajectory_Transformer/trajectory/utils/__init__.py b/Trajectory_Transformer/trajectory/utils/__init__.py
--index 7c596c3..7529384 100644
----- a/Trajectory_Transformer/trajectory/utils/__init__.py
--+++ b/Trajectory_Transformer/trajectory/utils/__init__.py
--@@ -2,7 +2,7 @@ from .setup import Parser, watch
-- from .arrays import *
-- from .serialization import *
-- from .progress import Progress, Silent
---from .rendering import make_renderer
--+#from .rendering import make_renderer
-- # from .video import *
-- from .config import Config
-- from .training import Trainer
--diff --git a/requirements.txt b/requirements.txt
--index ece16ed..a579177 100644
----- a/requirements.txt
--+++ b/requirements.txt
--@@ -1,14 +1,16 @@
-- numpy
-- gym
-- numpy
---torch
--+pytorch==1.12.1
--+torchvision==0.13.1 
--+torchaudio==0.12.1
-- transformers==4.5.1
-- wandb==0.9.1
-- tensorboard
-- pyprind
-- tensorflow
-- gin-config
---gym
--+gym==0.21.0
-- tqdm
-- blosc
-- git+https://github.com/google/dopamine.git
-\ No newline at end of file
-+diff --git a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+index f42cef8..0e84897 100644
-+--- a/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-++++ b/logs/forex-v0/plans/defaults/freq1_H15_beam128/0/args.json
-+@@ -1,23 +1,23 @@
-+ {
-+     "add_extras": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaB6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDKGlFKULg=="
-+     },
-+     "beam_width": 128,
-+     "cdf_act": 0.6,
-+     "cdf_obs": null,
-+-    "commit": "205f6b61ecea62a899bd494faab1459a62ea5525 main",
-++    "commit": "16f212f01059ed68ee337318ecfc4a57d31bdca4 main",
-+     "config": "config.offline",
-+     "dataset": "forex-v0",
-+     "device": "cuda",
-+     "exp_name": "plans/defaults/freq1_H15_beam128",
-+     "generate_exp_name": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaCqGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaBSGlFKULg=="
-+     },
-+     "get_commit": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDGGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaDWGlFKULg=="
-+     },
-+     "gpt_epoch": "latest",
-+     "gpt_loadpath": "gpt/azure",
-+@@ -28,7 +28,7 @@
-+     "max_context_transitions": 5,
-+     "mkdir": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaD6GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaC+GlFKULg=="
-+     },
-+     "n_expand": 2,
-+     "percentile": "mean",
-+@@ -37,24 +37,24 @@
-+     "prefix_context": true,
-+     "read_config": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaDSGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaD6GlFKULg=="
-+     },
-+     "renderer": "Renderer",
-+     "reproducibility": {
-+         "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/plan.py",
-+         "git_has_uncommitted_changes": true,
-+         "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
-+-        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/205f6b61ecea62a899bd494faab1459a62ea5525",
-+-        "time": "Sun May 14 00:30:59 2023"
-++        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/16f212f01059ed68ee337318ecfc4a57d31bdca4",
-++        "time": "Tue May 16 00:22:08 2023"
-+     },
-+     "save_diff": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaBaGlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCeGlFKULg=="
-+     },
-+     "savepath": "logs/forex-v0/plans/defaults/freq1_H15_beam128/0",
-+     "set_seed": {
-+         "_type": "python_object (type = method)",
-+-        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMB2hvcml6b26USw+MB3ZlcmJvc2WUiIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB2NkZl9hY3SURz/jMzMzMzMzjApwZXJjZW50aWxllIwEbWVhbpSMCHNldF9zZWVklGgCaAZoD4aUUpSMCHZpc19mcmVxlEsyjAdjZGZfb2JzlE6MBmNvbW1pdJSMLTIwNWY2YjYxZWNlYTYyYTg5OWJkNDk0ZmFhYjE0NTlhNjJlYTU1MjUgbWFpbpSMCXNhdmVfZGlmZpRoAmgGaBaGlFKUjAZzdWZmaXiUjAEwlIwJcGxhbl9mcmVxlEsBjA5wcmVmaXhfY29udGV4dJSIjApiZWFtX3dpZHRolEuAjAphZGRfZXh0cmFzlGgCaAZoHoaUUpSMB2RhdGFzZXSUjAhmb3JleC12MJSMCGV4cF9uYW1llIwgcGxhbnMvZGVmYXVsdHMvZnJlcTFfSDE1X2JlYW0xMjiUjAhuX2V4cGFuZJRLAowGcHJlZml4lIwPcGxhbnMvZGVmYXVsdHMvlIwFa19vYnOUSwGMF21heF9jb250ZXh0X3RyYW5zaXRpb25zlEsFjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaCqGlFKUjAZkZXZpY2WUjARjdWRhlIwMZ3B0X2xvYWRwYXRolIwJZ3B0L2F6dXJllIwKZ2V0X2NvbW1pdJRoAmgGaDGGlFKUjAtyZWFkX2NvbmZpZ5RoAmgGaDSGlFKUjAVrX2FjdJROjAlncHRfZXBvY2iUjAZsYXRlc3SUjAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMB2xvZ2Jhc2WUjAVsb2dzL5SMBW1rZGlylGgCaAZoPoaUUpSMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlHViaA+GlFKULg=="
-++        "_value": "gASVAgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMDnByZWZpeF9jb250ZXh0lIiMBWtfb2JzlEsBjAlncHRfZXBvY2iUjAZsYXRlc3SUjAVrX2FjdJROjAdsb2diYXNllIwFbG9ncy+UjAh2aXNfZnJlcZRLMowXbWF4X2NvbnRleHRfdHJhbnNpdGlvbnOUSwWMBmNvbW1pdJSMLTE2ZjIxMmYwMTA1OWVkNjhlZTMzNzMxOGVjZmM0YTU3ZDMxYmRjYTQgbWFpbpSMCmJlYW1fd2lkdGiUS4CMEWdlbmVyYXRlX2V4cF9uYW1llGgCaAZoFIaUUpSMDGdwdF9sb2FkcGF0aJSMCWdwdC9henVyZZSMCnBlcmNlbnRpbGWUjARtZWFulIwIcmVuZGVyZXKUjAhSZW5kZXJlcpSMB3ZlcmJvc2WUiIwIZXhwX25hbWWUjCBwbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOJSMBnByZWZpeJSMD3BsYW5zL2RlZmF1bHRzL5SMCHNhdmVwYXRolIwwbG9ncy9mb3JleC12MC9wbGFucy9kZWZhdWx0cy9mcmVxMV9IMTVfYmVhbTEyOC8wlIwIc2V0X3NlZWSUaAJoBmgkhpRSlIwJc2F2ZV9kaWZmlGgCaAZoJ4aUUpSMBmNvbmZpZ5SMDmNvbmZpZy5vZmZsaW5llIwJcGxhbl9mcmVxlEsBjAZzdWZmaXiUjAEwlIwFbWtkaXKUaAJoBmgvhpRSlIwKYWRkX2V4dHJhc5RoAmgGaDKGlFKUjApnZXRfY29tbWl0lGgCaAZoNYaUUpSMB2NkZl9vYnOUTowHY2RmX2FjdJRHP+MzMzMzMzOMB2hvcml6b26USw+MBmRldmljZZSMBGN1ZGGUjAhuX2V4cGFuZJRLAowLcmVhZF9jb25maWeUaAJoBmg+hpRSlIwHZGF0YXNldJSMCGZvcmV4LXYwlHViaCSGlFKULg=="
-+     },
-+     "suffix": "0",
-+     "verbose": true,
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/args.json b/logs/stocks-v0_r/gpt/azure/args.json
-deleted file mode 100644
-index 59fc81f..0000000
---- a/logs/stocks-v0_r/gpt/azure/args.json
-+++ /dev/null
-@@ -1,65 +0,0 @@
--{
--    "N": 20,
--    "action_weight": 5,
--    "add_extras": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1Ymg6hpRSlC4="
--    },
--    "attn_pdrop": 0.1,
--    "batch_size": 64,
--    "commit": "0087b0f25f1751605a875ea673eb0304703b47fe main",
--    "config": "config.offline",
--    "dataset": "stocks-v0_r",
--    "device": "cuda",
--    "discount": 0.99,
--    "discretizer": "QuantileDiscretizer",
--    "embd_pdrop": 0.1,
--    "exp_name": "gpt/azure",
--    "generate_exp_name": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgVhpRSlC4="
--    },
--    "get_commit": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgKhpRSlC4="
--    },
--    "learning_rate": 0.0006,
--    "logbase": "logs/",
--    "lr_decay": true,
--    "mkdir": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgZhpRSlC4="
--    },
--    "n_embd": 32,
--    "n_epochs_ref": 50,
--    "n_head": 4,
--    "n_layer": 4,
--    "n_saves": 3,
--    "read_config": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgdhpRSlC4="
--    },
--    "reproducibility": {
--        "command_line": "python /home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading/Trajectory_Transformer/scripts/train.py",
--        "git_has_uncommitted_changes": true,
--        "git_root": "/home/kjlin0508/Course_work/AI_Intro/RL_for_Quatitatitive_Trading",
--        "git_url": "https://github.com/KJLdefeated/RL_for_Quatitatitive_Trading/tree/0087b0f25f1751605a875ea673eb0304703b47fe",
--        "time": "Mon May 15 17:39:32 2023"
--    },
--    "resid_pdrop": 0.1,
--    "reward_weight": 1,
--    "save_diff": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgphpRSlC4="
--    },
--    "savepath": "logs/stocks-v0_r/gpt/azure",
--    "seed": 42,
--    "set_seed": {
--        "_type": "python_object (type = method)",
--        "_value": "gASVHgMAAAAAAACMCGJ1aWx0aW5zlIwHZ2V0YXR0cpSTlIwIX19tYWluX1+UjAZQYXJzZXKUk5QpgZR9lCiMBHNlZWSUSyqMDHZhbHVlX3dlaWdodJRLAYwKZ2V0X2NvbW1pdJRoAmgGaAqGlFKUjBN0ZXJtaW5hdGlvbl9wZW5hbHR5lEqc////jAZjb25maWeUjA5jb25maWcub2ZmbGluZZSMCGxyX2RlY2F5lIiMCmF0dG5fcGRyb3CURz+5mZmZmZmajAFOlEsUjAdkYXRhc2V0lIwLc3RvY2tzLXYwX3KUjBFnZW5lcmF0ZV9leHBfbmFtZZRoAmgGaBWGlFKUjAZuX2VtYmSUSyCMBW1rZGlylGgCaAZoGYaUUpSMDXJld2FyZF93ZWlnaHSUSwGMC3JlYWRfY29uZmlnlGgCaAZoHYaUUpSMCHNldF9zZWVklGgCaAZoIIaUUpSMCmVtYmRfcGRyb3CURz+5mZmZmZmajAZkZXZpY2WUjARjdWRhlIwNYWN0aW9uX3dlaWdodJRLBYwLZGlzY3JldGl6ZXKUjBNRdWFudGlsZURpc2NyZXRpemVylIwJc2F2ZV9kaWZmlGgCaAZoKYaUUpSMBmNvbW1pdJSMLTAwODdiMGYyNWYxNzUxNjA1YTg3NWVhNjczZWIwMzA0NzAzYjQ3ZmUgbWFpbpSMBHN0ZXCUSwGMDWxlYXJuaW5nX3JhdGWURz9DqSowVTJhjBpzdWJzYW1wbGVkX3NlcXVlbmNlX2xlbmd0aJRLCowHbl9sYXllcpRLBIwIc2F2ZXBhdGiUjBpsb2dzL3N0b2Nrcy12MF9yL2dwdC9henVyZZSMDG5fZXBvY2hzX3JlZpRLMowIZGlzY291bnSURz/vrhR64UeujApiYXRjaF9zaXpllEtAjAhleHBfbmFtZZSMCWdwdC9henVyZZSMB25fc2F2ZXOUSwOMCmFkZF9leHRyYXOUaAJoBmg6hpRSlIwHbG9nYmFzZZSMBWxvZ3MvlIwLcmVzaWRfcGRyb3CURz+5mZmZmZmajAZuX2hlYWSUSwR1YmgghpRSlC4="
--    },
--    "step": 1,
--    "subsampled_sequence_length": 10,
--    "termination_penalty": -100,
--    "value_weight": 1
--}
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/data_config.pkl b/logs/stocks-v0_r/gpt/azure/data_config.pkl
-deleted file mode 100644
-index f2b7eea..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/data_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/diff.txt b/logs/stocks-v0_r/gpt/azure/diff.txt
-deleted file mode 100644
-index 7d861b1..0000000
---- a/logs/stocks-v0_r/gpt/azure/diff.txt
-+++ /dev/null
-@@ -1,59 +0,0 @@
--diff --git a/Trajectory_Transformer/config/offline.py b/Trajectory_Transformer/config/offline.py
--index 98c4875..9a7a974 100644
----- a/Trajectory_Transformer/config/offline.py
--+++ b/Trajectory_Transformer/config/offline.py
--@@ -29,7 +29,7 @@ base = {
--         'device': 'cuda',
-- 
--         'n_embd': 32,
---        'batch_size': 256,
--+        'batch_size': 64,
--         'learning_rate': 6e-4,
--         'lr_decay': True,
--         'seed': 42,
--diff --git a/Trajectory_Transformer/scripts/train.py b/Trajectory_Transformer/scripts/train.py
--index 9a2273b..6ef5569 100644
----- a/Trajectory_Transformer/scripts/train.py
--+++ b/Trajectory_Transformer/scripts/train.py
--@@ -15,7 +15,7 @@ os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
-- os.environ["CUDA_VISIBLE_DEVICES"] = '2'
-- 
-- class Parser(utils.Parser):
---    dataset: str = 'forex-v0'
--+    dataset: str = 'stocks-v0_r'
--     config: str = 'config.offline'
-- 
-- #######################
--@@ -111,7 +111,7 @@ trainer = trainer_config()
-- 
-- ## scale number of epochs to keep number of updates constant
-- #n_epochs = int(1e6 / len(dataset) * args.n_epochs_ref)
---n_epochs = 3000
--+n_epochs = 5000
-- save_freq = int(n_epochs // args.n_saves)
-- 
-- for epoch in range(n_epochs):
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl
--index 506330f..e08063c 100644
--Binary files a/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl and b/Trajectory_Transformer/trajectory/datasets/Random/forex-v0_r.pkl differ
--diff --git a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--index bbd08e4..659bd84 100644
----- a/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--+++ b/Trajectory_Transformer/trajectory/datasets/Random/gen_data.py
--@@ -6,13 +6,13 @@ import matplotlib.pyplot as plt
-- import numpy as np
-- import pickle
-- 
---quat_type = "forex-v0"
---env = gym.make('forex-v0', frame_bound=(50, 100), window_size=10)
--+quat_type = "stocks-v0"
--+env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- # env = gym.make('stocks-v0', frame_bound=(50, 100), window_size=10)
-- 
-- action_dim = env.action_space.n
-- 
---episode = 10
--+episode = 100
-- T = 0
-- episode_data = {}
-- for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:
-\ No newline at end of file
-diff --git a/logs/stocks-v0_r/gpt/azure/model_config.pkl b/logs/stocks-v0_r/gpt/azure/model_config.pkl
-deleted file mode 100644
-index db868c9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/model_config.pkl and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_0.pt b/logs/stocks-v0_r/gpt/azure/state_0.pt
-deleted file mode 100644
-index aaacded..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_0.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_1666.pt b/logs/stocks-v0_r/gpt/azure/state_1666.pt
-deleted file mode 100644
-index c3fe2b4..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_1666.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_3332.pt b/logs/stocks-v0_r/gpt/azure/state_3332.pt
-deleted file mode 100644
-index f13edba..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_3332.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/state_4998.pt b/logs/stocks-v0_r/gpt/azure/state_4998.pt
-deleted file mode 100644
-index 5531c7d..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/state_4998.pt and /dev/null differ
-diff --git a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl b/logs/stocks-v0_r/gpt/azure/trainer_config.pkl
-deleted file mode 100644
-index 090ede9..0000000
-Binary files a/logs/stocks-v0_r/gpt/azure/trainer_config.pkl and /dev/null differ
\ No newline at end of file
diff --git a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/rollout.json b/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/rollout.json
deleted file mode 100644
index fcf8f69..0000000
--- a/logs/stocks-v0/plans/defaults/freq1_H15_beam128/0/rollout.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-  "gpt_epoch": 4998,
-  "return": 16.521515000000022,
-  "step": 48,
-  "term": true
-}
\ No newline at end of file